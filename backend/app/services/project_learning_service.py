"""
Project Learning Service - é¡¹ç›®çº§ç»´åº¦/æ ‡ç­¾å­¦ä¹ ä¸æ˜ å°„æœåŠ¡

ç”¨äºå¸‚åœºæ´å¯ŸåŠŸèƒ½çš„"é¡¹ç›®çº§å­¦ä¹ "æ¨¡å¼ï¼š
1. ä»å¤šä¸ªäº§å“ä¸­é‡‡æ ·è¯„è®ºï¼ˆç§‘å­¦é‡‡æ ·ï¼Œä¸äº§å“å±‚é¢ä¸€è‡´ï¼‰
2. è°ƒç”¨ç°æœ‰çš„ translation_service å­¦ä¹ é¡¹ç›®çº§ç»´åº¦å’Œæ ‡ç­¾
3. è°ƒç”¨ AI å»ºç«‹æ˜ å°„å…³ç³»ï¼ˆåªä¼ åç§°åˆ—è¡¨ï¼Œæ•°æ®é‡å°ï¼‰
4. å­˜å‚¨é¡¹ç›®çº§ç»´åº¦/æ ‡ç­¾å’Œæ˜ å°„å…³ç³»

å‚è€ƒäº§å“å±‚é¢çš„ç§‘å­¦å­¦ä¹ æ–¹æ³•ï¼Œåªæ˜¯æ•°æ®é‡åšäº†å¢åŠ ã€‚
"""
import json
import logging
import random
from typing import List, Dict, Optional, Tuple
from uuid import UUID
from difflib import SequenceMatcher

from sqlalchemy import select, delete, func
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.product import Product
from app.models.product_dimension import ProductDimension
from app.models.product_context_label import ProductContextLabel
from app.models.review import Review, TranslationStatus
from app.models.project_learning import (
    ProjectDimension, 
    ProjectContextLabel, 
    ProjectDimensionMapping, 
    ProjectLabelMapping
)
from app.services.translation import translation_service
from app.core.config import settings

logger = logging.getLogger(__name__)


class ProjectLearningService:
    """
    é¡¹ç›®çº§ç»´åº¦/æ ‡ç­¾å­¦ä¹ ä¸æ˜ å°„æœåŠ¡
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. é‡‡æ ·è¯„è®ºï¼šä»å¤šä¸ªäº§å“ä¸­æŒ‰æ¯”ä¾‹é‡‡æ ·è¯„è®º
    2. å­¦ä¹ é˜¶æ®µï¼šå¤ç”¨ translation_service å­¦ä¹ é¡¹ç›®çº§ç»´åº¦å’Œæ ‡ç­¾
    3. æ˜ å°„é˜¶æ®µï¼šè°ƒç”¨ AI å»ºç«‹æ˜ å°„å…³ç³»
    4. å­˜å‚¨ç»“æœï¼šæŒä¹…åŒ–åˆ°æ•°æ®åº“
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    async def learn_project_dimensions_and_labels(
        self,
        project_id: UUID,
        product_ids: List[UUID],
        sample_per_product: int = 40,
        max_total_samples: int = 100
    ) -> Dict:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šé¡¹ç›®çº§ç»´åº¦å’Œæ ‡ç­¾å­¦ä¹  + æ˜ å°„å»ºç«‹
        
        æµç¨‹ï¼š
        1. ä»æ¯ä¸ªäº§å“é‡‡æ ·è¯„è®ºï¼ˆé™åˆ¶æ•°é‡ï¼Œä¸äº§å“å±‚é¢ä¸€è‡´ï¼‰
        2. è°ƒç”¨ translation_service å­¦ä¹ é¡¹ç›®çº§ç»´åº¦
        3. è°ƒç”¨ translation_service å­¦ä¹ é¡¹ç›®çº§æ ‡ç­¾
        4. è°ƒç”¨ AI å»ºç«‹æ˜ å°„å…³ç³»
        5. å­˜å‚¨åˆ°æ•°æ®åº“
        
        Args:
            project_id: åˆ†æé¡¹ç›® ID
            product_ids: å‚ä¸åˆ†æçš„äº§å“ ID åˆ—è¡¨
            sample_per_product: æ¯ä¸ªäº§å“é‡‡æ ·æ•°é‡ï¼ˆé»˜è®¤ 40 æ¡ï¼‰
            max_total_samples: æœ€å¤§æ€»æ ·æœ¬æ•°ï¼ˆé»˜è®¤ 100 æ¡ï¼Œä¸äº§å“å±‚é¢ç±»ä¼¼ï¼‰
            
        Returns:
            å­¦ä¹ ç»“æœå­—å…¸
        """
        logger.info(f"ğŸ“ å¼€å§‹é¡¹ç›®çº§å­¦ä¹ ï¼Œé¡¹ç›®ID={project_id}ï¼Œäº§å“æ•°={len(product_ids)}")
        
        # 1. é‡‡æ ·è¯„è®ºï¼ˆè‹±æ–‡åŸæ–‡ï¼Œç”¨äºè·¨è¯­è¨€å­¦ä¹ ï¼‰
        sampled_reviews, review_stats = await self._sample_reviews_raw(
            product_ids, 
            sample_per_product,
            max_total_samples
        )
        
        if len(sampled_reviews) < 10:
            raise ValueError(f"æ ·æœ¬ä¸è¶³ï¼šéœ€è¦è‡³å°‘10æ¡è¯„è®ºï¼Œå½“å‰åªæœ‰ {len(sampled_reviews)} æ¡")
        
        logger.info(f"ğŸ“ é‡‡æ ·å®Œæˆï¼šå…± {len(sampled_reviews)} æ¡è¯„è®º")
        
        # 2. è·å–äº§å“ä¿¡æ¯ï¼ˆç”¨äºå­¦ä¹ ä¸Šä¸‹æ–‡ï¼‰
        product_info = await self._get_products_info(product_ids)
        
        # åˆå¹¶äº§å“æ ‡é¢˜å’Œå–ç‚¹ä½œä¸ºä¸Šä¸‹æ–‡
        combined_title = " | ".join([p['title'][:50] for p in product_info.values()])
        combined_bullets = []
        for p in product_info.values():
            if p.get('bullet_points'):
                combined_bullets.extend(p['bullet_points'][:3])
        
        # 3. å­¦ä¹ é¡¹ç›®çº§ç»´åº¦ï¼ˆå¤ç”¨ç°æœ‰æ–¹æ³•ï¼‰
        logger.info(f"ğŸ” å¼€å§‹å­¦ä¹ é¡¹ç›®çº§ç»´åº¦...")
        project_dimensions = translation_service.learn_dimensions_from_raw(
            raw_reviews=sampled_reviews[:80],  # é™åˆ¶æ•°é‡
            product_title=combined_title[:200],
            bullet_points="\n".join(combined_bullets[:10])
        )
        
        if not project_dimensions:
            logger.warning("é¡¹ç›®çº§ç»´åº¦å­¦ä¹ è¿”å›ç©ºï¼Œä½¿ç”¨é»˜è®¤ç»´åº¦")
            project_dimensions = {
                "product": [{"name": "åŠŸèƒ½è¡¨ç°", "description": "äº§å“æ ¸å¿ƒåŠŸèƒ½çš„è¡¨ç°"}],
                "scenario": [{"name": "æ—¥å¸¸ä½¿ç”¨", "description": "æ—¥å¸¸ä½¿ç”¨åœºæ™¯"}],
                "emotion": [{"name": "æ»¡æ„åº¦", "description": "æ•´ä½“æ»¡æ„åº¦"}]
            }
        
        dim_count = sum(len(v) for v in project_dimensions.values())
        logger.info(f"âœ… é¡¹ç›®çº§ç»´åº¦å­¦ä¹ å®Œæˆï¼š{dim_count} ä¸ªç»´åº¦")
        
        # 4. å­¦ä¹ é¡¹ç›®çº§æ ‡ç­¾ï¼ˆå¤ç”¨ç°æœ‰æ–¹æ³•ï¼‰
        logger.info(f"ğŸ·ï¸ å¼€å§‹å­¦ä¹ é¡¹ç›®çº§5Wæ ‡ç­¾...")
        project_labels = translation_service.learn_context_labels_from_raw(
            raw_reviews=sampled_reviews[:80],  # é™åˆ¶æ•°é‡
            product_title=combined_title[:200],
            bullet_points=combined_bullets[:10]
        )
        
        if not project_labels:
            logger.warning("é¡¹ç›®çº§æ ‡ç­¾å­¦ä¹ è¿”å›ç©ºï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾")
            project_labels = {
                "buyer": [{"name": "æ™®é€šæ¶ˆè´¹è€…", "description": "ä¸€èˆ¬è´­ä¹°è€…"}],
                "user": [{"name": "æ—¥å¸¸ç”¨æˆ·", "description": "æ—¥å¸¸ä½¿ç”¨è€…"}],
                "where": [{"name": "å®¶åº­", "description": "å®¶åº­ç¯å¢ƒ"}],
                "when": [{"name": "æ—¥å¸¸", "description": "æ—¥å¸¸æ—¶åˆ»"}],
                "why": [{"name": "å®ç”¨éœ€æ±‚", "description": "å®ç”¨ç›®çš„"}],
                "what": [{"name": "ä¸»è¦åŠŸèƒ½", "description": "æ ¸å¿ƒåŠŸèƒ½"}]
            }
        
        label_count = sum(len(v) for v in project_labels.values())
        logger.info(f"âœ… é¡¹ç›®çº§æ ‡ç­¾å­¦ä¹ å®Œæˆï¼š{label_count} ä¸ªæ ‡ç­¾")
        
        # 5. è·å–äº§å“çº§ç»´åº¦å’Œæ ‡ç­¾ï¼ˆç”¨äºå»ºç«‹æ˜ å°„ï¼‰
        products_data = await self._get_products_dimensions_and_labels(product_ids)
        
        # 6. è°ƒç”¨ AI å»ºç«‹æ˜ å°„å…³ç³»
        logger.info(f"ğŸ”— å¼€å§‹å»ºç«‹æ˜ å°„å…³ç³»...")
        dimension_mappings = await self._create_dimension_mappings(
            project_dimensions, 
            products_data
        )
        label_mappings = await self._create_label_mappings(
            project_labels, 
            products_data
        )
        logger.info(f"âœ… æ˜ å°„å…³ç³»å»ºç«‹å®Œæˆ")
        
        # 7. å­˜å‚¨åˆ°æ•°æ®åº“
        await self._save_project_learning_result(
            project_id,
            product_ids,
            project_dimensions,
            project_labels,
            dimension_mappings,
            label_mappings,
            products_data
        )
        
        logger.info(f"âœ… é¡¹ç›®çº§å­¦ä¹ å®Œæˆï¼Œå·²å­˜å‚¨åˆ°æ•°æ®åº“")
        
        return {
            "project_id": str(project_id),
            "sample_stats": review_stats,
            "dimensions": project_dimensions,
            "labels": project_labels,
            "dimension_mappings_count": sum(len(m) for m in dimension_mappings.values()),
            "label_mappings_count": sum(len(m) for m in label_mappings.values())
        }
    
    async def _sample_reviews_raw(
        self,
        product_ids: List[UUID],
        sample_per_product: int,
        max_total_samples: int
    ) -> Tuple[List[str], Dict]:
        """
        ä»å¤šä¸ªäº§å“ä¸­é‡‡æ ·è‹±æ–‡åŸæ–‡è¯„è®ºï¼ˆç”¨äºè·¨è¯­è¨€å­¦ä¹ ï¼‰
        
        é‡‡æ ·ç­–ç•¥ï¼š
        1. æ¯ä¸ªäº§å“é‡‡æ · sample_per_product æ¡
        2. åˆ†å±‚é‡‡æ ·ï¼šä¿æŒè¯„åˆ†åˆ†å¸ƒ
        3. ä½¿ç”¨è‹±æ–‡åŸæ–‡ï¼ˆè·¨è¯­è¨€å­¦ä¹ ï¼‰
        4. æ€»æ•°ä¸Šé™æ§åˆ¶
        """
        all_reviews = []
        stats = {
            "total_products": len(product_ids),
            "products_sampled": {},
            "total_reviews": 0,
            "rating_distribution": {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}
        }
        
        # è®¡ç®—æ¯ä¸ªäº§å“çš„é…é¢
        quota_per_product = max(10, max_total_samples // len(product_ids))
        
        for product_id in product_ids:
            product_reviews = []
            
            # åˆ†å±‚é‡‡æ ·ï¼šæŒ‰è¯„åˆ†åˆ†ç»„
            for rating_range, ratio in [
                ((1, 2), 0.25),   # å·®è¯„ 25%
                ((3, 3), 0.15),  # ä¸­è¯„ 15%
                ((4, 5), 0.60),  # å¥½è¯„ 60%
            ]:
                range_sample = max(2, int(quota_per_product * ratio))
                
                reviews_result = await self.db.execute(
                    select(Review.body_original, Review.rating)
                    .where(Review.product_id == product_id)
                    .where(Review.is_deleted == False)
                    .where(Review.body_original.isnot(None))
                    .where(Review.rating >= rating_range[0])
                    .where(Review.rating <= rating_range[1])
                    .order_by(func.random())
                    .limit(range_sample)
                )
                
                for row in reviews_result.all():
                    text = row.body_original
                    if text and text.strip() and len(text.strip()) > 20:
                        # æˆªæ–­è¿‡é•¿çš„è¯„è®º
                        truncated = text.strip()[:500]
                        product_reviews.append(truncated)
                        rating = int(row.rating) if row.rating else 3
                        if rating in stats["rating_distribution"]:
                            stats["rating_distribution"][rating] += 1
            
            if product_reviews:
                all_reviews.extend(product_reviews)
                stats["products_sampled"][str(product_id)] = len(product_reviews)
        
        stats["total_reviews"] = len(all_reviews)
        
        # å¦‚æœè¶…è¿‡ä¸Šé™ï¼ŒéšæœºæŠ½å–
        if len(all_reviews) > max_total_samples:
            all_reviews = random.sample(all_reviews, max_total_samples)
            stats["total_reviews"] = max_total_samples
        
        return all_reviews, stats
    
    async def _get_products_info(self, product_ids: List[UUID]) -> Dict[str, Dict]:
        """è·å–äº§å“åŸºæœ¬ä¿¡æ¯"""
        result = {}
        
        for product_id in product_ids:
            product_result = await self.db.execute(
                select(Product).where(Product.id == product_id)
            )
            product = product_result.scalar_one_or_none()
            
            if product:
                # è§£æ bullet_points
                bullet_list = []
                if product.bullet_points:
                    try:
                        bullet_list = json.loads(product.bullet_points)
                        if not isinstance(bullet_list, list):
                            bullet_list = []
                    except:
                        bullet_list = []
                
                result[str(product_id)] = {
                    "asin": product.asin,
                    "title": product.title or product.asin,
                    "bullet_points": bullet_list
                }
        
        return result
    
    async def _get_products_dimensions_and_labels(
        self,
        product_ids: List[UUID]
    ) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰äº§å“çš„ç»´åº¦å’Œæ ‡ç­¾"""
        products_data = {}
        
        for product_id in product_ids:
            # è·å–äº§å“ä¿¡æ¯
            product_result = await self.db.execute(
                select(Product).where(Product.id == product_id)
            )
            product = product_result.scalar_one_or_none()
            
            if not product:
                continue
            
            # è·å–ç»´åº¦
            dims_result = await self.db.execute(
                select(ProductDimension)
                .where(ProductDimension.product_id == product_id)
            )
            dimensions = {}
            for d in dims_result.scalars().all():
                dim_type = d.dimension_type or "product"
                if dim_type not in dimensions:
                    dimensions[dim_type] = []
                dimensions[dim_type].append({
                    "id": str(d.id),
                    "name": d.name
                })
            
            # è·å–æ ‡ç­¾
            labels_result = await self.db.execute(
                select(ProductContextLabel)
                .where(ProductContextLabel.product_id == product_id)
            )
            labels = {}
            for label in labels_result.scalars().all():
                if label.type not in labels:
                    labels[label.type] = []
                labels[label.type].append({
                    "id": str(label.id),
                    "name": label.name
                })
            
            products_data[str(product_id)] = {
                "asin": product.asin,
                "title": product.title or product.asin,
                "dimensions": dimensions,
                "labels": labels
            }
        
        return products_data
    
    def _create_fallback_dimension_mappings(
        self,
        project_dimensions: Dict[str, List[Dict]],
        products_data: Dict[str, Dict],
        similarity_threshold: float = 0.5
    ) -> Dict[str, List[Dict]]:
        """
        åŸºäºåç§°ç›¸ä¼¼åº¦çš„åå¤‡ç»´åº¦æ˜ å°„æ–¹æ¡ˆ
        
        å½“ AI æ˜ å°„å¤±è´¥æ—¶ä½¿ç”¨
        
        ç»´åº¦æ˜ å°„é™åˆ¶ç±»å‹ï¼ˆproduct->product, scenario->scenario, emotion->emotionï¼‰
        """
        mappings = {}
        total_checked = 0
        total_matched = 0
        
        for dim_type, project_dims in project_dimensions.items():
            mappings[dim_type] = []
            
            for project_dim in project_dims:
                project_dim_name = project_dim['name']
                
                # åœ¨æ¯ä¸ªäº§å“ä¸­æŸ¥æ‰¾ç›¸ä¼¼ç»´åº¦ï¼ˆåŒç±»å‹ï¼‰
                for product_id, data in products_data.items():
                    product_dims = data.get('dimensions', {}).get(dim_type, [])
                    
                    for product_dim in product_dims:
                        product_dim_name = product_dim['name']
                        total_checked += 1
                        
                        # è®¡ç®—ç›¸ä¼¼åº¦
                        similarity = SequenceMatcher(
                            None, 
                            project_dim_name.lower(), 
                            product_dim_name.lower()
                        ).ratio()
                        
                        if similarity >= similarity_threshold:
                            total_matched += 1
                            mappings[dim_type].append({
                                "project_dimension_name": project_dim_name,
                                "product_id": product_id,
                                "product_dimension_name": product_dim_name
                            })
        
        logger.info(f"ç»´åº¦åå¤‡æ˜ å°„ï¼šæ£€æŸ¥äº† {total_checked} å¯¹ï¼ŒåŒ¹é…äº† {total_matched} å¯¹ï¼ˆé˜ˆå€¼={similarity_threshold}ï¼‰")
        return mappings
    
    def _create_fallback_label_mappings(
        self,
        project_labels: Dict[str, List[Dict]],
        products_data: Dict[str, Dict],
        similarity_threshold: float = 0.5
    ) -> Dict[str, List[Dict]]:
        """
        åŸºäºåç§°ç›¸ä¼¼åº¦çš„åå¤‡æ ‡ç­¾æ˜ å°„æ–¹æ¡ˆ
        
        å½“ AI æ˜ å°„å¤±è´¥æ—¶ä½¿ç”¨
        
        æ ‡ç­¾æ˜ å°„æŒ‰ç±»å‹åŒ¹é…ï¼ˆbuyer->buyer, user->user ç­‰ï¼‰ï¼Œ
        å› ä¸ºæ ‡ç­¾ç±»å‹æ˜¯æœ‰è¯­ä¹‰æ„ä¹‰çš„ã€‚
        """
        mappings = {}
        total_checked = 0
        total_matched = 0
        
        for label_type, project_labels_list in project_labels.items():
            mappings[label_type] = []
            
            for project_label in project_labels_list:
                project_label_name = project_label['name']
                
                # åœ¨æ¯ä¸ªäº§å“ä¸­æŸ¥æ‰¾ç›¸ä¼¼æ ‡ç­¾ï¼ˆåŒç±»å‹ï¼‰
                for product_id, data in products_data.items():
                    product_labels_list = data.get('labels', {}).get(label_type, [])
                    
                    for product_label in product_labels_list:
                        product_label_name = product_label['name']
                        total_checked += 1
                        
                        # è®¡ç®—ç›¸ä¼¼åº¦
                        similarity = SequenceMatcher(
                            None, 
                            project_label_name.lower(), 
                            product_label_name.lower()
                        ).ratio()
                        
                        if similarity >= similarity_threshold:
                            total_matched += 1
                            mappings[label_type].append({
                                "project_label_name": project_label_name,
                                "product_id": product_id,
                                "product_label_name": product_label_name
                            })
        
        logger.info(f"æ ‡ç­¾åå¤‡æ˜ å°„ï¼šæ£€æŸ¥äº† {total_checked} å¯¹ï¼ŒåŒ¹é…äº† {total_matched} å¯¹ï¼ˆé˜ˆå€¼={similarity_threshold}ï¼‰")
        return mappings
    
    async def _create_dimension_mappings(
        self,
        project_dimensions: Dict[str, List[Dict]],
        products_data: Dict[str, Dict]
    ) -> Dict[str, List[Dict]]:
        """
        è°ƒç”¨ AI å»ºç«‹ç»´åº¦æ˜ å°„å…³ç³»
        
        è¾“å…¥åªæœ‰åç§°åˆ—è¡¨ï¼Œæ•°æ®é‡å¾ˆå°
        å¦‚æœ AI å¤±è´¥ï¼Œä½¿ç”¨åŸºäºåç§°ç›¸ä¼¼åº¦çš„åå¤‡æ–¹æ¡ˆ
        """
        # å‡†å¤‡æ˜ å°„è¾“å…¥ï¼ˆåªæœ‰åç§°ï¼‰
        project_dim_names = {}
        for dim_type, dims in project_dimensions.items():
            project_dim_names[dim_type] = [d['name'] for d in dims]
        
        product_dim_names = {}
        for product_id, data in products_data.items():
            product_dim_names[product_id] = {}
            for dim_type, dims in data.get('dimensions', {}).items():
                product_dim_names[product_id][dim_type] = [d['name'] for d in dims]
        
        # è°ƒç”¨ AI å»ºç«‹æ˜ å°„
        mappings = await self._call_ai_for_dimension_mapping(
            project_dim_names, 
            product_dim_names
        )
        
        # å¦‚æœ AI æ˜ å°„å¤±è´¥æˆ–è¿”å›ç©ºï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ
        if not mappings or sum(len(m) for m in mappings.values()) == 0:
            logger.info("ç»´åº¦æ˜ å°„ï¼šAI æ˜ å°„å¤±è´¥ï¼Œä½¿ç”¨åŸºäºåç§°ç›¸ä¼¼åº¦çš„åå¤‡æ–¹æ¡ˆ")
            mappings = self._create_fallback_dimension_mappings(
                project_dimensions, 
                products_data
            )
            logger.info(f"ç»´åº¦æ˜ å°„ï¼šåå¤‡æ–¹æ¡ˆç”Ÿæˆäº† {sum(len(m) for m in mappings.values())} ä¸ªæ˜ å°„")
        
        return mappings
    
    async def _create_label_mappings(
        self,
        project_labels: Dict[str, List[Dict]],
        products_data: Dict[str, Dict]
    ) -> Dict[str, List[Dict]]:
        """
        è°ƒç”¨ AI å»ºç«‹æ ‡ç­¾æ˜ å°„å…³ç³»
        
        è¾“å…¥åªæœ‰åç§°åˆ—è¡¨ï¼Œæ•°æ®é‡å¾ˆå°
        å¦‚æœ AI å¤±è´¥ï¼Œä½¿ç”¨åŸºäºåç§°ç›¸ä¼¼åº¦çš„åå¤‡æ–¹æ¡ˆ
        """
        # å‡†å¤‡æ˜ å°„è¾“å…¥ï¼ˆåªæœ‰åç§°ï¼‰
        project_label_names = {}
        for label_type, labels in project_labels.items():
            project_label_names[label_type] = [l['name'] for l in labels]
        
        product_label_names = {}
        for product_id, data in products_data.items():
            product_label_names[product_id] = {}
            for label_type, labels in data.get('labels', {}).items():
                product_label_names[product_id][label_type] = [l['name'] for l in labels]
        
        # è°ƒç”¨ AI å»ºç«‹æ˜ å°„
        mappings = await self._call_ai_for_label_mapping(
            project_label_names, 
            product_label_names
        )
        
        # å¦‚æœ AI æ˜ å°„å¤±è´¥æˆ–è¿”å›ç©ºï¼Œä½¿ç”¨åå¤‡æ–¹æ¡ˆ
        if not mappings or sum(len(m) for m in mappings.values()) == 0:
            logger.info("æ ‡ç­¾æ˜ å°„ï¼šAI æ˜ å°„å¤±è´¥ï¼Œä½¿ç”¨åŸºäºåç§°ç›¸ä¼¼åº¦çš„åå¤‡æ–¹æ¡ˆ")
            mappings = self._create_fallback_label_mappings(
                project_labels, 
                products_data
            )
            logger.info(f"æ ‡ç­¾æ˜ å°„ï¼šåå¤‡æ–¹æ¡ˆç”Ÿæˆäº† {sum(len(m) for m in mappings.values())} ä¸ªæ˜ å°„")
        
        return mappings
    
    def _safe_parse_json(self, text: str) -> Optional[dict]:
        """
        å®‰å…¨åœ°è§£æ JSONï¼Œå°è¯•ä¿®å¤å¸¸è§é”™è¯¯
        
        Returns:
            è§£æåçš„å­—å…¸ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        if not text or not text.strip():
            return None
        
        # æ¸…ç† markdown ä»£ç å—
        cleaned = text.strip()
        if cleaned.startswith("```json"):
            cleaned = cleaned[7:]
        elif cleaned.startswith("```"):
            cleaned = cleaned[3:]
        if cleaned.endswith("```"):
            cleaned = cleaned[:-3]
        cleaned = cleaned.strip()
        
        # å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(cleaned)
        except json.JSONDecodeError as e:
            logger.warning(f"JSON è§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤: {e}")
            
            # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é”™è¯¯
            # 1. ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²ï¼ˆåœ¨å­—ç¬¦ä¸²æœ«å°¾æ·»åŠ å¼•å·ï¼‰
            try:
                # æ‰¾åˆ°æœ€åä¸€ä¸ªæœªé—­åˆçš„å¼•å·ä½ç½®
                last_quote = cleaned.rfind('"')
                if last_quote > 0:
                    # æ£€æŸ¥æ˜¯å¦åœ¨å­—ç¬¦ä¸²ä¸­é—´ï¼ˆç®€å•æ£€æŸ¥ï¼šå¼•å·æ•°é‡æ˜¯å¦ä¸ºå¥‡æ•°ï¼‰
                    before_quote = cleaned[:last_quote]
                    # æ’é™¤è½¬ä¹‰çš„å¼•å·
                    quote_count = 0
                    i = 0
                    while i < len(before_quote):
                        if before_quote[i] == '"' and (i == 0 or before_quote[i-1] != '\\'):
                            quote_count += 1
                        i += 1
                    
                    if quote_count % 2 == 1:  # å¥‡æ•°ä¸ªå¼•å·ï¼Œè¯´æ˜æœ‰æœªé—­åˆçš„
                        # å°è¯•åœ¨æœ«å°¾æ·»åŠ å¼•å·å’Œé—­åˆæ‹¬å·
                        if cleaned.rstrip().endswith(','):
                            fixed = cleaned.rstrip()[:-1] + '"}'
                        else:
                            fixed = cleaned + '"'
                        return json.loads(fixed)
            except:
                pass
            
            # 2. å°è¯•ä¿®å¤å­—ç¬¦ä¸²ä¸­çš„æ¢è¡Œç¬¦ï¼ˆåœ¨å­—ç¬¦ä¸²å€¼ä¸­ï¼‰
            try:
                import re
                # ç®€å•æ–¹æ³•ï¼šåœ¨å­—ç¬¦ä¸²å€¼ä¸­ï¼Œå°†æœªè½¬ä¹‰çš„æ¢è¡Œç¬¦æ›¿æ¢ä¸º \n
                # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•æ¯”è¾ƒç²—ç³™ï¼Œä½†å¯ä»¥å¤„ç†ä¸€äº›å¸¸è§æƒ…å†µ
                # åŒ¹é… "key": "value\nwith newline" è¿™ç§æƒ…å†µ
                fixed = re.sub(r'(?<!\\)\n', '\\n', cleaned)
                fixed = re.sub(r'(?<!\\)\r', '\\r', fixed)
                fixed = re.sub(r'(?<!\\)\t', '\\t', fixed)
                if fixed != cleaned:
                    return json.loads(fixed)
            except:
                pass
            
            # 3. å°è¯•æå–ç¬¬ä¸€ä¸ªå®Œæ•´çš„ JSON å¯¹è±¡
            try:
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ª { å’Œæœ€åä¸€ä¸ª }
                start = cleaned.find('{')
                if start >= 0:
                    # ä»åå¾€å‰æ‰¾åŒ¹é…çš„ }
                    depth = 0
                    end = len(cleaned)
                    for i in range(len(cleaned) - 1, start - 1, -1):
                        if cleaned[i] == '}':
                            if depth == 0:
                                end = i + 1
                                break
                            depth -= 1
                        elif cleaned[i] == '{':
                            depth += 1
                    
                    if end > start:
                        partial = cleaned[start:end]
                        return json.loads(partial)
            except:
                pass
            
            # 3. å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè®°å½•è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
            error_pos = getattr(e, 'pos', None) or 0
            start_pos = max(0, error_pos - 200)
            end_pos = min(len(cleaned), error_pos + 200)
            error_context = cleaned[start_pos:end_pos]
            logger.error(f"æ— æ³•ä¿®å¤ JSONï¼Œé”™è¯¯: {e}ï¼Œé”™è¯¯ä½ç½®: {error_pos}")
            logger.error(f"é”™è¯¯ä¸Šä¸‹æ–‡: {error_context}")
            logger.error(f"å®Œæ•´ JSON é•¿åº¦: {len(cleaned)} å­—ç¬¦")
            # ä¿å­˜å®Œæ•´ JSON åˆ°æ—¥å¿—ï¼ˆé™åˆ¶é•¿åº¦é¿å…æ—¥å¿—è¿‡å¤§ï¼‰
            if len(cleaned) > 2000:
                logger.error(f"JSON å‰ 1000 å­—ç¬¦: {cleaned[:1000]}")
                logger.error(f"JSON å 1000 å­—ç¬¦: {cleaned[-1000:]}")
            else:
                logger.error(f"å®Œæ•´ JSON: {cleaned}")
            return None
    
    async def _call_ai_for_dimension_mapping(
        self,
        project_dims: Dict[str, List[str]],
        product_dims: Dict[str, Dict[str, List[str]]]
    ) -> Dict[str, List[Dict]]:
        """
        è°ƒç”¨ AI å»ºç«‹ç»´åº¦æ˜ å°„
        
        è¾“å…¥æ•°æ®é‡å¾ˆå°ï¼šåªæœ‰ç»´åº¦åç§°åˆ—è¡¨
        """
        from openai import OpenAI
        
        # æ„å»ºç®€æ´çš„ Prompt
        prompt = f"""è¯·å»ºç«‹é¡¹ç›®çº§ç»´åº¦ä¸äº§å“çº§ç»´åº¦çš„æ˜ å°„å…³ç³»ã€‚

## é¡¹ç›®çº§ç»´åº¦ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼‰
{json.dumps(project_dims, ensure_ascii=False, indent=2)}

## äº§å“çº§ç»´åº¦ï¼ˆæŒ‰äº§å“IDç»„ç»‡ï¼‰
{json.dumps(product_dims, ensure_ascii=False, indent=2)}

## ä»»åŠ¡
å¯¹äºæ¯ä¸ªé¡¹ç›®çº§ç»´åº¦ï¼Œæ‰¾å‡ºè¯­ä¹‰ç›¸è¿‘çš„äº§å“çº§ç»´åº¦ã€‚ä¸€ä¸ªé¡¹ç›®ç»´åº¦å¯ä»¥æ˜ å°„å¤šä¸ªäº§å“ç»´åº¦ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
```json
{{
  "ç»´åº¦ç±»å‹": {{
    "é¡¹ç›®ç»´åº¦å": [
      {{"product_id": "xxx", "dimension_name": "äº§å“ç»´åº¦å"}},
      ...
    ]
  }}
}}
```

è¯·ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²éƒ½ç”¨åŒå¼•å·åŒ…è£¹ï¼ŒJSON æ ¼å¼å®Œæ•´ã€‚"""

        try:
            client = OpenAI(
                api_key=settings.QWEN_API_KEY,
                base_url=settings.QWEN_API_BASE,
                timeout=60.0
            )
            
            response = client.chat.completions.create(
                model=settings.QWEN_MODEL,  # ä½¿ç”¨æ™®é€šæ¨¡å‹å³å¯
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ˜ å°„ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼Œç¡®ä¿ï¼š1) æ‰€æœ‰å­—ç¬¦ä¸²éƒ½ç”¨åŒå¼•å·åŒ…è£¹ï¼›2) å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚æ¢è¡Œç¬¦ã€å¼•å·ï¼‰è¦æ­£ç¡®è½¬ä¹‰ï¼›3) JSON æ ¼å¼å®Œæ•´ä¸”æœ‰æ•ˆï¼›4) ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ï¼Œåªè¾“å‡º JSONã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=4000  # å¢åŠ  token é™åˆ¶ï¼Œé¿å…æˆªæ–­
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # è®°å½•åŸå§‹è¿”å›å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.debug(f"ç»´åº¦æ˜ å°„ AI è¿”å›é•¿åº¦: {len(result_text)} å­—ç¬¦")
            if len(result_text) > 500:
                logger.debug(f"ç»´åº¦æ˜ å°„ AI è¿”å›å‰ 500 å­—ç¬¦: {result_text[:500]}")
            
            # ä½¿ç”¨å®‰å…¨çš„ JSON è§£æ
            parsed = self._safe_parse_json(result_text)
            
            if not parsed:
                logger.warning(f"ç»´åº¦æ˜ å°„ï¼šJSON è§£æå¤±è´¥ï¼Œè¿”å›ç©ºæ˜ å°„ã€‚åŸå§‹è¿”å›é•¿åº¦: {len(result_text)}")
                # è®°å½•æ›´å¤šè°ƒè¯•ä¿¡æ¯
                if len(result_text) > 1000:
                    logger.warning(f"åŸå§‹è¿”å›å‰ 1000 å­—ç¬¦: {result_text[:1000]}")
                else:
                    logger.warning(f"å®Œæ•´åŸå§‹è¿”å›: {result_text}")
                return {}
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            mappings = {}
            for dim_type, type_mappings in parsed.items():
                if not isinstance(type_mappings, dict):
                    continue
                mappings[dim_type] = []
                for project_dim_name, product_mappings in type_mappings.items():
                    if not isinstance(product_mappings, list):
                        continue
                    for pm in product_mappings:
                        if isinstance(pm, dict):
                            mappings[dim_type].append({
                                "project_dimension_name": project_dim_name,
                                "product_id": pm.get("product_id"),
                                "product_dimension_name": pm.get("dimension_name")
                            })
            
            return mappings
            
        except Exception as e:
            logger.error(f"ç»´åº¦æ˜ å°„ AI è°ƒç”¨å¤±è´¥: {e}")
            return {}
    
    async def _call_ai_for_label_mapping(
        self,
        project_labels: Dict[str, List[str]],
        product_labels: Dict[str, Dict[str, List[str]]]
    ) -> Dict[str, List[Dict]]:
        """
        è°ƒç”¨ AI å»ºç«‹æ ‡ç­¾æ˜ å°„
        
        è¾“å…¥æ•°æ®é‡å¾ˆå°ï¼šåªæœ‰æ ‡ç­¾åç§°åˆ—è¡¨
        """
        from openai import OpenAI
        
        # æ„å»ºç®€æ´çš„ Prompt
        prompt = f"""è¯·å»ºç«‹é¡¹ç›®çº§5Wæ ‡ç­¾ä¸äº§å“çº§5Wæ ‡ç­¾çš„æ˜ å°„å…³ç³»ã€‚

## é¡¹ç›®çº§æ ‡ç­¾ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼‰
{json.dumps(project_labels, ensure_ascii=False, indent=2)}

## äº§å“çº§æ ‡ç­¾ï¼ˆæŒ‰äº§å“IDç»„ç»‡ï¼‰
{json.dumps(product_labels, ensure_ascii=False, indent=2)}

## ä»»åŠ¡
å¯¹äºæ¯ä¸ªé¡¹ç›®çº§æ ‡ç­¾ï¼Œæ‰¾å‡ºè¯­ä¹‰ç›¸è¿‘çš„äº§å“çº§æ ‡ç­¾ï¼ˆåŒç±»å‹å†…åŒ¹é…ï¼‰ã€‚ä¸€ä¸ªé¡¹ç›®æ ‡ç­¾å¯ä»¥æ˜ å°„å¤šä¸ªäº§å“æ ‡ç­¾ã€‚

## è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
```json
{{
  "æ ‡ç­¾ç±»å‹": {{
    "é¡¹ç›®æ ‡ç­¾å": [
      {{"product_id": "xxx", "label_name": "äº§å“æ ‡ç­¾å"}},
      ...
    ]
  }}
}}
```

è¯·ç›´æ¥è¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚ç¡®ä¿æ‰€æœ‰å­—ç¬¦ä¸²éƒ½ç”¨åŒå¼•å·åŒ…è£¹ï¼ŒJSON æ ¼å¼å®Œæ•´ã€‚"""

        try:
            client = OpenAI(
                api_key=settings.QWEN_API_KEY,
                base_url=settings.QWEN_API_BASE,
                timeout=60.0
            )
            
            response = client.chat.completions.create(
                model=settings.QWEN_MODEL,  # ä½¿ç”¨æ™®é€šæ¨¡å‹å³å¯
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ˜ å°„ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºï¼Œç¡®ä¿ï¼š1) æ‰€æœ‰å­—ç¬¦ä¸²éƒ½ç”¨åŒå¼•å·åŒ…è£¹ï¼›2) å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼ˆå¦‚æ¢è¡Œç¬¦ã€å¼•å·ï¼‰è¦æ­£ç¡®è½¬ä¹‰ï¼›3) JSON æ ¼å¼å®Œæ•´ä¸”æœ‰æ•ˆï¼›4) ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–æ–‡å­—ï¼Œåªè¾“å‡º JSONã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=4000  # å¢åŠ  token é™åˆ¶ï¼Œé¿å…æˆªæ–­
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # è®°å½•åŸå§‹è¿”å›å†…å®¹ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            logger.debug(f"æ ‡ç­¾æ˜ å°„ AI è¿”å›é•¿åº¦: {len(result_text)} å­—ç¬¦")
            if len(result_text) > 500:
                logger.debug(f"æ ‡ç­¾æ˜ å°„ AI è¿”å›å‰ 500 å­—ç¬¦: {result_text[:500]}")
            
            # ä½¿ç”¨å®‰å…¨çš„ JSON è§£æ
            parsed = self._safe_parse_json(result_text)
            
            if not parsed:
                logger.warning(f"æ ‡ç­¾æ˜ å°„ï¼šJSON è§£æå¤±è´¥ï¼Œè¿”å›ç©ºæ˜ å°„ã€‚åŸå§‹è¿”å›é•¿åº¦: {len(result_text)}")
                # è®°å½•æ›´å¤šè°ƒè¯•ä¿¡æ¯
                if len(result_text) > 1000:
                    logger.warning(f"åŸå§‹è¿”å›å‰ 1000 å­—ç¬¦: {result_text[:1000]}")
                else:
                    logger.warning(f"å®Œæ•´åŸå§‹è¿”å›: {result_text}")
                return {}
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            mappings = {}
            for label_type, type_mappings in parsed.items():
                if not isinstance(type_mappings, dict):
                    continue
                mappings[label_type] = []
                for project_label_name, product_mappings in type_mappings.items():
                    if not isinstance(product_mappings, list):
                        continue
                    for pm in product_mappings:
                        if isinstance(pm, dict):
                            mappings[label_type].append({
                                "project_label_name": project_label_name,
                                "product_id": pm.get("product_id"),
                                "product_label_name": pm.get("label_name")
                            })
            
            return mappings
            
        except Exception as e:
            logger.error(f"æ ‡ç­¾æ˜ å°„ AI è°ƒç”¨å¤±è´¥: {e}")
            return {}
    
    async def _save_project_learning_result(
        self,
        project_id: UUID,
        product_ids: List[UUID],
        project_dimensions: Dict[str, List[Dict]],
        project_labels: Dict[str, List[Dict]],
        dimension_mappings: Dict[str, List[Dict]],
        label_mappings: Dict[str, List[Dict]],
        products_data: Dict[str, Dict]
    ):
        """å­˜å‚¨é¡¹ç›®çº§å­¦ä¹ ç»“æœåˆ°æ•°æ®åº“"""
        
        # å…ˆæ¸…é™¤æ—§æ•°æ®
        await self.db.execute(
            delete(ProjectDimension).where(ProjectDimension.project_id == project_id)
        )
        await self.db.execute(
            delete(ProjectContextLabel).where(ProjectContextLabel.project_id == project_id)
        )
        
        # æ„å»ºäº§å“ç»´åº¦/æ ‡ç­¾çš„åç§° -> ID æ˜ å°„
        product_dim_id_map = {}  # {product_id: {name: dimension_id}}
        product_label_id_map = {}  # {product_id: {type: {name: label_id}}}
        
        for product_id_str, data in products_data.items():
            product_dim_id_map[product_id_str] = {}
            for dim_type, dims in data.get('dimensions', {}).items():
                for d in dims:
                    product_dim_id_map[product_id_str][d['name']] = d['id']
            
            product_label_id_map[product_id_str] = {}
            for label_type, labels in data.get('labels', {}).items():
                product_label_id_map[product_id_str][label_type] = {}
                for l in labels:
                    product_label_id_map[product_id_str][label_type][l['name']] = l['id']
        
        # ä¿å­˜é¡¹ç›®çº§ç»´åº¦
        project_dim_id_map = {}  # {dim_type: {name: project_dim_id}}
        for dim_type, dims in project_dimensions.items():
            project_dim_id_map[dim_type] = {}
            for dim_data in dims:
                project_dim = ProjectDimension(
                    project_id=project_id,
                    name=dim_data['name'],
                    description=dim_data.get('description', ''),
                    dimension_type=dim_type,
                    is_ai_generated=True
                )
                self.db.add(project_dim)
                await self.db.flush()
                project_dim_id_map[dim_type][dim_data['name']] = project_dim.id
        
        # ä¿å­˜ç»´åº¦æ˜ å°„
        for dim_type, mappings in dimension_mappings.items():
            for mapping in mappings:
                project_dim_name = mapping.get('project_dimension_name')
                product_id_str = mapping.get('product_id')
                product_dim_name = mapping.get('product_dimension_name')
                
                project_dim_id = project_dim_id_map.get(dim_type, {}).get(project_dim_name)
                product_dim_id = product_dim_id_map.get(product_id_str, {}).get(product_dim_name)
                
                if project_dim_id and product_dim_id:
                    dim_mapping = ProjectDimensionMapping(
                        project_dimension_id=project_dim_id,
                        product_dimension_id=UUID(product_dim_id),
                        product_id=UUID(product_id_str)
                    )
                    self.db.add(dim_mapping)
        
        # ä¿å­˜é¡¹ç›®çº§æ ‡ç­¾
        project_label_id_map = {}  # {label_type: {name: project_label_id}}
        for label_type, labels in project_labels.items():
            project_label_id_map[label_type] = {}
            for label_data in labels:
                project_label = ProjectContextLabel(
                    project_id=project_id,
                    type=label_type,
                    name=label_data['name'],
                    description=label_data.get('description', ''),
                    is_ai_generated=True
                )
                self.db.add(project_label)
                await self.db.flush()
                project_label_id_map[label_type][label_data['name']] = project_label.id
        
        # ä¿å­˜æ ‡ç­¾æ˜ å°„
        for label_type, mappings in label_mappings.items():
            for mapping in mappings:
                project_label_name = mapping.get('project_label_name')
                product_id_str = mapping.get('product_id')
                product_label_name = mapping.get('product_label_name')
                
                project_label_id = project_label_id_map.get(label_type, {}).get(project_label_name)
                product_label_id = (
                    product_label_id_map
                    .get(product_id_str, {})
                    .get(label_type, {})
                    .get(product_label_name)
                )
                
                if project_label_id and product_label_id:
                    label_mapping = ProjectLabelMapping(
                        project_label_id=project_label_id,
                        product_label_id=UUID(product_label_id),
                        product_id=UUID(product_id_str)
                    )
                    self.db.add(label_mapping)
        
        await self.db.commit()
        logger.info(f"âœ… é¡¹ç›®çº§å­¦ä¹ ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“")
    
    async def check_products_analysis_status(
        self,
        product_ids: List[UUID]
    ) -> Dict[str, Dict]:
        """
        æ£€æŸ¥å¤šä¸ªäº§å“çš„åˆ†æå®ŒæˆçŠ¶æ€
        
        å¸‚åœºæ´å¯Ÿéœ€è¦æ‰€æœ‰äº§å“éƒ½å·²å®Œæˆåˆ†æï¼ˆæœ‰ç»´åº¦å’Œæ ‡ç­¾ï¼‰
        """
        result = {}
        
        for product_id in product_ids:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç»´åº¦
            dim_count = await self.db.execute(
                select(func.count(ProductDimension.id))
                .where(ProductDimension.product_id == product_id)
            )
            has_dimensions = (dim_count.scalar() or 0) > 0
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾
            label_count = await self.db.execute(
                select(func.count(ProductContextLabel.id))
                .where(ProductContextLabel.product_id == product_id)
            )
            has_labels = (label_count.scalar() or 0) > 0
            
            # è·å–äº§å“ä¿¡æ¯
            product_result = await self.db.execute(
                select(Product.asin, Product.title)
                .where(Product.id == product_id)
            )
            product = product_result.first()
            
            result[str(product_id)] = {
                "asin": product.asin if product else "Unknown",
                "title": product.title if product else "Unknown",
                "has_dimensions": has_dimensions,
                "has_labels": has_labels,
                "is_ready": has_dimensions and has_labels
            }
        
        return result
    
    async def get_incomplete_products(
        self,
        product_ids: List[UUID]
    ) -> List[Dict]:
        """è·å–æœªå®Œæˆåˆ†æçš„äº§å“åˆ—è¡¨"""
        status = await self.check_products_analysis_status(product_ids)
        incomplete = [
            {"product_id": pid, **info}
            for pid, info in status.items()
            if not info["is_ready"]
        ]
        return incomplete
