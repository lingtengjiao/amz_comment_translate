"""
Summary Service - æ™ºèƒ½æŠ¥å‘Šç”Ÿæˆæ¨¡å— (Report Generation Module)

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ•°æ®èšåˆ (Data Gathering): ä»æ•°æ®åº“ä¸­èšåˆ Insightsï¼ˆç»´åº¦æ•°æ®ï¼‰å’Œ ThemeHighlightsï¼ˆ5W æ•°æ®ï¼‰
2. ç»Ÿè®¡ç”»åƒ (Profiling): è®¡ç®— Top N äººç¾¤ã€åœºæ™¯ã€åŠ¨æœºç­‰
3. ç—›ç‚¹å…³è” (Correlation): æ‰¾å‡ºæœ€æ˜¾è‘—çš„ç—›ç‚¹å’Œçˆ½ç‚¹
4. AI æ’°å†™ (Drafting): å°†ç»“æ„åŒ–æ•°æ®å¡«å…¥ Promptï¼Œè®© LLM ç”Ÿæˆ JSON æ ¼å¼çš„ç»“æ„åŒ–æŠ¥å‘Š
5. æŒä¹…åŒ–å­˜å‚¨ (Persistence): å°†æŠ¥å‘Šå­˜å…¥æ•°æ®åº“ï¼Œæ”¯æŒå†å²å›æº¯

æ”¯æŒå››ç§æŠ¥å‘Šç±»å‹ï¼ˆå››ä½ä¸€ä½“å†³ç­–ä¸­å°ï¼‰ï¼š
- COMPREHENSIVE: CEO/ç»¼åˆæˆ˜ç•¥ç‰ˆ
- OPERATIONS: CMO/è¿è¥å¸‚åœºç‰ˆ
- PRODUCT: CPO/äº§å“ç ”å‘ç‰ˆ
- SUPPLY_CHAIN: ä¾›åº”é“¾/è´¨æ£€ç‰ˆ

ä¾èµ–ï¼š
- ReviewInsight æ¨¡å‹ (ç»´åº¦æ´å¯Ÿ)
- ReviewThemeHighlight æ¨¡å‹ (5W ä¸»é¢˜)
- ProductReport æ¨¡å‹ (æŠ¥å‘Šå­˜å‚¨)
- TranslationService (LLM è°ƒç”¨)
"""
import logging
import json
from collections import defaultdict, Counter
from datetime import datetime
from typing import Optional, List, Dict, Any
from uuid import UUID

from sqlalchemy import select, func, and_, desc
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.review import Review, TranslationStatus
from app.models.insight import ReviewInsight
from app.models.theme_highlight import ReviewThemeHighlight, ThemeType
from app.models.product import Product
from app.models.report import ProductReport, ReportType, ReportStatus
from app.services.translation import translation_service

logger = logging.getLogger(__name__)


# ==========================================
# [PROMPT CONFIGURATION] è§’è‰²åŒ–æŒ‡ä»¤åº“ (JSONæ¨¡å¼)
# ==========================================

COMMON_INSTRUCTION = """
# è¾“å‡ºæ ¼å¼è¦æ±‚ (CRITICAL)
1. **å¿…é¡»ä¸¥æ ¼ä»…è¾“å‡ºåˆæ³•çš„ JSON æ ¼å¼**ã€‚
2. **ä¸¥ç¦**åŒ…å« markdown ä»£ç å—æ ‡è®° (å¦‚ ```json ... ```)ã€‚
3. **ä¸¥ç¦**åœ¨ JSON å‰åæ·»åŠ ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
4. è¯­è¨€é£æ ¼ï¼šä¸“ä¸šã€æ•°æ®é©±åŠ¨ã€å®¢è§‚ã€‚ä½¿ç”¨ä¸­æ–‡è¾“å‡ºã€‚

# ğŸ”— è¯æ®å¼•ç”¨è§„èŒƒï¼ˆCRITICAL - å¿…é¡»éµå®ˆï¼‰

## ç½®ä¿¡åº¦è¯„ä¼°æ ‡å‡†
æ¯ä¸ªåˆ†æç»“è®ºå¿…é¡»æ ‡æ³¨ `confidence` å­—æ®µï¼š
- **"high"**: â‰¥5æ¡è¯„è®ºæ˜ç¡®æ”¯æŒ + æ•°æ®å æ¯”â‰¥15%ï¼Œè¯æ®ç›´æ¥æ˜ç¡®
- **"medium"**: 2-4æ¡è¯„è®ºæ”¯æŒï¼Œæˆ–å æ¯”10-15%ï¼Œéœ€è¦åˆç†æ¨æ–­
- **"low"**: ä»…1æ¡è¯„è®ºæˆ–å æ¯”<10%ï¼Œè¯æ®è¾ƒå¼±ï¼Œæ ‡è®°ä¸º"å‚è€ƒæ€§å»ºè®®"

## è¯æ®å¼•ç”¨è¦æ±‚
1. **æ¯ä¸ªåˆ†æç‚¹å¿…é¡»å¼•ç”¨çœŸå®è¯„è®º**
   - ä»è¾“å…¥æ•°æ®çš„ `evidence` åˆ—è¡¨ä¸­é€‰å– `review_id`
   - ä¸¥ç¦ç¼–é€ ä¸å­˜åœ¨çš„ ID æˆ–å¼•ç”¨å†…å®¹
   - å¦‚æ— è¶³å¤Ÿè¯æ®æ”¯æŒï¼Œåº”é™ä½ç½®ä¿¡åº¦æˆ–ä¸è¾“å‡ºè¯¥ç»“è®º

2. **å¼•ç”¨æ ¼å¼**ï¼ˆé€‚ç”¨äºæ‰€æœ‰å¸¦ source_tag çš„å­—æ®µï¼‰
   ç¤ºä¾‹: {{"point": "åˆ†æç»“è®º", "confidence": "high", "source_tag": "Battery", "evidence": {{"count": 30, "percentage": "23.5%", "sample_ids": ["uuid-1"], "sample_quotes": ["ç”µæ± ç»­èˆªå¾ˆä¹…..."]}}}}

3. **ç¦æ­¢è¡Œä¸º**
   - âŒ ä½¿ç”¨ä¸åœ¨è¾“å…¥æ•°æ®ä¸­çš„ review_id
   - âŒ ç¼–é€ å¼•ç”¨å†…å®¹æˆ–è™šæ„æ•°æ®
   - âŒ ç»™å‡ºæ²¡æœ‰è¯æ®æ”¯æŒçš„å¼ºç»“è®º
   - âŒ åœ¨è¯æ®ä¸è¶³æ—¶ä½¿ç”¨ "high" ç½®ä¿¡åº¦

4. **ä¸“ä¸šæ€§è¦æ±‚**
   - å¼•ç”¨å…·ä½“æ•°æ®ï¼ˆæ ·æœ¬é‡ã€ç™¾åˆ†æ¯”ã€è¶‹åŠ¿ï¼‰
   - ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼ˆPMFã€NPSã€JTBDã€CACã€LTVï¼‰
   - è¿›è¡Œäº¤å‰åˆ†æï¼ˆç»“åˆç”¨æˆ·ç”»åƒå’Œç—›ç‚¹ï¼‰
   - ç»™å‡ºå¯æ‰§è¡Œå»ºè®®ï¼ˆæ˜ç¡®è´£ä»»äººã€ä¼˜å…ˆçº§ï¼‰
"""

# ------------------------------------------------------------------
# 1. [CEO/ç»¼åˆç‰ˆ] å…¨å±€æˆ˜ç•¥è§†è§’
# ------------------------------------------------------------------
COMPREHENSIVE_PROMPT = """ä½ æ˜¯ä¸€ä½**ä¼ä¸šCEOå…¼æˆ˜ç•¥é¡¾é—®**ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„ç”µå•†äº§å“åˆ†æç»éªŒã€‚è¯·åŸºäº"ç”¨æˆ·ç”»åƒ(5W)"å’Œ"å£ç¢‘æ´å¯Ÿ(5ç±»)"æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½**æ·±åº¦å…¨å±€æˆ˜ç•¥åˆ†ææŠ¥å‘Š** (JSON)ã€‚

# æ ¸å¿ƒç›®æ ‡
è¯„ä¼°äº§å“ä¸å¸‚åœºçš„åŒ¹é…åº¦(PMF)ï¼Œè¯†åˆ«æ ¸å¿ƒå¢é•¿ç‚¹ä¸è‡´å‘½é£é™©ï¼Œåˆ¶å®šå¯æ‰§è¡Œçš„å…¨ç›˜ç­–ç•¥ã€‚

# è¾“å…¥æ•°æ®
{stats_text}

# å¿…å¡«å­—æ®µ (JSON Key)

## A. ç”¨æˆ·ç”»åƒæ·±åº¦åˆ†æ (åŸºäº 5W Context æ•°æ®)
1. "user_profile": (Object) ç”¨æˆ·ç”»åƒæ·±åº¦åˆ†æã€‚æ ¼å¼:
   {{
     "core_buyers": {{
       "description": (String) **è´­ä¹°è€…ç¾¤ä½“**æè¿°ï¼ˆç»“åˆ Buyer æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{
         "count": æ•°å­—,
         "percentage": "ç™¾åˆ†æ¯”",
         "sample_ids": ["uuid-1", "uuid-2"],
         "sample_quotes": ["å¼•ç”¨1...", "å¼•ç”¨2..."]
       }}
     }},
     "core_users": {{
       "description": (String) **ä½¿ç”¨è€…ç¾¤ä½“**æè¿°ï¼ˆç»“åˆ User æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "user_characteristics": (Array) ç”¨æˆ·ç‰¹å¾æ ‡ç­¾ ["..."],
     "usage_scenarios": {{
       "description": (String) å…¸å‹ä½¿ç”¨åœºæ™¯æè¿°ï¼ˆç»“åˆ Where/When æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "purchase_motivation": {{
       "description": (String) ä¸»è¦è´­ä¹°åŠ¨æœºåˆ†æï¼ˆç»“åˆ Why æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "jobs_to_be_done": {{
       "description": (String) ç”¨æˆ·æ ¸å¿ƒä»»åŠ¡/JTBDï¼ˆç»“åˆ What æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "persona_insight": (String) ä¸€å¥è¯ç”¨æˆ·ç”»åƒæ€»ç»“ï¼ˆéœ€æ˜ç¡®åŒºåˆ†è´­ä¹°è€…å’Œä½¿ç”¨è€…ï¼‰
   }}

## B. æˆ˜ç•¥åˆ†æ
2. "strategic_verdict": {{
     "summary": (String) 3-5å¥è¯çš„æˆ˜ç•¥å®šè°ƒï¼ŒåŒ…å«ï¼šå½“å‰å¸‚åœºå®šä½è¯„ä¼°ã€æ ¸å¿ƒç«äº‰åŠ›ã€ä¸»è¦é£é™©ã€æˆ˜ç•¥å»ºè®®,
     "pmf_score": (Integer) äº§å“å¸‚åœºåŒ¹é…åº¦è¯„åˆ† 0-100,
     "pmf_analysis": (String) PMF è¯„åˆ†ä¾æ®
   }}

3. "market_fit_analysis": {{
     "current_positioning": (String) å½“å‰äº§å“å®šä½,
     "ideal_positioning": (String) åŸºäºç”¨æˆ·åé¦ˆçš„ç†æƒ³å®šä½,
     "gap_analysis": (String) å®šä½å·®è·åˆ†æ,
     "recommendations": (Array) è°ƒæ•´å»ºè®® ["..."]
   }}

4. "core_swot": (Object) SWOTåˆ†æï¼Œ**æ¯é¡¹å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   {{
     "strengths": [{{
       "point": "...", 
       "source_tag": "Battery",
       "confidence": "high|medium|low",
       "evidence": {{
         "count": 30,
         "percentage": "23.5%",
         "sample_ids": ["uuid-1", "uuid-2"],
         "sample_quotes": ["ç”µæ± ç»­èˆªå¾ˆå¥½...", "å……ç”µä¸€æ¬¡ç”¨ä¸‰å¤©..."]
       }}
     }}],
     "weaknesses": [{{...åŒä¸Šæ ¼å¼...}}],
     "opportunities": [{{
       "point": "...",
       "source_tag": "å¯é€‰",
       "rationale": "æœºä¼šåˆ†æä¾æ®"
     }}],
     "threats": [{{
       "point": "...",
       "source_tag": "å¯é€‰", 
       "rationale": "å¨èƒåˆ†æä¾æ®"
     }}]
   }}

5. "department_directives": (Object) ç»™å„éƒ¨é—¨çš„è¯¦ç»†æŒ‡ä»¤ã€‚æ ¼å¼: 
   {{
     "to_marketing": {{
       "directive": "ä¸€å¥è¯æŒ‡ä»¤",
       "key_actions": ["å…·ä½“è¡ŒåŠ¨1", "å…·ä½“è¡ŒåŠ¨2"],
       "kpi": "è¡¡é‡æŒ‡æ ‡"
     }},
     "to_product": {{...åŒä¸Šæ ¼å¼...}},
     "to_supply_chain": {{...åŒä¸Šæ ¼å¼...}},
     "to_customer_service": {{...åŒä¸Šæ ¼å¼...}}
   }}

6. "priority_actions": (Array) Top 5 ä¼˜å…ˆè¡ŒåŠ¨é¡¹ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "action": "å…·ä½“è¡ŒåŠ¨æè¿°",
     "owner": "è´£ä»»éƒ¨é—¨",
     "priority": "P0/P1/P2",
     "deadline": "å»ºè®®æ—¶é—´çº¿",
     "expected_impact": "é¢„æœŸå½±å“",
     "confidence": "high|medium|low",
     "source_tag": "å…³è”æ ‡ç­¾",
     "evidence": {{
       "count": æ•°å­—,
       "percentage": "ç™¾åˆ†æ¯”",
       "sample_ids": ["uuid-1"],
       "sample_quotes": ["ç›¸å…³å¼•ç”¨..."]
     }}
   }}]

7. "risk_assessment": {{
     "overall_level": (String) "low|medium|high|critical",
     "key_risks": [{{
       "risk": "é£é™©æè¿°",
       "probability": "high|medium|low",
       "impact": "high|medium|low",
       "mitigation": "ç¼“è§£æªæ–½",
       "source_tag": "å…³è”ç—›ç‚¹æ ‡ç­¾",
       "confidence": "high|medium|low",
       "evidence": {{...}}
     }}]
   }}

8. "executive_summary": (String) 150å­—ä»¥å†…çš„æ‰§è¡Œæ‘˜è¦ï¼Œä¾›é«˜ç®¡å¿«é€Ÿé˜…è¯»

""" + COMMON_INSTRUCTION

# ------------------------------------------------------------------
# 2. [è¿è¥/å¸‚åœºç‰ˆ] CMOè§†è§’
# ------------------------------------------------------------------
OPERATIONS_PROMPT = """ä½ æ˜¯ä¸€ä½**é¦–å¸­è¥é”€å®˜(CMO)**ï¼Œç²¾é€šç”µå•†è¿è¥å’Œç”¨æˆ·å¢é•¿ã€‚è¯·åŸºäºç»Ÿè®¡æ•°æ®ï¼Œä¸º**è¿è¥å›¢é˜Ÿ**ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„JSONæ ¼å¼ç­–ç•¥æŠ¥å‘Šã€‚

# æ ¸å¿ƒç›®æ ‡
æŒ–æ˜äº§å“å–ç‚¹(Hooks)ï¼Œè§„é¿é€€è´§é£é™©ï¼Œç²¾å‡†å®šä½å¹¿å‘Šå—ä¼—ï¼Œä¼˜åŒ–è½¬åŒ–æ¼æ–—ã€‚

# è¾“å…¥æ•°æ®
{stats_text}

# å¿…å¡«å­—æ®µ (JSON Key)

## A. ç”¨æˆ·ç”»åƒä¸å¸‚åœºå®šä½ (åŸºäº 5W Context æ•°æ®)
1. "user_profile": (Object) ç”¨æˆ·ç”»åƒåˆ†æï¼Œç”¨äºç²¾å‡†è¥é”€ã€‚æ ¼å¼:
   {{
     "primary_buyers": {{
       "description": (String) **ä¸»è¦è´­ä¹°è€…**æè¿°ï¼ˆç»“åˆ Buyer æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{
         "count": æ•°å­—,
         "percentage": "ç™¾åˆ†æ¯”",
         "sample_ids": ["uuid-1", "uuid-2"],
         "sample_quotes": ["å¼•ç”¨1...", "å¼•ç”¨2..."]
       }}
     }},
     "primary_users": {{
       "description": (String) **ä¸»è¦ä½¿ç”¨è€…**æè¿°ï¼ˆç»“åˆ User æ•°æ®ï¼‰ï¼Œ
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "secondary_audience": (String) æ¬¡è¦/æ½œåœ¨äººç¾¤,
     "usage_context": {{
       "description": (String) æ ¸å¿ƒä½¿ç”¨åœºæ™¯æè¿°,
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "buying_triggers": (Array) è´­ä¹°è§¦å‘ç‚¹ ["..."],
     "use_cases": (Array) å…¸å‹ç”¨ä¾‹ ["..."],
     "ad_targeting_keywords": (Array) å¹¿å‘ŠæŠ•æ”¾å…³é”®è¯å»ºè®® ["..."],
     "negative_keywords": (Array) å»ºè®®æ’é™¤çš„å…³é”®è¯ï¼ˆé¿å…é”™è¯¯æµé‡ï¼‰["..."]
   }}

## B. è¥é”€ç­–ç•¥
2. "executive_summary": {{
     "market_status": (String) å¸‚åœºç°çŠ¶3-5å¥è¯æ€»ç»“,
     "key_opportunity": (String) æœ€å¤§æœºä¼šç‚¹,
     "key_risk": (String) æœ€å¤§é£é™©ç‚¹,
     "recommended_action": (String) é¦–è¦å»ºè®®è¡ŒåŠ¨
   }}

3. "selling_points": (Array) æç‚¼5ä¸ªæ ¸å¿ƒå–ç‚¹ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "title": "å–ç‚¹æ ‡é¢˜ï¼ˆå¦‚ï¼šè¶…é•¿ç»­èˆªï¼‰",
     "copywriting": "å¹¿å‘Šæ–‡æ¡ˆå»ºè®®ï¼ˆ50å­—ä»¥å†…ï¼‰",
     "hook": "ä¸€å¥è¯é’©å­ï¼ˆç”¨äºå¹¿å‘Šå¼€å¤´ï¼‰",
     "source_tag": "Battery",
     "confidence": "high|medium|low",
     "evidence": {{
       "count": 30,
       "percentage": "23.5%",
       "sample_ids": ["uuid-1", "uuid-2"],
       "sample_quotes": ["ç”µæ± å¾ˆè€ç”¨...", "å……ç”µä¸€æ¬¡ç”¨ä¸‰å¤©..."]
     }}
   }}]

4. "marketing_risks": (Array) å®¢æœé¢„è­¦ç—›ç‚¹ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "risk": "é£é™©æè¿°",
     "severity": "high|medium|low",
     "talking_points": "å®¢æœè¯æœ¯å»ºè®®",
     "preemptive_action": "é¢„é˜²æªæ–½ï¼ˆå¦‚ï¼šåœ¨Listingä¸­æå‰è¯´æ˜ï¼‰",
     "source_tag": "Battery",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

5. "target_audience": {{
     "primary_segments": [{{
       "segment": "äººç¾¤åç§°",
       "size_estimate": "è§„æ¨¡ä¼°è®¡ï¼ˆå¦‚ï¼šå æ¯”30%ï¼‰",
       "key_messaging": "é’ˆå¯¹æ€§ä¿¡æ¯",
       "confidence": "high|medium|low",
       "evidence": {{...}}
     }}],
     "secondary_segments": ["..."],
     "ad_strategy": {{
       "platform_recommendations": ["æ¨èæŠ•æ”¾å¹³å°"],
       "budget_allocation": "é¢„ç®—åˆ†é…å»ºè®®",
       "creative_direction": "åˆ›æ„æ–¹å‘å»ºè®®"
     }}
   }}

6. "competitor_analysis": {{
     "mentioned_competitors": (Array) ç”¨æˆ·æåˆ°çš„ç«å“ ["..."],
     "our_advantages": (Array) ç›¸æ¯”ç«å“çš„ä¼˜åŠ¿ ["..."],
     "our_disadvantages": (Array) ç›¸æ¯”ç«å“çš„åŠ£åŠ¿ ["..."],
     "differentiation_strategy": (String) å·®å¼‚åŒ–ç­–ç•¥å»ºè®®,
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}

7. "listing_optimization": (Array) Listing ä¼˜åŒ–å»ºè®®ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "element": "Title|Bullets|Images|A+Content|Backend Keywords",
     "current_issue": "å½“å‰é—®é¢˜",
     "suggestion": "ä¼˜åŒ–å»ºè®®",
     "priority": "P0|P1|P2",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

8. "review_response_templates": (Array) å·®è¯„å›å¤æ¨¡æ¿ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "pain_point": "ç—›ç‚¹æè¿°",
     "response_template": "å›å¤æ¨¡æ¿ï¼ˆ100å­—ä»¥å†…ï¼‰",
     "follow_up_action": "åç»­è¡ŒåŠ¨å»ºè®®",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

9. "conversion_funnel_analysis": {{
     "traffic_quality": (String) æµé‡è´¨é‡åˆ†æ,
     "conversion_barriers": (Array) è½¬åŒ–éšœç¢ ["..."],
     "optimization_suggestions": (Array) ä¼˜åŒ–å»ºè®® ["..."]
   }}

""" + COMMON_INSTRUCTION

# ------------------------------------------------------------------
# 3. [äº§å“/ç ”å‘ç‰ˆ] CPOè§†è§’
# ------------------------------------------------------------------
PRODUCT_PROMPT = """ä½ æ˜¯ä¸€ä½**äº§å“æ€»ç›‘(CPO)**ï¼Œä¸“æ³¨äºç”¨æˆ·ä½“éªŒå’Œäº§å“è¿­ä»£ã€‚è¯·åŸºäºç»Ÿè®¡æ•°æ®ï¼Œä¸º**ç ”å‘å›¢é˜Ÿ**ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„JSONæ ¼å¼è¿­ä»£å»ºè®®ä¹¦ã€‚

# æ ¸å¿ƒç›®æ ‡
å‘ç°è®¾è®¡ç¼ºé™·ï¼Œæ˜ç¡®ä¸‹ä¸€ä»£äº§å“(Next-Gen)çš„æ”¹è¿›æ–¹å‘ï¼Œæå‡ç”¨æˆ·æ»¡æ„åº¦ã€‚

# è¾“å…¥æ•°æ®
{stats_text}

# å¿…å¡«å­—æ®µ (JSON Key)

## A. ç”¨æˆ·ç ”ç©¶æ´å¯Ÿ (åŸºäº 5W Context æ•°æ®)
1. "user_research": (Object) ç”¨æˆ·ç ”ç©¶æ´å¯Ÿï¼Œç”¨äºäº§å“è®¾è®¡ã€‚æ ¼å¼:
   {{
     "target_buyers": {{
       "description": (String) **è´­ä¹°è€…ç¾¤ä½“**ç”»åƒ,
       "decision_factors": (Array) è´­ä¹°å†³ç­–å› ç´  ["..."],
       "confidence": "high|medium|low",
       "evidence": {{
         "count": æ•°å­—,
         "percentage": "ç™¾åˆ†æ¯”",
         "sample_ids": ["uuid-1", "uuid-2"],
         "sample_quotes": ["å¼•ç”¨1...", "å¼•ç”¨2..."]
       }}
     }},
     "target_users": {{
       "description": (String) **ä½¿ç”¨è€…ç¾¤ä½“**ç”»åƒ,
       "usage_frequency": (String) ä½¿ç”¨é¢‘ç‡åˆ†æ,
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "user_pain_points_by_group": (Array) æŒ‰ç”¨æˆ·ç±»å‹åˆ†ç±»çš„ç—›ç‚¹:
       [{{
         "user_group": "è€å¹´ç”¨æˆ·",
         "pain_points": ["æŒ‰é”®å¤ªå°", "å­—ä½“çœ‹ä¸æ¸…"],
         "design_implications": "é€‚è€åŒ–è®¾è®¡éœ€æ±‚",
         "confidence": "high|medium|low",
         "evidence": {{...}}
       }}],
     "real_usage_environments": {{
       "environments": (Array) çœŸå®ä½¿ç”¨ç¯å¢ƒ ["è½¦å†…", "åŠå…¬å®¤", "..."],
       "unexpected_scenarios": (Array) è¶…å‡ºè®¾è®¡é¢„æœŸçš„åœºæ™¯ ["..."],
       "confidence": "high|medium|low",
       "evidence": {{...}}
     }},
     "jobs_to_be_done": {{
       "primary_jtbd": (String) æ ¸å¿ƒç”¨æˆ·ä»»åŠ¡,
       "secondary_jtbd": (Array) æ¬¡è¦ä»»åŠ¡ ["..."],
       "unmet_jtbd": (Array) æœªæ»¡è¶³çš„ä»»åŠ¡ ["..."],
       "confidence": "high|medium|low",
       "evidence": {{...}}
     }},
     "expectation_gap": {{
       "user_expectations": (Array) ç”¨æˆ·æœŸæœ› ["..."],
       "current_reality": (Array) äº§å“ç°çŠ¶ ["..."],
       "gap_analysis": (String) å·®è·åˆ†æ
     }}
   }}

## B. äº§å“è´¨é‡è¯„ä¼°
2. "quality_assessment": {{
     "overall_score": (Integer) 0-100åˆ†,
     "scoring_breakdown": {{
       "functionality": (Integer) åŠŸèƒ½æ€§å¾—åˆ† 0-100,
       "usability": (Integer) æ˜“ç”¨æ€§å¾—åˆ† 0-100,
       "reliability": (Integer) å¯é æ€§å¾—åˆ† 0-100,
       "aesthetics": (Integer) å¤–è§‚å¾—åˆ† 0-100
     }},
     "scoring_rationale": (String) è¯„åˆ†ä¾æ®
   }}

3. "critical_bugs": (Array) Top 5 è‡´å‘½ç¼ºé™·ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "issue": "é—®é¢˜æè¿°",
     "severity": "Critical|High|Medium|Low",
     "affected_users": "å—å½±å“ç”¨æˆ·ç¾¤ä½“",
     "frequency": "å‘ç”Ÿé¢‘ç‡ä¼°è®¡",
     "root_cause_hypothesis": "æ ¹å› å‡è®¾",
     "suggested_fix": "å»ºè®®ä¿®å¤æ–¹æ¡ˆ",
     "priority": "P0|P1|P2",
     "source_tag": "Battery",
     "confidence": "high|medium|low",
     "evidence": {{
       "count": 30,
       "percentage": "23.5%",
       "sample_ids": ["uuid-1", "uuid-2"],
       "sample_quotes": ["ç”µæ± ç»å¸¸æ­»æœº...", "ç”¨äº†ä¸¤å‘¨å°±åäº†..."]
     }}
   }}]

4. "unmet_needs": (Array) ç”¨æˆ·æœŸæœ›çš„åŠŸèƒ½ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "feature": "åŠŸèƒ½æè¿°",
     "user_demand_level": "High|Medium|Low",
     "implementation_complexity": "High|Medium|Low",
     "business_value": "High|Medium|Low",
     "recommendation": "å»ºè®®å®ç°æ–¹å¼",
     "priority": "P0|P1|P2",
     "source_tag": "LED Light",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

5. "usage_context_analysis": {{
     "designed_for": (String) äº§å“è®¾è®¡çš„ç›®æ ‡åœºæ™¯,
     "actually_used_for": (Array) å®é™…ä½¿ç”¨åœºæ™¯ ["..."],
     "context_gaps": (Array) åœºæ™¯å·®è· ["..."],
     "design_adaptations_needed": (Array) éœ€è¦çš„è®¾è®¡è°ƒæ•´ ["..."],
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}

6. "product_roadmap": {{
     "next_version_focus": (String) ä¸‹ç‰ˆæœ¬æ ¸å¿ƒæ–¹å‘,
     "short_term_fixes": (Array) çŸ­æœŸä¿®å¤é¡¹ï¼ˆ1ä¸ªæœˆå†…ï¼‰["..."],
     "medium_term_improvements": (Array) ä¸­æœŸæ”¹è¿›é¡¹ï¼ˆ3ä¸ªæœˆå†…ï¼‰["..."],
     "long_term_innovations": (Array) é•¿æœŸåˆ›æ–°é¡¹ï¼ˆ6ä¸ªæœˆ+ï¼‰["..."],
     "version_naming_suggestion": (String) ç‰ˆæœ¬å‘½åå»ºè®®ï¼ˆå¦‚ V2.0 - é€‚è€åŒ–å‡çº§ç‰ˆï¼‰
   }}

7. "usability_issues": (Array) æ˜“ç”¨æ€§é—®é¢˜ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "issue": "é—®é¢˜æè¿°",
     "affected_user_group": "å—å½±å“ç¾¤ä½“",
     "impact_level": "High|Medium|Low",
     "current_workaround": "ç”¨æˆ·å½“å‰çš„è§£å†³æ–¹æ³•ï¼ˆå¦‚æœæœ‰ï¼‰",
     "suggested_improvement": "æ”¹è¿›å»ºè®®",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

8. "design_recommendations": (Array) è®¾è®¡æ”¹è¿›å»ºè®®ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "area": "æ”¹è¿›é¢†åŸŸï¼ˆå¦‚ï¼šæŒ‰é’®è®¾è®¡ã€åŒ…è£…ã€è¯´æ˜ä¹¦ï¼‰",
     "current_state": "å½“å‰çŠ¶æ€",
     "user_feedback": "ç”¨æˆ·åé¦ˆæ‘˜è¦",
     "recommendation": "æ”¹è¿›å»ºè®®",
     "expected_impact": "é¢„æœŸå½±å“",
     "priority": "P0|P1|P2",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

9. "competitive_feature_gap": {{
     "features_users_expect": (Array) ç”¨æˆ·æœŸæœ›æˆ‘ä»¬æœ‰çš„åŠŸèƒ½ï¼ˆå¯èƒ½æ¥è‡ªç«å“ï¼‰["..."],
     "our_unique_advantages": (Array) æˆ‘ä»¬çš„ç‹¬ç‰¹ä¼˜åŠ¿ ["..."],
     "recommendations": (Array) åŠŸèƒ½å·®è·å»ºè®® ["..."]
   }}

""" + COMMON_INSTRUCTION

# ------------------------------------------------------------------
# 4. [ä¾›åº”é“¾/è´¨æ£€ç‰ˆ] ä¾›åº”é“¾æ€»ç›‘è§†è§’
# ------------------------------------------------------------------
SUPPLY_CHAIN_PROMPT = """ä½ æ˜¯ä¸€ä½**ä¾›åº”é“¾æ€»ç›‘**ï¼Œä¸“æ³¨äºè´¨é‡ç®¡ç†å’Œæˆæœ¬æ§åˆ¶ã€‚è¯·åŸºäºç»Ÿè®¡æ•°æ®ï¼Œä¸º**å·¥å‚å’ŒQCå›¢é˜Ÿ**ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„JSONæ ¼å¼è´¨é‡æ•´æ”¹æŠ¥å‘Šã€‚

# æ ¸å¿ƒç›®æ ‡
é™ä½é€€è´§ç‡(Return Rate)ï¼Œä¼˜åŒ–åŒ…è£…ï¼Œè¿½è´£ä¾›åº”å•†ï¼Œæå‡å‡ºå‚è‰¯å“ç‡ã€‚

# è¾“å…¥æ•°æ®
{stats_text}

# å¿…å¡«å­—æ®µ (JSON Key)

## A. ä½¿ç”¨åœºæ™¯ä¸è´¨é‡éœ€æ±‚ (åŸºäº 5W Context æ•°æ®)
1. "usage_context_analysis": (Object) ä½¿ç”¨ç¯å¢ƒåˆ†æï¼Œç”¨äºè´¨é‡æ ‡å‡†åˆ¶å®šã€‚æ ¼å¼:
   {{
     "buyer_groups": {{
       "description": (String) **è´­ä¹°è€…ç¾¤ä½“**ç”»åƒ,
       "quality_expectations": (Array) è´­ä¹°è€…çš„è´¨é‡æœŸæœ› ["..."],
       "confidence": "high|medium|low",
       "evidence": {{
         "count": æ•°å­—,
         "percentage": "ç™¾åˆ†æ¯”",
         "sample_ids": ["uuid-1", "uuid-2"],
         "sample_quotes": ["å¼•ç”¨1...", "å¼•ç”¨2..."]
       }}
     }},
     "user_groups": {{
       "description": (String) **ä½¿ç”¨è€…ç¾¤ä½“**ç”»åƒ,
       "special_requirements": (Array) ç‰¹æ®Šè´¨é‡è¦æ±‚ï¼ˆå¦‚å„¿ç«¥å®‰å…¨ã€è€äººæ˜“ç”¨ï¼‰["..."],
       "confidence": "high|medium|low",
       "evidence": {{...åŒä¸Šæ ¼å¼...}}
     }},
     "usage_environments": {{
       "environments": (Array) ä¸»è¦ä½¿ç”¨ç¯å¢ƒ ["æˆ·å¤–", "æ½®æ¹¿ç¯å¢ƒ", "..."],
       "environmental_stress_factors": (Array) ç¯å¢ƒå‹åŠ›å› ç´  ["é«˜æ¸©", "éœ‡åŠ¨", "..."],
       "quality_implications": (String) å¯¹è´¨é‡æ ‡å‡†çš„å½±å“,
       "confidence": "high|medium|low",
       "evidence": {{...}}
     }},
     "usage_intensity": {{
       "frequency": (String) ä½¿ç”¨é¢‘ç‡åˆ†æ,
       "duration": (String) å•æ¬¡ä½¿ç”¨æ—¶é•¿,
       "durability_requirements": (Array) è€ä¹…æ€§è¦æ±‚ ["..."],
       "confidence": "high|medium|low",
       "evidence": {{...}}
     }}
   }}

## B. è´¨é‡é—®é¢˜åˆ†æ
2. "quality_summary": {{
     "summary": (String) è´¨é‡æ¦‚å†µæ€»ç»“æ–‡æœ¬,
     "confidence": (String) "high"|"medium"|"low",
     "evidence": (Array) è¯æ®å¼•ç”¨ [{{"review_id": "...", "quote": "..."}}],
     "overall_quality_score": (Integer) **å¿…å¡«** 0-100åˆ†è´¨é‡è¯„åˆ†ï¼ŒåŸºäºè´Ÿé¢åé¦ˆæ¯”ä¾‹å’Œä¸¥é‡ç¨‹åº¦è®¡ç®—,
     "estimated_return_rate": (String) **å¿…å¡«** ä¼°è®¡é€€è´§ç‡ï¼ˆå¦‚"15-20%"ï¼‰ï¼ŒåŸºäºé€€è´§åŸå› åˆ†æ,
     "top_quality_issues": (Array) Top 3 è´¨é‡é—®é¢˜æ¦‚è¦ ["..."],
     "improvement_priority": (String) ä¼˜å…ˆæ”¹è¿›æ–¹å‘
   }}

3. "material_defects": (Array) æè´¨åšå·¥é—®é¢˜ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "part": "éƒ¨ä»¶åç§°ï¼ˆå¦‚ï¼šå¤–å£³ã€æŒ‰é”®ã€å¯†å°åœˆï¼‰",
     "problem": "é—®é¢˜æè¿°",
     "frequency": "High|Medium|Low",
     "affected_percentage": "å—å½±å“æ¯”ä¾‹ä¼°è®¡",
     "root_cause_hypothesis": "æ ¹å› å‡è®¾",
     "suggested_fix": "å»ºè®®ä¿®å¤æ–¹æ¡ˆ",
     "supplier_action": "ä¾›åº”å•†æ•´æ”¹è¦æ±‚",
     "source_tag": "Build Quality",
     "confidence": "high|medium|low",
     "evidence": {{
       "count": æ•°å­—,
       "percentage": "ç™¾åˆ†æ¯”",
       "sample_ids": ["uuid-1", "uuid-2"],
       "sample_quotes": ["å¡‘æ–™æ„Ÿå¾ˆå¼º...", "ç”¨äº†ä¸¤å‘¨å°±è£‚äº†..."]
     }}
   }}]

4. "packaging_issues": {{
     "has_damage_reports": (Boolean) æ˜¯å¦æœ‰åŒ…è£…æŸåæŠ¥å‘Š,
     "damage_types": (Array) æŸåç±»å‹ ["è¿è¾“ç ´æŸ", "åŒ…è£…ä¸è¶³", "..."],
     "current_packaging": (String) å½“å‰åŒ…è£…æè¿°,
     "improvement_suggestions": (Array) æ”¹è¿›å»ºè®® ["åŠ åšæ³¡æ²«", "å¢åŠ è§’ä¿æŠ¤", "..."],
     "cost_impact_estimate": (String) æˆæœ¬å½±å“ä¼°è®¡,
     "source_tag": "Packaging",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}

5. "missing_parts": (Array) æ¼å‘é…ä»¶é—®é¢˜ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "part": "é…ä»¶åç§°",
     "frequency": "High|Medium|Low",
     "packing_station_issue": "å¯èƒ½çš„åŒ…è£…å·¥ä½é—®é¢˜",
     "prevention_measure": "é¢„é˜²æªæ–½",
     "source_tag": "Missing Parts",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

6. "qc_checklist": (Array) å‡ºè´§å‰å¿…æ£€é¡¹ç›®ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "item": "æ£€æŸ¥é¡¹ç›®",
     "check_method": "æ£€æŸ¥æ–¹æ³•",
     "acceptance_criteria": "åˆæ ¼æ ‡å‡†",
     "priority": "Critical|High|Medium",
     "related_complaints": "ç›¸å…³æŠ•è¯‰æ•°é‡",
     "source_tag": "Battery",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

7. "supplier_issues": (Array) ä¾›åº”å•†é—®é¢˜ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "component": "éƒ¨ä»¶åç§°",
     "issue": "é—®é¢˜æè¿°",
     "severity": "Critical|High|Medium|Low",
     "recommended_action": "å»ºè®®è¡ŒåŠ¨ï¼ˆå¦‚ï¼šæ›´æ¢ä¾›åº”å•†ã€åŠ å¼ºæ¥æ–™æ£€éªŒï¼‰",
     "timeline": "æ•´æ”¹æ—¶é—´çº¿",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

8. "return_rate_factors": (Array) é€€è´§åŸå› åˆ†æï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "reason": "é€€è´§åŸå› ",
     "estimated_percentage": "å é€€è´§æ¯”ä¾‹ä¼°è®¡",
     "preventable": (Boolean) æ˜¯å¦å¯é¢„é˜²,
     "prevention_measure": "é¢„é˜²æªæ–½",
     "cost_of_inaction": "ä¸è¡ŒåŠ¨çš„æˆæœ¬ä¼°è®¡",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

9. "assembly_defects": (Array) ç»„è£…é—®é¢˜ï¼Œ**å¿…é¡»å¸¦ confidence å’Œ evidence**ã€‚æ ¼å¼: 
   [{{
     "defect": "ç¼ºé™·æè¿°",
     "frequency": "High|Medium|Low",
     "likely_station": "å¯èƒ½çš„å·¥ä½",
     "detection_method": "æ£€æµ‹æ–¹æ³•å»ºè®®",
     "correction_action": "çº æ­£æªæ–½",
     "source_tag": "å…³è”æ ‡ç­¾",
     "confidence": "high|medium|low",
     "evidence": {{...}}
   }}]

10. "continuous_improvement": {{
      "immediate_actions": (Array) ç«‹å³è¡ŒåŠ¨é¡¹ï¼ˆæœ¬å‘¨ï¼‰["..."],
      "short_term_actions": (Array) çŸ­æœŸè¡ŒåŠ¨é¡¹ï¼ˆæœ¬æœˆï¼‰["..."],
      "process_improvements": (Array) æµç¨‹æ”¹è¿›å»ºè®® ["..."],
      "training_needs": (Array) åŸ¹è®­éœ€æ±‚ ["..."]
    }}

""" + COMMON_INSTRUCTION

# ==========================================
# [REPORT TYPE CONFIGS] ç»Ÿä¸€é…ç½®æ³¨å†Œè¡¨
# ==========================================
# å¯¼å…¥ ReportTypeConfig
from app.models.report import ReportTypeConfig

# [MAP] æ˜ å°„è¡¨ï¼šç±»å‹ -> Promptï¼ˆä¿ç•™å‘åå…¼å®¹ï¼‰
PROMPT_MAP = {
    ReportType.COMPREHENSIVE.value: COMPREHENSIVE_PROMPT,
    ReportType.OPERATIONS.value: OPERATIONS_PROMPT,
    ReportType.PRODUCT.value: PRODUCT_PROMPT,
    ReportType.SUPPLY_CHAIN.value: SUPPLY_CHAIN_PROMPT,
}

# [NEW] ç»Ÿä¸€é…ç½®æ³¨å†Œè¡¨ - ç®¡ç†æ‰€æœ‰æŠ¥å‘Šç±»å‹çš„å…ƒæ•°æ®
# æ·»åŠ æ–°ç±»å‹æ—¶ï¼Œåœ¨æ­¤æ·»åŠ é…ç½®é¡¹å³å¯
REPORT_TYPE_CONFIGS: Dict[str, ReportTypeConfig] = {
    ReportType.COMPREHENSIVE.value: ReportTypeConfig(
        key=ReportType.COMPREHENSIVE.value,
        display_name="å…¨ç»´åº¦æˆ˜ç•¥åˆ†ææŠ¥å‘Š",
        short_name="CEOç»¼åˆç‰ˆ",
        description="é¢å‘ä¼ä¸šé«˜ç®¡çš„å…¨å±€æˆ˜ç•¥è§†è§’æŠ¥å‘Šï¼Œè¯„ä¼°äº§å“å¸‚åœºåŒ¹é…åº¦(PMF)ã€SWOTåˆ†æã€éƒ¨é—¨æŒ‡ä»¤",
        target_audience="CEO/ä¼ä¸šé«˜ç®¡/æˆ˜ç•¥å†³ç­–å±‚",
        icon="ğŸ¯",
        color="#4F46E5",
        sort_order=1,
        is_active=True,
        expected_fields=["user_profile", "strategic_verdict", "market_fit_analysis", "core_swot", "department_directives", "priority_actions", "risk_level"],
        category="strategy"
    ),
    ReportType.OPERATIONS.value: ReportTypeConfig(
        key=ReportType.OPERATIONS.value,
        display_name="è¿è¥ä¸å¸‚åœºç­–ç•¥æŠ¥å‘Š",
        short_name="è¿è¥ç‰ˆ",
        description="é¢å‘è¿è¥å›¢é˜Ÿçš„è¥é”€ç­–ç•¥æŠ¥å‘Šï¼ŒæŒ–æ˜äº§å“å–ç‚¹ã€è§„é¿é€€è´§é£é™©ã€ç²¾å‡†å®šä½å¹¿å‘Šå—ä¼—",
        target_audience="CMO/è¿è¥ç»ç†/å¸‚åœºè¥é”€å›¢é˜Ÿ",
        icon="ğŸ“ˆ",
        color="#059669",
        sort_order=2,
        is_active=True,
        expected_fields=["user_profile", "executive_summary", "selling_points", "marketing_risks", "target_audience", "competitor_analysis", "listing_optimization", "review_response_templates"],
        category="operations"
    ),
    ReportType.PRODUCT.value: ReportTypeConfig(
        key=ReportType.PRODUCT.value,
        display_name="äº§å“è¿­ä»£å»ºè®®ä¹¦",
        short_name="äº§å“ç‰ˆ",
        description="é¢å‘ç ”å‘å›¢é˜Ÿçš„äº§å“æ”¹è¿›æŠ¥å‘Šï¼Œå‘ç°è®¾è®¡ç¼ºé™·ã€æ˜ç¡®ä¸‹ä¸€ä»£äº§å“æ”¹è¿›æ–¹å‘",
        target_audience="CPO/äº§å“ç»ç†/ç ”å‘å›¢é˜Ÿ",
        icon="ğŸ”§",
        color="#D97706",
        sort_order=3,
        is_active=True,
        expected_fields=["user_research", "quality_score", "critical_bugs", "unmet_needs", "usage_context_gap", "roadmap_suggestion", "usability_issues", "design_recommendations"],
        category="product"
    ),
    ReportType.SUPPLY_CHAIN.value: ReportTypeConfig(
        key=ReportType.SUPPLY_CHAIN.value,
        display_name="ä¾›åº”é“¾è´¨é‡æ•´æ”¹æŠ¥å‘Š",
        short_name="ä¾›åº”é“¾ç‰ˆ",
        description="é¢å‘å·¥å‚å’ŒQCå›¢é˜Ÿçš„è´¨é‡æ•´æ”¹æŠ¥å‘Šï¼Œé™ä½é€€è´§ç‡ã€ä¼˜åŒ–åŒ…è£…ã€è¿½è´£ä¾›åº”å•†",
        target_audience="ä¾›åº”é“¾æ€»ç›‘/QCå›¢é˜Ÿ/å·¥å‚ç®¡ç†",
        icon="ğŸ­",
        color="#DC2626",
        sort_order=4,
        is_active=True,
        expected_fields=["usage_context_analysis", "material_defects", "packaging_issues", "missing_parts", "qc_checklist", "supplier_issues", "return_rate_factors", "assembly_defects"],
        category="quality"
    ),
    # ==========================================
    # [é¢„ç•™æ‰©å±•ä½ç½®] æœªæ¥å¯æ·»åŠ æ›´å¤šç±»å‹ï¼š
    # ==========================================
    # "logistics": ReportTypeConfig(
    #     key="logistics",
    #     display_name="ç‰©æµé…é€ä¼˜åŒ–æŠ¥å‘Š",
    #     short_name="ç‰©æµç‰ˆ",
    #     description="åˆ†æç‰©æµç›¸å…³é—®é¢˜ï¼Œä¼˜åŒ–é…é€ä½“éªŒ",
    #     target_audience="ç‰©æµç»ç†/ä»“å‚¨å›¢é˜Ÿ",
    #     icon="ğŸšš",
    #     color="#8B5CF6",
    #     sort_order=5,
    #     expected_fields=["delivery_issues", "packaging_damage", "logistics_recommendations"],
    #     category="logistics"
    # ),
}

# æŠ¥å‘Šæ ‡é¢˜æ˜ å°„ï¼ˆå‘åå…¼å®¹ï¼Œä»é…ç½®ä¸­è‡ªåŠ¨ç”Ÿæˆï¼‰
REPORT_TITLE_MAP = {key: config.display_name for key, config in REPORT_TYPE_CONFIGS.items()}


# ==========================================
# [è¾…åŠ©å‡½æ•°] æŠ¥å‘Šç±»å‹ç®¡ç†
# ==========================================

def get_available_report_types() -> List[ReportTypeConfig]:
    """
    è·å–æ‰€æœ‰å¯ç”¨ï¼ˆå·²å¯ç”¨ï¼‰çš„æŠ¥å‘Šç±»å‹é…ç½®
    
    Returns:
        æŒ‰ sort_order æ’åºçš„é…ç½®åˆ—è¡¨
    """
    return sorted(
        [c for c in REPORT_TYPE_CONFIGS.values() if c.is_active],
        key=lambda x: x.sort_order
    )


def get_report_type_config(type_key: str) -> Optional[ReportTypeConfig]:
    """
    è·å–æŒ‡å®šç±»å‹çš„é…ç½®
    
    Args:
        type_key: æŠ¥å‘Šç±»å‹æ ‡è¯†ï¼ˆå¦‚ "comprehensive"ï¼‰
        
    Returns:
        ReportTypeConfig å¯¹è±¡ï¼Œæˆ– Noneï¼ˆå¦‚æœç±»å‹ä¸å­˜åœ¨ï¼‰
    """
    return REPORT_TYPE_CONFIGS.get(type_key)


def validate_report_type(type_key: str) -> bool:
    """
    éªŒè¯æŠ¥å‘Šç±»å‹æ˜¯å¦æœ‰æ•ˆä¸”å·²å¯ç”¨
    
    Args:
        type_key: æŠ¥å‘Šç±»å‹æ ‡è¯†
        
    Returns:
        True å¦‚æœç±»å‹æœ‰æ•ˆä¸”å·²å¯ç”¨
    """
    config = REPORT_TYPE_CONFIGS.get(type_key)
    return config is not None and config.is_active


def get_prompt_for_type(type_key: str) -> Optional[str]:
    """
    è·å–æŒ‡å®šç±»å‹çš„ Prompt æ¨¡æ¿
    
    Args:
        type_key: æŠ¥å‘Šç±»å‹æ ‡è¯†
        
    Returns:
        Prompt æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œæˆ– None
    """
    return PROMPT_MAP.get(type_key)


class SummaryService:
    """
    æ™ºèƒ½æŠ¥å‘Šç”ŸæˆæœåŠ¡ï¼ˆæ”¯æŒæŒä¹…åŒ–å­˜å‚¨ï¼‰
    
    æ”¯æŒå››ç§æŠ¥å‘Šç±»å‹ï¼š
    - comprehensive: CEO/ç»¼åˆæˆ˜ç•¥ç‰ˆ
    - operations: CMO/è¿è¥å¸‚åœºç‰ˆ
    - product: CPO/äº§å“ç ”å‘ç‰ˆ
    - supply_chain: ä¾›åº”é“¾/è´¨æ£€ç‰ˆ
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    ```python
    service = SummaryService(db)
    
    # ç”Ÿæˆæ–°æŠ¥å‘Šï¼ˆæŒ‡å®šç±»å‹ï¼‰
    report = await service.generate_report(product_id, report_type="operations")
    
    # è·å–æœ€æ–°æŠ¥å‘Šï¼ˆç§’å¼€ï¼‰
    latest = await service.get_latest_report(product_id)
    
    # è·å–å†å²æŠ¥å‘Šåˆ—è¡¨ï¼ˆå¯æŒ‰ç±»å‹ç­›é€‰ï¼‰
    history = await service.get_report_history(product_id, report_type="product")
    ```
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    async def generate_report(
        self, 
        product_id: UUID,
        report_type: str = ReportType.COMPREHENSIVE.value,
        min_reviews: int = 30,  # [UPDATED 2026-01-19] æŠ¥å‘Šç”Ÿæˆéœ€è¦è‡³å°‘30æ¡è¯„è®º
        save_to_db: bool = True,
        force_regenerate: bool = False,  # [NEW] æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆå¿½ç•¥å»é‡ï¼‰
        require_full_completion: bool = True  # [NEW] æ˜¯å¦è¦æ±‚æ´å¯Ÿå’Œä¸»é¢˜100%å®Œæˆ
    ) -> dict:
        """
        æ ¸å¿ƒå…¥å£ï¼šç”ŸæˆæŒ‡å®šç±»å‹çš„ç»“æ„åŒ–æŠ¥å‘Š (JSON)
        
        Args:
            product_id: äº§å“ UUID
            report_type: æŠ¥å‘Šç±»å‹ (ä½¿ç”¨ ReportType æšä¸¾å€¼)
            min_reviews: æœ€å°‘è¯„è®ºæ•°ï¼ˆé»˜è®¤ 30ï¼ŒæŠ¥å‘Šç”Ÿæˆéœ€è¦è¶³å¤Ÿæ•°æ®é‡ä¿è¯è´¨é‡ï¼‰
            save_to_db: æ˜¯å¦å­˜å…¥æ•°æ®åº“ï¼ˆé»˜è®¤ Trueï¼‰
            force_regenerate: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼ˆé»˜è®¤ Falseï¼Œä¼šæ£€æŸ¥å»é‡ï¼‰
            require_full_completion: æ˜¯å¦è¦æ±‚æ´å¯Ÿå’Œä¸»é¢˜100%å®Œæˆï¼ˆé»˜è®¤ Trueï¼‰
            
        Returns:
            {
                "success": True/False,
                "report": ProductReport å¯¹è±¡çš„ dict,
                "stats": {...åŸå§‹ç»Ÿè®¡æ•°æ®...},
                "report_type_config": {...æŠ¥å‘Šç±»å‹é…ç½®...},
                "error": "é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰"
            }
            
        Note:
            æ”¯æŒçš„æŠ¥å‘Šç±»å‹è¯·å‚è€ƒ REPORT_TYPE_CONFIGS é…ç½®è¡¨
        """
        try:
            # 0. [NEW] éªŒè¯æŠ¥å‘Šç±»å‹
            type_config = get_report_type_config(report_type)
            if not type_config:
                return {
                    "success": False,
                    "report": None,
                    "stats": None,
                    "report_type_config": None,
                    "error": f"ä¸æ”¯æŒçš„æŠ¥å‘Šç±»å‹: {report_type}ã€‚å¯ç”¨ç±»å‹: {', '.join(REPORT_TYPE_CONFIGS.keys())}"
                }
            
            if not type_config.is_active:
                return {
                    "success": False,
                    "report": None,
                    "stats": None,
                    "report_type_config": type_config.to_dict(),
                    "error": f"æŠ¥å‘Šç±»å‹ '{type_config.display_name}' å½“å‰å·²ç¦ç”¨"
                }
            
            # [NEW] 0.5 æ£€æŸ¥å»é‡ï¼š1å°æ—¶å†…æ˜¯å¦å·²æœ‰ç›¸åŒç±»å‹çš„æŠ¥å‘Š
            if not force_regenerate:
                from datetime import timedelta
                one_hour_ago = datetime.now() - timedelta(hours=1)
                
                existing_report_result = await self.db.execute(
                    select(ProductReport)
                    .where(
                        and_(
                            ProductReport.product_id == product_id,
                            ProductReport.report_type == report_type,
                            ProductReport.status == ReportStatus.COMPLETED.value,
                            ProductReport.created_at >= one_hour_ago
                        )
                    )
                    .order_by(ProductReport.created_at.desc())
                    .limit(1)
                )
                existing_report = existing_report_result.scalar_one_or_none()
                
                if existing_report:
                    logger.info(f"[å»é‡] äº§å“ {product_id} åœ¨1å°æ—¶å†…å·²æœ‰ {report_type} æŠ¥å‘Šï¼Œè·³è¿‡ç”Ÿæˆ")
                    return {
                        "success": True,
                        "report": existing_report.to_dict(),
                        "stats": existing_report.analysis_data,
                        "report_type_config": type_config.to_dict(),
                        "error": None,
                        "is_cached": True  # æ ‡è®°ä¸ºç¼“å­˜ç»“æœ
                    }
            
            # 1. è·å–äº§å“ä¿¡æ¯
            product = await self._get_product(product_id)
            if not product:
                return {
                    "success": False,
                    "report": None,
                    "stats": None,
                    "report_type_config": type_config.to_dict(),
                    "error": "äº§å“ä¸å­˜åœ¨"
                }
            
            # 2. æ£€æŸ¥æ•°æ®é‡
            total_reviews = await self._count_translated_reviews(product_id)
            
            # [UPDATED 2026-01-19] æŠ¥å‘Šç”Ÿæˆéœ€è¦è‡³å°‘30æ¡è¯„è®ºä»¥ä¿è¯åˆ†æè´¨é‡
            if total_reviews < min_reviews:
                return {
                    "success": False,
                    "report": None,
                    "stats": {"total_reviews": total_reviews},
                    "report_type_config": type_config.to_dict(),
                    "error": f"è¯„è®ºæ•°æ®ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆé«˜è´¨é‡æŠ¥å‘Šã€‚å½“å‰ä»…æœ‰ {total_reviews} æ¡è¯„è®ºï¼Œå»ºè®®é‡‡é›†è‡³å°‘ {min_reviews} æ¡è¯„è®ºåå†ç”ŸæˆæŠ¥å‘Šã€‚"
                }
            
            # [NEW] 2.5 æ£€æŸ¥æ´å¯Ÿå’Œä¸»é¢˜æ˜¯å¦100%å®Œæˆ
            if require_full_completion:
                from app.models.insight import ReviewInsight
                from app.models.theme_highlight import ReviewThemeHighlight
                
                # æ£€æŸ¥æ´å¯Ÿå®Œæˆåº¦
                insight_count_result = await self.db.execute(
                    select(func.count(func.distinct(ReviewInsight.review_id)))
                    .select_from(ReviewInsight)
                    .join(Review, ReviewInsight.review_id == Review.id)
                    .where(Review.product_id == product_id)
                )
                insight_count = insight_count_result.scalar() or 0
                
                # æ£€æŸ¥ä¸»é¢˜å®Œæˆåº¦
                theme_count_result = await self.db.execute(
                    select(func.count(func.distinct(ReviewThemeHighlight.review_id)))
                    .select_from(ReviewThemeHighlight)
                    .join(Review, ReviewThemeHighlight.review_id == Review.id)
                    .where(Review.product_id == product_id)
                )
                theme_count = theme_count_result.scalar() or 0
                
                # è®¡ç®—å®Œæˆåº¦
                insight_completion = insight_count / total_reviews if total_reviews > 0 else 0
                theme_completion = theme_count / total_reviews if total_reviews > 0 else 0
                
                logger.info(f"[å®Œæˆåº¦æ£€æŸ¥] æ´å¯Ÿ: {insight_count}/{total_reviews} ({insight_completion:.1%}), ä¸»é¢˜: {theme_count}/{total_reviews} ({theme_completion:.1%})")
                
                # è¦æ±‚100%å®Œæˆï¼ˆæˆ–å…è®¸å°‘é‡è¯¯å·®ï¼Œå¦‚95%ï¼‰
                COMPLETION_THRESHOLD = 0.95
                
                if insight_completion < COMPLETION_THRESHOLD:
                    return {
                        "success": False,
                        "report": None,
                        "stats": {
                            "total_reviews": total_reviews,
                            "insight_count": insight_count,
                            "theme_count": theme_count,
                            "insight_completion": f"{insight_completion:.1%}",
                            "theme_completion": f"{theme_completion:.1%}"
                        },
                        "report_type_config": type_config.to_dict(),
                        "error": f"æ´å¯Ÿæå–æœªå®Œæˆï¼ˆ{insight_count}/{total_reviews}ï¼Œ{insight_completion:.1%}ï¼‰ã€‚è¯·ç­‰å¾…æ´å¯Ÿæå–å®Œæˆåå†ç”ŸæˆæŠ¥å‘Šã€‚"
                    }
                
                if theme_completion < COMPLETION_THRESHOLD:
                    return {
                        "success": False,
                        "report": None,
                        "stats": {
                            "total_reviews": total_reviews,
                            "insight_count": insight_count,
                            "theme_count": theme_count,
                            "insight_completion": f"{insight_completion:.1%}",
                            "theme_completion": f"{theme_completion:.1%}"
                        },
                        "report_type_config": type_config.to_dict(),
                        "error": f"ä¸»é¢˜æå–æœªå®Œæˆï¼ˆ{theme_count}/{total_reviews}ï¼Œ{theme_completion:.1%}ï¼‰ã€‚è¯·ç­‰å¾…ä¸»é¢˜æå–å®Œæˆåå†ç”ŸæˆæŠ¥å‘Šã€‚"
                    }
            
            # 3. èšåˆåŸå§‹æ•°æ® (Raw Data) - ECharts æ ¼å¼
            context_stats = await self._aggregate_5w_stats(product_id)
            insight_stats = await self._aggregate_insight_stats(product_id)
            
            # 4. [å…³é”®] æ•°æ®èåˆæ ¼å¼åŒ– - å–‚ç»™ LLM
            stats_text = self._format_stats_for_llm(context_stats, insight_stats, total_reviews)
            
            # 5. [UPDATED] ä»é…ç½®è¡¨è·å– Prompt
            prompt_template = get_prompt_for_type(report_type)
            if not prompt_template:
                prompt_template = COMPREHENSIVE_PROMPT  # é™çº§åˆ°é»˜è®¤
                logger.warning(f"No prompt found for type '{report_type}', falling back to comprehensive")
            final_prompt = prompt_template.format(stats_text=stats_text)
            
            # 6. è°ƒç”¨ LLM (å¼ºåˆ¶ JSON è¾“å‡º)
            if not translation_service.client:
                return {
                    "success": False,
                    "report": None,
                    "stats": {
                        "total_reviews": total_reviews,
                        "context": context_stats,
                        "insight": insight_stats
                    },
                    "report_type_config": type_config.to_dict(),
                    "error": "AI æœåŠ¡æœªé…ç½®ï¼ˆç¼ºå°‘ API Keyï¼‰"
                }
            
            try:
                logger.info(f"Generating {report_type} report for product {product.asin}...")
                
                # === åˆ†æ¨¡å—ç”Ÿæˆç­–ç•¥ ===
                # å°†å¤§æŠ¥å‘Šæ‹†åˆ†æˆå¤šä¸ªå°æ¨¡å—ï¼Œåˆ†åˆ«è°ƒç”¨ AIï¼Œç„¶ååˆå¹¶
                parsed_content = await self._generate_report_in_modules(
                    report_type=report_type,
                    stats_text=stats_text,
                    prompt_template=prompt_template
                )
                
                cleaned_json_str = json.dumps(parsed_content, ensure_ascii=False)
                logger.info(f"æˆåŠŸç”ŸæˆæŠ¥å‘Šï¼Œå…± {len(parsed_content)} ä¸ªé¡¶çº§å­—æ®µ")
                
                # 7. æ„å»º analysis_data (åŸå§‹ç»Ÿè®¡æ•°æ®ï¼Œç»™å‰ç«¯ç”»å›¾)
                analysis_data = {
                    "total_reviews": total_reviews,  # é¡¶å±‚ï¼Œç¬¦åˆ ReportStats æ¥å£
                    "context": context_stats,
                    "insight": insight_stats,
                    "meta": {
                        "total_reviews": total_reviews,  # ä¿ç•™åœ¨ meta ä¸­ç”¨äºå…¼å®¹
                        "generated_at": datetime.now().isoformat(),
                        "report_type": report_type,
                        "product_asin": product.asin
                    }
                }
                
                # 8. æŒä¹…åŒ–å­˜å‚¨
                if save_to_db:
                    report_title = f"{REPORT_TITLE_MAP.get(report_type, 'åˆ†ææŠ¥å‘Š')} - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                    
                    new_report = ProductReport(
                        product_id=product_id,
                        title=report_title,
                        content=cleaned_json_str,      # AI çš„è§‚ç‚¹ (JSON)
                        report_type=report_type,
                        analysis_data=analysis_data,   # åŸå§‹æ•°æ® (ç»™å‰ç«¯ç”»å›¾)
                        status=ReportStatus.COMPLETED.value
                    )
                    
                    self.db.add(new_report)
                    await self.db.commit()
                    await self.db.refresh(new_report)
                    
                    logger.info(f"Report saved to DB: {new_report.id}")
                    
                    return {
                        "success": True,
                        "report": new_report.to_dict(),
                        "stats": analysis_data,
                        "report_type_config": type_config.to_dict(),
                        "error": None
                    }
                else:
                    return {
                        "success": True,
                        "report": {
                            "content": cleaned_json_str,
                            "report_type": report_type,
                            "analysis_data": analysis_data
                        },
                        "stats": analysis_data,
                        "report_type_config": type_config.to_dict(),
                        "error": None
                    }
                
            except Exception as e:
                logger.error(f"AI æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
                return {
                    "success": False,
                    "report": None,
                    "stats": {
                        "total_reviews": total_reviews,
                        "context": context_stats,
                        "insight": insight_stats
                    },
                    "report_type_config": type_config.to_dict(),
                    "error": f"AI æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
                }
                
        except Exception as e:
            logger.error(f"æŠ¥å‘Šç”Ÿæˆè¿‡ç¨‹å‡ºé”™: {e}")
            return {
                "success": False,
                "report": None,
                "stats": None,
                "report_type_config": None,
                "error": f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    async def _generate_report_in_modules(
        self,
        report_type: str,
        stats_text: str,
        prompt_template: str
    ) -> Dict[str, Any]:
        """
        åˆ†æ¨¡å—ç”ŸæˆæŠ¥å‘Š - å°†å¤§æŠ¥å‘Šæ‹†åˆ†æˆå¤šä¸ªå°æ¨¡å—åˆ†åˆ«ç”Ÿæˆï¼Œæé«˜æˆåŠŸç‡
        
        ç­–ç•¥ï¼š
        1. æ ¹æ®æŠ¥å‘Šç±»å‹å®šä¹‰æ¨¡å—åˆ—è¡¨
        2. æ¯ä¸ªæ¨¡å—ç‹¬ç«‹è°ƒç”¨ AI
        3. åˆå¹¶æ‰€æœ‰æ¨¡å—çš„è¾“å‡º
        """
        # å®šä¹‰å„æŠ¥å‘Šç±»å‹çš„æ¨¡å—
        MODULE_CONFIGS = {
            "comprehensive": [
                {"name": "user_profile", "fields": ["user_profile"], "desc": "ç”¨æˆ·ç”»åƒåˆ†æï¼ˆè´­ä¹°è€…ã€ä½¿ç”¨è€…ã€åœºæ™¯ã€åŠ¨æœºï¼‰"},
                {"name": "strategy", "fields": ["strategic_verdict", "market_fit_analysis", "risk_level"], "desc": "æˆ˜ç•¥å®šè°ƒä¸å¸‚åœºåŒ¹é…åº¦"},
                {"name": "swot", "fields": ["core_swot"], "desc": "SWOTåˆ†æï¼ˆä¼˜åŠ¿ã€åŠ£åŠ¿ã€æœºä¼šã€å¨èƒï¼‰"},
                {"name": "actions", "fields": ["department_directives", "priority_actions"], "desc": "éƒ¨é—¨æŒ‡ä»¤ä¸ä¼˜å…ˆè¡ŒåŠ¨é¡¹"},
            ],
            "operations": [
                {"name": "user_profile", "fields": ["user_profile"], "desc": "ç”¨æˆ·ç”»åƒä¸å¸‚åœºå®šä½"},
                {"name": "marketing", "fields": ["executive_summary", "selling_points"], "desc": "å¸‚åœºç°çŠ¶ä¸æ ¸å¿ƒå–ç‚¹"},
                {"name": "risks", "fields": ["marketing_risks", "target_audience", "competitor_analysis"], "desc": "è¥é”€é£é™©ä¸ç«å“åˆ†æ"},
                {"name": "optimization", "fields": ["listing_optimization", "review_response_templates"], "desc": "Listingä¼˜åŒ–ä¸å·®è¯„å›å¤"},
            ],
            "product": [
                {"name": "user_research", "fields": ["user_research"], "desc": "ç”¨æˆ·ç ”ç©¶æ´å¯Ÿ"},
                {"name": "quality", "fields": ["quality_score", "critical_bugs"], "desc": "äº§å“è´¨é‡è¯„ä¼°ä¸è‡´å‘½ç¼ºé™·"},
                {"name": "needs", "fields": ["unmet_needs", "usage_context_gap", "roadmap_suggestion"], "desc": "æœªæ»¡è¶³éœ€æ±‚ä¸è¿­ä»£æ–¹å‘"},
                {"name": "usability", "fields": ["usability_issues", "design_recommendations"], "desc": "æ˜“ç”¨æ€§é—®é¢˜ä¸è®¾è®¡å»ºè®®"},
            ],
            "supply_chain": [
                {"name": "context", "fields": ["usage_context_analysis"], "desc": "ä½¿ç”¨åœºæ™¯ä¸è´¨é‡éœ€æ±‚åˆ†æ"},
                {"name": "quality", "fields": ["quality_summary", "material_defects", "packaging_issues"], "desc": "è´¨é‡é—®é¢˜ä¸åŒ…è£…åˆ†æ"},
                {"name": "supplier", "fields": ["supplier_issues", "return_rate_factors", "missing_parts"], "desc": "ä¾›åº”å•†é—®é¢˜ä¸é€€è´§åˆ†æ"},
                {"name": "qc", "fields": ["qc_checklist", "assembly_defects"], "desc": "QCæ£€æŸ¥æ¸…å•ä¸ç»„è£…é—®é¢˜"},
            ]
        }
        
        modules = MODULE_CONFIGS.get(report_type, MODULE_CONFIGS["comprehensive"])
        
        # åˆå¹¶ç»“æœ
        final_result = {}
        
        for module in modules:
            try:
                logger.info(f"ç”Ÿæˆæ¨¡å—: {module['name']} - {module['desc']}")
                
                # æ„å»ºæ¨¡å—ä¸“ç”¨ Promptï¼ˆåŠ å¼ºæ ¼å¼çº¦æŸï¼‰
                fields_format_hint = self._get_fields_format_hint(module['fields'])
                module_prompt = f"""åŸºäºä»¥ä¸‹æ•°æ®ï¼Œåªç”Ÿæˆ {module['desc']} éƒ¨åˆ†çš„ JSONã€‚

# è¾“å…¥æ•°æ®
{stats_text}

# è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
1. åªè¾“å‡º JSON æ ¼å¼ï¼Œä¸è¦ä»»ä½•è§£é‡Šæ–‡å­—
2. åªç”Ÿæˆè¿™äº›å­—æ®µ: {', '.join(module['fields'])}
3. **é‡è¦**: ä»¥ä¸‹å­—æ®µå¿…é¡»æ˜¯æ•°ç»„æ ¼å¼ [{{...}}, {{...}}]ï¼Œå³ä½¿åªæœ‰ä¸€æ¡æ•°æ®ï¼š
   - usage_context_analysis, material_defects, packaging_issues, missing_parts
   - supplier_issues, return_rate_factors, qc_checklist, assembly_defects
   - user_profile, user_research, selling_points, critical_bugs
4. æ¯ä¸ªå¯¹è±¡å¿…é¡»åŒ…å«:
   - "insight" æˆ– "issue": ä¸»è¦å†…å®¹æè¿°
   - "confidence": "high" | "medium" | "low"
   - "evidence": [{{ "review_id": null, "quote": "å¼•ç”¨åŸæ–‡" }}]
5. ä½¿ç”¨ä¸­æ–‡
{fields_format_hint}

è¯·ç›´æ¥è¾“å‡º JSON:"""

                response = translation_service.client.chat.completions.create(
                    model="qwen-plus",  # ä½¿ç”¨ qwen-plusï¼Œé€Ÿåº¦æ›´å¿«
                    messages=[
                        {"role": "system", "content": "You are a data analyst. Output JSON only. Always respond in Chinese."},
                        {"role": "user", "content": module_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=2000,
                    response_format={"type": "json_object"},
                    timeout=60  # æ¯ä¸ªæ¨¡å—60ç§’è¶…æ—¶
                )
                
                content = response.choices[0].message.content
                cleaned = content.replace("```json", "").replace("```", "").strip()
                
                try:
                    module_data = json.loads(cleaned)
                    final_result.update(module_data)
                    logger.info(f"æ¨¡å— {module['name']} ç”ŸæˆæˆåŠŸï¼ŒåŒ…å« {len(module_data)} ä¸ªå­—æ®µ")
                except json.JSONDecodeError as e:
                    logger.warning(f"æ¨¡å— {module['name']} JSON è§£æå¤±è´¥: {e}")
                    
            except Exception as e:
                logger.warning(f"æ¨¡å— {module['name']} ç”Ÿæˆå¤±è´¥: {e}")
                # ç»§ç»­ç”Ÿæˆå…¶ä»–æ¨¡å—
                continue
        
        if not final_result:
            raise Exception("æ‰€æœ‰æ¨¡å—ç”Ÿæˆå¤±è´¥")
        
        # ğŸ”§ æ ¼å¼æ ¡éªŒå’Œä¿®å¤
        final_result = self._normalize_report_format(final_result, report_type)
        
        return final_result
    
    def _get_fields_format_hint(self, fields: List[str]) -> str:
        """
        æ ¹æ®å­—æ®µåˆ—è¡¨ç”Ÿæˆæ ¼å¼æç¤ºç¤ºä¾‹
        """
        hints = []
        
        FIELD_EXAMPLES = {
            # ========== ä¾›åº”é“¾æŠ¥å‘Šå­—æ®µ ==========
            "usage_context_analysis": '''
# usage_context_analysis æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"usage_context_analysis": [
  {"insight": "ç”¨æˆ·ä¸»è¦æ˜¯...", "confidence": "high", "evidence": [{"review_id": null, "quote": "..."}]}
]''',
            "quality_summary": '''
# quality_summary æ ¼å¼ç¤ºä¾‹ï¼ˆå•ä¸ªå¯¹è±¡ï¼‰:
"quality_summary": {
  "summary": "æ•´ä½“è´¨é‡è¯„ä¼°æè¿°...",
  "confidence": "high",
  "evidence": [{"review_id": null, "quote": "..."}]
}''',
            "material_defects": '''
# material_defects æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"material_defects": [
  {"issue": "é—®é¢˜æè¿°...", "confidence": "high", "evidence": [{"review_id": null, "quote": "..."}]}
]''',
            "packaging_issues": '''
# packaging_issues æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"packaging_issues": [
  {"issue": "åŒ…è£…é—®é¢˜æè¿°...", "confidence": "medium", "evidence": [...]}
]''',
            "missing_parts": '''
# missing_parts æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"missing_parts": [
  {"issue": "ç¼ºå¤±é…ä»¶æè¿°...", "confidence": "medium", "evidence": [...]}
]''',
            "supplier_issues": '''
# supplier_issues æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"supplier_issues": [
  {"issue": "ä¾›åº”å•†é—®é¢˜æè¿°...", "confidence": "high", "evidence": [...]}
]''',
            "return_rate_factors": '''
# return_rate_factors æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"return_rate_factors": [
  {"insight": "é€€è´§åŸå› åˆ†æ...", "confidence": "high", "evidence": [...]}
]''',
            "qc_checklist": '''
# qc_checklist æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼Œæ¯é¡¹åŒ…å« issue å­—æ®µï¼‰:
"qc_checklist": [
  {"issue": "æ£€æŸ¥é¡¹æè¿°...", "suggestion": "å»ºè®®æªæ–½", "confidence": "high", "evidence": [...]}
]''',
            "assembly_defects": '''
# assembly_defects æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"assembly_defects": [
  {"issue": "ç»„è£…é—®é¢˜æè¿°...", "confidence": "medium", "evidence": [...]}
]''',
            # ========== ç»¼åˆæŠ¥å‘Šå­—æ®µ ==========
            "user_profile": '''
# user_profile æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"user_profile": [
  {"insight": "è´­ä¹°è€…ç”»åƒæè¿°...", "confidence": "high", "evidence": [...]},
  {"insight": "ä½¿ç”¨è€…ç‰¹å¾...", "confidence": "medium", "evidence": [...]}
]''',
            "strategic_verdict": '''
# strategic_verdict æ ¼å¼ç¤ºä¾‹ï¼ˆå­—ç¬¦ä¸²ï¼‰:
"strategic_verdict": "æˆ˜ç•¥å®šè°ƒæè¿°æ–‡æœ¬..."''',
            "market_fit_analysis": '''
# market_fit_analysis æ ¼å¼ç¤ºä¾‹ï¼ˆæ•°ç»„ï¼‰:
"market_fit_analysis": [
  {"insight": "å¸‚åœºåŒ¹é…åˆ†æ...", "confidence": "high", "evidence": [...]}
]''',
            "core_swot": '''
# core_swot æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯å¯¹è±¡ï¼ŒåŒ…å«å››ä¸ªåˆ†ç±»æ•°ç»„ï¼‰:
# é‡è¦ï¼šè¿™æ˜¯ä¸€ä¸ªå¯¹è±¡ï¼Œä¸æ˜¯æ•°ç»„ï¼å¿…é¡»æŒ‰ strengths/weaknesses/opportunities/threats åˆ†ç±»
"core_swot": {
  "strengths": [
    {"point": "äº§å“ä¼˜åŠ¿æè¿°...", "confidence": "high", "evidence": [{"review_id": null, "quote": "ç”¨æˆ·æ­£é¢è¯„ä»·..."}]}
  ],
  "weaknesses": [
    {"point": "äº§å“åŠ£åŠ¿/ç—›ç‚¹æè¿°...", "confidence": "high", "evidence": [...]}
  ],
  "opportunities": [
    {"point": "å¸‚åœºæœºä¼šæè¿°...", "rationale": "æœºä¼šåˆ†æä¾æ®"}
  ],
  "threats": [
    {"point": "æ½œåœ¨å¨èƒæè¿°...", "rationale": "å¨èƒåˆ†æä¾æ®"}
  ]
}''',
            "department_directives": '''
# department_directives æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼Œæ¯é¡¹æœ‰ insight å’Œ departmentï¼‰:
"department_directives": [
  {"department": "å¸‚åœºéƒ¨", "insight": "æŒ‡ä»¤å†…å®¹...", "confidence": "high", "evidence": [...]}
]''',
            "priority_actions": '''
# priority_actions æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼Œæ¯é¡¹æœ‰ action å­—æ®µï¼‰:
"priority_actions": [
  {"action": "è¡ŒåŠ¨æè¿°...", "owner": "è´Ÿè´£äºº", "priority": "P0", "confidence": "high", "evidence": [...]}
]''',
            # ========== è¿è¥æŠ¥å‘Šå­—æ®µ ==========
            "selling_points": '''
# selling_points æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"selling_points": [
  {"insight": "å–ç‚¹æè¿°...", "confidence": "high", "evidence": [...]}
]''',
            "marketing_risks": '''
# marketing_risks æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"marketing_risks": [
  {"insight": "é£é™©æè¿°...", "confidence": "high", "evidence": [...]}
]''',
            "target_audience": '''
# target_audience æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼Œä¸è¦åµŒå¥—å…¶ä»–å­—æ®µï¼‰:
"target_audience": [
  {"insight": "ç›®æ ‡å—ä¼—æè¿°...", "confidence": "high", "evidence": [...]}
]''',
            "competitor_analysis": '''
# competitor_analysis æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼Œä¸è¦åµŒå¥—å…¶ä»–å­—æ®µï¼‰:
"competitor_analysis": [
  {"insight": "ç«å“åˆ†ææè¿°...", "confidence": "medium", "evidence": [...]}
]''',
            "listing_optimization": '''
# listing_optimization æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"listing_optimization": [
  {"element": "Title/Bullets/Images", "suggestion": "ä¼˜åŒ–å»ºè®®...", "confidence": "high", "evidence": [...]}
]''',
            "review_response_templates": '''
# review_response_templates æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"review_response_templates": [
  {"issue": "é—®é¢˜ç±»å‹", "response": "å›å¤æ¨¡æ¿å†…å®¹...", "confidence": "medium", "evidence": [...]}
]''',
            "executive_summary": '''
# executive_summary æ ¼å¼ç¤ºä¾‹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰:
"executive_summary": "æ‰§è¡Œæ‘˜è¦æ–‡æœ¬..."''',
            # ========== äº§å“æŠ¥å‘Šå­—æ®µ ==========
            "user_research": '''
# user_research æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"user_research": [
  {"insight": "ç”¨æˆ·ç ”ç©¶æ´å¯Ÿ...", "confidence": "high", "evidence": [...]}
]''',
            "quality_score": '''
# quality_score æ ¼å¼ç¤ºä¾‹ï¼ˆå¯¹è±¡ï¼‰:
"quality_score": {
  "overall": 75,
  "design": 80,
  "functionality": 70
}''',
            "critical_bugs": '''
# critical_bugs æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"critical_bugs": [
  {"issue": "ä¸¥é‡ç¼ºé™·æè¿°...", "priority": "P0", "confidence": "high", "evidence": [...]}
]''',
            "unmet_needs": '''
# unmet_needs æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"unmet_needs": [
  {"insight": "ç”¨æˆ·æœªæ»¡è¶³éœ€æ±‚...", "confidence": "medium", "evidence": [...]}
]''',
            "usability_issues": '''
# usability_issues æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"usability_issues": [
  {"insight": "æ˜“ç”¨æ€§é—®é¢˜æè¿°...", "confidence": "high", "evidence": [...]}
]''',
            "design_recommendations": '''
# design_recommendations æ ¼å¼ç¤ºä¾‹ï¼ˆå¿…é¡»æ˜¯æ•°ç»„ï¼‰:
"design_recommendations": [
  {"insight": "è®¾è®¡æ”¹è¿›å»ºè®®...", "confidence": "medium", "evidence": [...]}
]''',
            "usage_context_gap": '''
# usage_context_gap æ ¼å¼ç¤ºä¾‹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰:
"usage_context_gap": "ä½¿ç”¨åœºæ™¯å·®è·åˆ†ææè¿°..."''',
            "roadmap_suggestion": '''
# roadmap_suggestion æ ¼å¼ç¤ºä¾‹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–æ•°ç»„ï¼‰:
"roadmap_suggestion": "ä¸‹ç‰ˆæœ¬å‡çº§æ–¹å‘æè¿°..."''',
        }
        
        for field in fields:
            if field in FIELD_EXAMPLES:
                hints.append(FIELD_EXAMPLES[field])
        
        return "\n".join(hints) if hints else ""
    
    def _normalize_report_format(self, data: Dict[str, Any], report_type: str) -> Dict[str, Any]:
        """
        ğŸ”§ æ ‡å‡†åŒ–æŠ¥å‘Šè¾“å‡ºæ ¼å¼
        
        AI è¾“å‡ºç»å¸¸ä¸éµå®ˆ prompt å®šä¹‰çš„æ ¼å¼ï¼Œè¿™é‡Œè¿›è¡Œç»Ÿä¸€ä¿®å¤ï¼š
        1. å°†åº”è¯¥æ˜¯æ•°ç»„çš„å­—æ®µè½¬æ¢ä¸ºæ•°ç»„
        2. ç»Ÿä¸€å­—æ®µåï¼ˆå¦‚ issue -> insightï¼‰
        3. ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
        """
        result = data.copy()
        
        # ==========================================
        # é€šç”¨ä¿®å¤ï¼šå°†å•å¯¹è±¡è½¬ä¸ºæ•°ç»„
        # ==========================================
        ARRAY_FIELDS = {
            # ä¾›åº”é“¾æŠ¥å‘Š
            "usage_context_analysis": True,
            "material_defects": True,
            "packaging_issues": True,
            "missing_parts": True,
            "supplier_issues": True,
            "return_rate_factors": True,
            "qc_checklist": True,
            "assembly_defects": True,
            # ç»¼åˆæŠ¥å‘Š
            "user_profile": True,
            "priority_actions": True,
            # è¿è¥æŠ¥å‘Š
            "selling_points": True,
            "marketing_risks": True,
            "review_response_templates": True,
            # äº§å“æŠ¥å‘Š
            "user_research": True,
            "critical_bugs": True,
            "unmet_needs": True,
            "usability_issues": True,
            "design_recommendations": True,
        }
        
        for field, should_be_array in ARRAY_FIELDS.items():
            if field in result and should_be_array:
                value = result[field]
                # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ä¸”æœ‰ issue/insight ç­‰å†…å®¹å­—æ®µï¼Œè½¬ä¸ºæ•°ç»„
                if isinstance(value, dict) and not isinstance(value, list):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯"å·²è½¬æ¢"çš„åµŒå¥—ç»“æ„ï¼ˆå¦‚ {issues: [...]}ï¼‰
                    if 'issues' in value and isinstance(value['issues'], list):
                        result[field] = value['issues']
                    elif 'items' in value and isinstance(value['items'], list):
                        result[field] = value['items']
                    else:
                        # å•å¯¹è±¡è½¬æ•°ç»„
                        result[field] = [value]
                        logger.info(f"[æ ¼å¼ä¿®å¤] {field}: å•å¯¹è±¡è½¬ä¸ºæ•°ç»„")
        
        # ==========================================
        # ä¾›åº”é“¾æŠ¥å‘Šä¸“ç”¨ä¿®å¤
        # ==========================================
        if report_type == "supply_chain":
            # 1. usage_context_analysis å­—æ®µæ ‡å‡†åŒ–
            if "usage_context_analysis" in result:
                items = result["usage_context_analysis"]
                if isinstance(items, list):
                    for item in items:
                        # ç¡®ä¿æœ‰ insight å­—æ®µï¼ˆä» issue å¤åˆ¶ï¼‰
                        if 'issue' in item and 'insight' not in item:
                            item['insight'] = item['issue']
                        # ç¡®ä¿æœ‰ evidence å­—æ®µ
                        if 'evidence' not in item:
                            item['evidence'] = []
            
            # 2. quality_summary å­—æ®µæ ‡å‡†åŒ–
            if "quality_summary" in result:
                qs = result["quality_summary"]
                if isinstance(qs, dict):
                    # ç¡®ä¿æœ‰ summary å­—æ®µï¼ˆä» issue å¤åˆ¶ï¼‰
                    if 'issue' in qs and 'summary' not in qs:
                        qs['summary'] = qs['issue']
            
            # 3. å…¶ä»–æ•°ç»„å­—æ®µæ ‡å‡†åŒ–
            for field in ["material_defects", "packaging_issues", "supplier_issues", 
                          "return_rate_factors", "missing_parts", "qc_checklist", "assembly_defects"]:
                if field in result:
                    items = result[field]
                    if isinstance(items, list):
                        for item in items:
                            # ç¡®ä¿æœ‰ confidence å­—æ®µ
                            if 'confidence' not in item:
                                item['confidence'] = 'medium'
                            # ç¡®ä¿æœ‰ evidence å­—æ®µ
                            if 'evidence' not in item:
                                item['evidence'] = []
        
        # ==========================================
        # é€šç”¨å­—æ®µæ ‡å‡†åŒ–
        # ==========================================
        for field in ["user_profile", "user_research"]:
            if field in result and isinstance(result[field], list):
                for item in result[field]:
                    # ç¡®ä¿æœ‰ insight å­—æ®µ
                    if 'insight' not in item:
                        # å°è¯•ä»å…¶ä»–å­—æ®µè·å–
                        for alt in ['issue', 'description', 'point', 'buyer', 'user', 
                                    'scenario', 'motivation', 'what', 'where', 'when', 'why']:
                            if alt in item:
                                item['insight'] = item[alt]
                                break
                    # ç¡®ä¿æœ‰ confidence å­—æ®µ
                    if 'confidence' not in item:
                        item['confidence'] = 'medium'
                    # ç¡®ä¿æœ‰ evidence å­—æ®µ
                    if 'evidence' not in item:
                        item['evidence'] = []
        
        # ==========================================
        # ç»¼åˆæŠ¥å‘Šä¸“ç”¨ä¿®å¤ï¼šcore_swot
        # ==========================================
        if report_type == "comprehensive" and "core_swot" in result:
            swot = result["core_swot"]
            
            # å¦‚æœ core_swot æ˜¯æ•°ç»„æ ¼å¼ï¼Œè½¬æ¢ä¸ºå¯¹è±¡æ ¼å¼
            if isinstance(swot, list):
                logger.info(f"[æ ¼å¼ä¿®å¤] core_swot æ˜¯æ•°ç»„æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸ºå¯¹è±¡æ ¼å¼")
                
                # å°è¯•åŸºäºå…³é”®è¯åˆ†ç±»
                strengths = []
                weaknesses = []
                opportunities = []
                threats = []
                
                positive_keywords = ['ä¼˜åŠ¿', 'ä¼˜ç‚¹', 'å–ç‚¹', 'äº®ç‚¹', 'å¥½è¯„', 'æ»¡æ„', 'å‡ºè‰²', 'ä¼˜ç§€', 'é«˜è´¨é‡', 
                                     'ç»­èˆª', 'ä¿æ¸©', 'è®¾è®¡å¥½', 'åšå·¥å¥½', 'è´¨é‡å¥½', 'æ€§ä»·æ¯”', 'æ¨è', 'å–œæ¬¢', 'äº”æ˜Ÿ']
                negative_keywords = ['åŠ£åŠ¿', 'ç¼ºç‚¹', 'é—®é¢˜', 'ç—›ç‚¹', 'å·®è¯„', 'å¤±æœ›', 'ç³Ÿç³•', 'è´¨é‡å·®', 'æŸå', 
                                     'æ•…éšœ', 'åäº†', 'ä¸æ»¡', 'é€€è´§', 'å”®å', 'å……ç”µæ…¢', 'ç”µæ± è¡°å‡', 'ä¸è€ç”¨']
                opportunity_keywords = ['æœºä¼š', 'æ½œåŠ›', 'å¸‚åœº', 'å¢é•¿', 'éœ€æ±‚', 'è¶‹åŠ¿', 'ç©ºé—´', 'æ‹“å±•', 'åœºæ™¯']
                threat_keywords = ['å¨èƒ', 'é£é™©', 'ç«äº‰', 'æŒ‘æˆ˜', 'ä¸‹é™', 'æµå¤±', 'è´Ÿé¢', 'å±æœº']
                
                for item in swot:
                    if not isinstance(item, dict):
                        continue
                    
                    # è·å–æ–‡æœ¬å†…å®¹ç”¨äºåˆ†ç±»
                    text = str(item.get('insight', '') or item.get('point', '') or item.get('description', '')).lower()
                    
                    # è½¬æ¢å­—æ®µåï¼šinsight -> point
                    if 'insight' in item and 'point' not in item:
                        item['point'] = item['insight']
                    
                    # åŸºäºå…³é”®è¯åˆ†ç±»
                    is_positive = any(kw in text for kw in positive_keywords)
                    is_negative = any(kw in text for kw in negative_keywords)
                    is_opportunity = any(kw in text for kw in opportunity_keywords)
                    is_threat = any(kw in text for kw in threat_keywords)
                    
                    if is_threat or (is_negative and 'é£é™©' in text):
                        threats.append(item)
                    elif is_opportunity:
                        opportunities.append(item)
                    elif is_negative or ('é—®é¢˜' in text) or ('ç¼º' in text) or ('å·®' in text):
                        weaknesses.append(item)
                    else:
                        # é»˜è®¤å½’ç±»ä¸ºä¼˜åŠ¿
                        strengths.append(item)
                
                result["core_swot"] = {
                    "strengths": strengths,
                    "weaknesses": weaknesses,
                    "opportunities": opportunities,
                    "threats": threats
                }
                logger.info(f"[æ ¼å¼ä¿®å¤] core_swot è½¬æ¢å®Œæˆ: S={len(strengths)}, W={len(weaknesses)}, O={len(opportunities)}, T={len(threats)}")
            
            # å¦‚æœæ˜¯å¯¹è±¡æ ¼å¼ä½†ç¼ºå°‘æŸäº›åˆ†ç±»ï¼Œè¡¥å…¨
            elif isinstance(swot, dict):
                for key in ['strengths', 'weaknesses', 'opportunities', 'threats']:
                    if key not in swot:
                        swot[key] = []
                        logger.info(f"[æ ¼å¼ä¿®å¤] core_swot è¡¥å…¨ç¼ºå¤±å­—æ®µ: {key}")
                    elif not isinstance(swot[key], list):
                        swot[key] = [swot[key]] if swot[key] else []
        
        # ==========================================
        # ç»¼åˆæŠ¥å‘Šä¸“ç”¨ä¿®å¤ï¼špriority_actions
        # ==========================================
        if report_type == "comprehensive" and "priority_actions" in result:
            items = result["priority_actions"]
            if isinstance(items, list):
                for item in items:
                    # issue -> action è½¬æ¢
                    if 'issue' in item and 'action' not in item:
                        item['action'] = item['issue']
                        logger.info(f"[æ ¼å¼ä¿®å¤] priority_actions: issue -> action")
                    # ç¡®ä¿æœ‰ confidence å’Œ evidence
                    if 'confidence' not in item:
                        item['confidence'] = 'medium'
                    if 'evidence' not in item:
                        item['evidence'] = []
        
        # ==========================================
        # ç»¼åˆæŠ¥å‘Šä¸“ç”¨ä¿®å¤ï¼šdepartment_directives
        # ==========================================
        if report_type == "comprehensive" and "department_directives" in result:
            items = result["department_directives"]
            if isinstance(items, list):
                for i, item in enumerate(items):
                    # ç¡®ä¿æœ‰ insight å­—æ®µ
                    if 'insight' not in item:
                        for alt in ['directive', 'action', 'issue', 'description', 'content']:
                            if alt in item:
                                item['insight'] = item[alt]
                                break
                    # ç¡®ä¿æœ‰ department å­—æ®µ
                    if 'department' not in item:
                        item['department'] = item.get('to', f'æŒ‡ä»¤ {i+1}')
                    if 'confidence' not in item:
                        item['confidence'] = 'medium'
                    if 'evidence' not in item:
                        item['evidence'] = []
        
        # ==========================================
        # è¿è¥æŠ¥å‘Šä¸“ç”¨ä¿®å¤
        # ==========================================
        if report_type == "operations":
            # ä¿®å¤ target_audienceï¼šå¦‚æœæ˜¯åµŒå¥—ç»“æ„ï¼Œæå–å‡ºæ¥
            if "target_audience" in result:
                ta = result["target_audience"]
                if isinstance(ta, list) and len(ta) > 0:
                    first = ta[0]
                    # æ£€æŸ¥æ˜¯å¦åµŒå¥—äº†å…¶ä»–å­—æ®µ
                    if isinstance(first, dict) and any(k in first for k in ['user_profile', 'user_research', 'selling_points', 'critical_bugs']):
                        # æå–åµŒå¥—çš„ insight
                        extracted = []
                        for item in ta:
                            if isinstance(item, dict):
                                for key, value in item.items():
                                    if isinstance(value, list):
                                        extracted.extend(value)
                                    elif isinstance(value, dict) and 'insight' in value:
                                        extracted.append(value)
                        result["target_audience"] = extracted if extracted else [{"insight": "ç›®æ ‡å—ä¼—æ•°æ®æ ¼å¼å¼‚å¸¸", "confidence": "low", "evidence": []}]
                        logger.info(f"[æ ¼å¼ä¿®å¤] target_audience: ä¿®å¤åµŒå¥—ç»“æ„")
                elif isinstance(ta, dict):
                    # å¯¹è±¡è½¬æ•°ç»„
                    result["target_audience"] = [ta] if ta else []
            
            # ä¿®å¤ competitor_analysisï¼šå¦‚æœæ˜¯åµŒå¥—ç»“æ„ï¼Œæå–å‡ºæ¥
            if "competitor_analysis" in result:
                ca = result["competitor_analysis"]
                if isinstance(ca, list) and len(ca) > 0:
                    first = ca[0]
                    # æ£€æŸ¥æ˜¯å¦åµŒå¥—äº†å…¶ä»–å­—æ®µ
                    if isinstance(first, dict) and any(k in first for k in ['usage_context_analysis', 'material_defects', 'supplier_issues', 'qc_checklist']):
                        # æå–åµŒå¥—çš„ insight/issue
                        extracted = []
                        for item in ca:
                            if isinstance(item, dict):
                                for key, value in item.items():
                                    if isinstance(value, list):
                                        for v in value:
                                            if isinstance(v, dict) and ('insight' in v or 'issue' in v):
                                                # ç¡®ä¿æœ‰ insight
                                                if 'issue' in v and 'insight' not in v:
                                                    v['insight'] = v['issue']
                                                extracted.append(v)
                        result["competitor_analysis"] = extracted if extracted else []
                        logger.info(f"[æ ¼å¼ä¿®å¤] competitor_analysis: ä¿®å¤åµŒå¥—ç»“æ„")
                elif isinstance(ca, dict):
                    result["competitor_analysis"] = [ca] if ca else []
            
            # ä¿®å¤ selling_points, marketing_risks ç­‰æ•°ç»„å­—æ®µ
            for field in ["selling_points", "marketing_risks", "listing_optimization", "review_response_templates"]:
                if field in result and isinstance(result[field], list):
                    for item in result[field]:
                        if isinstance(item, dict):
                            # ç¡®ä¿æœ‰å†…å®¹å­—æ®µ
                            if 'insight' not in item and 'issue' not in item:
                                for alt in ['point', 'description', 'content', 'element', 'suggestion', 'response']:
                                    if alt in item:
                                        item['insight'] = item[alt]
                                        break
                            if 'confidence' not in item:
                                item['confidence'] = 'medium'
                            if 'evidence' not in item:
                                item['evidence'] = []
            
            # ä¿®å¤ executive_summaryï¼šå¦‚æœæ˜¯æ•°ç»„ï¼Œæå–ç¬¬ä¸€ä¸ªçš„ insight
            if "executive_summary" in result:
                es = result["executive_summary"]
                if isinstance(es, list) and len(es) > 0:
                    first = es[0]
                    if isinstance(first, dict) and 'insight' in first:
                        result["executive_summary"] = first['insight']
                        logger.info(f"[æ ¼å¼ä¿®å¤] executive_summary: æ•°ç»„è½¬å­—ç¬¦ä¸²")
        
        # ==========================================
        # äº§å“æŠ¥å‘Šä¸“ç”¨ä¿®å¤
        # ==========================================
        if report_type == "product":
            # ä¿®å¤æ•°ç»„å­—æ®µ
            for field in ["critical_bugs", "unmet_needs", "usability_issues", "design_recommendations"]:
                if field in result and isinstance(result[field], list):
                    for item in result[field]:
                        if isinstance(item, dict):
                            # issue/insight äº’æ¢
                            if field == "critical_bugs":
                                if 'insight' in item and 'issue' not in item:
                                    item['issue'] = item['insight']
                            else:
                                if 'issue' in item and 'insight' not in item:
                                    item['insight'] = item['issue']
                            if 'confidence' not in item:
                                item['confidence'] = 'medium'
                            if 'evidence' not in item:
                                item['evidence'] = []
        
        # ==========================================
        # ä¾›åº”é“¾æŠ¥å‘Šä¸“ç”¨ä¿®å¤ï¼šqc_checklist çš„ insight -> issue
        # ==========================================
        if report_type == "supply_chain" and "qc_checklist" in result:
            items = result["qc_checklist"]
            if isinstance(items, list):
                for item in items:
                    if isinstance(item, dict):
                        # insight -> issue è½¬æ¢ï¼ˆå‰ç«¯æœŸæœ› issueï¼‰
                        if 'insight' in item and 'issue' not in item:
                            item['issue'] = item['insight']
                            logger.info(f"[æ ¼å¼ä¿®å¤] qc_checklist: insight -> issue")
        
        logger.info(f"[æ ¼å¼ä¿®å¤] å®Œæˆ {report_type} æŠ¥å‘Šæ ¼å¼æ ‡å‡†åŒ–")
        return result
    
    def _format_stats_for_llm(
        self, 
        context: Dict[str, Any], 
        insight: Dict[str, Any],
        total_reviews: int
    ) -> str:
        """
        [æ ¸å¿ƒé€»è¾‘] å°† 5W (Context) å’Œ 5ç±» Insight æ•°æ®ç»“åˆæˆ LLM å¯è¯»çš„å™äº‹ç»“æ„ã€‚
        LLM ä¼šæ ¹æ®æ­¤ç»“æ„è¿›è¡Œäº¤å‰åˆ†æã€‚
        
        2026-01-14 å¢å¼ºï¼šä¼ å…¥ evidence è¯¦æƒ…ï¼ˆreview_id + quoteï¼‰ï¼Œæ”¯æŒè¯æ®æº¯æº
        
        5ç±» Insight:
        - strength: äº§å“ä¼˜åŠ¿/å–ç‚¹ -> ç”¨äº Listing äº”ç‚¹æè¿°
        - weakness: æ”¹è¿›ç©ºé—´/ç—›ç‚¹ -> ç”¨äºäº§å“æ”¹è¿›å’Œå®¢æœ QA
        - suggestion: ç”¨æˆ·å»ºè®® -> äº§å“ç»ç†ç›´æ¥éœ€æ±‚
        - scenario: è¡Œä¸ºæ•…äº‹ -> è¾¹ç¼˜åœºæ™¯å‘ç°/è¥é”€ç´ æ
        - emotion: æƒ…ç»ªé¢„è­¦ -> å®¢æœå’Œå…¬å…³å…³æ³¨
        """
        
        def get_fmt_with_evidence(data: Any, max_items: int = 3) -> str:
            """
            æ ¼å¼åŒ–æ•°æ®ï¼ŒåŒ…å«è¯æ®è¯¦æƒ…ï¼ˆç”¨äº AI å¼•ç”¨ï¼‰
            2026-01-14: ä¼˜åŒ– - å¤§å¹…å‡å°‘æ•°æ®é‡ä»¥æ§åˆ¶ Prompt é•¿åº¦
            """
            if isinstance(data, dict) and 'items' in data:
                items = data.get('items', [])
                total_count = data.get('total_count', 0)
            elif isinstance(data, list):
                items = data
                total_count = sum(x.get('value', 0) for x in items)
            else:
                return "æš‚æ— "
            
            if not items:
                return "æš‚æ— "
            
            result = []
            for item in items[:max_items]:
                entry = {
                    "tag": item['name'],
                    "count": item['value'],
                    "percent": f"{item.get('percent', 0):.1f}%"
                }
                # ä»…æ·»åŠ 1æ¡è¯æ®æ ·æœ¬
                evidence_list = item.get('evidence', [])
                if evidence_list:
                    e = evidence_list[0]
                    entry["quote"] = (e.get("quote", "") or "")[:50]
                result.append(entry)
            
            return json.dumps(result, ensure_ascii=False)
        
        # ç®€åŒ–æ ¼å¼ï¼ˆç”¨äºæ¦‚è§ˆï¼‰
        def get_fmt_simple(data: Any, max_items: int = 8) -> str:
            if isinstance(data, dict) and 'items' in data:
                items = data.get('items', [])
            elif isinstance(data, list):
                items = data
            else:
                return "æš‚æ— æ•°æ®"
            
            if not items:
                return "æš‚æ— æ•°æ®"
            
            formatted = [f"{x['name']}({x['value']}æ¬¡, {x.get('percent', 0):.1f}%)" for x in items[:max_items]]
            return ", ".join(formatted)

        return f"""
=== ğŸ“Š åŸºç¡€ä¿¡æ¯ ===
- åˆ†ææ ·æœ¬: {total_reviews} æ¡å·²ç¿»è¯‘è¯„è®º
- æ•°æ®è¯´æ˜: æ¯ä¸ªæ ‡ç­¾éƒ½é™„å¸¦ evidenceï¼ˆè¯æ®ï¼‰ï¼ŒåŒ…å« review_id å’Œ quoteï¼Œ**ä½ å¿…é¡»ä»è¿™äº›è¯æ®ä¸­å¼•ç”¨**

=== ğŸ“Š PART 1: 5W Context (å®è§‚ç”»åƒ) ===
ç”¨æˆ·ç”»åƒæ•°æ®ï¼Œç”¨äºç†è§£"è°åœ¨ä¹°ã€è°åœ¨ç”¨ã€åœ¨å“ªç”¨ã€ä»€ä¹ˆæ—¶å€™ç”¨ã€ä¸ºä»€ä¹ˆä¹°ã€ä¹°æ¥åšä»€ä¹ˆ"ã€‚

**æ¦‚è§ˆ:**
- Buyer (è´­ä¹°è€…): {get_fmt_simple(context.get('buyer', {}))}
- User (ä½¿ç”¨è€…): {get_fmt_simple(context.get('user', {}))}
- Where (ä½¿ç”¨åœ°ç‚¹): {get_fmt_simple(context.get('where', {}))}
- When (ä½¿ç”¨æ—¶æœº): {get_fmt_simple(context.get('when', {}))}
- Why (è´­ä¹°åŠ¨æœº): {get_fmt_simple(context.get('why', {}))}
- What (ç”¨æˆ·ä»»åŠ¡/JTBD): {get_fmt_simple(context.get('what', {}))}

**è¯¦ç»†æ•°æ®ï¼ˆå«è¯æ®ï¼Œç”¨äºå¼•ç”¨ï¼‰:**

[Buyer - è´­ä¹°è€…]:
{get_fmt_with_evidence(context.get('buyer', {}))}

[User - ä½¿ç”¨è€…]:
{get_fmt_with_evidence(context.get('user', {}))}

[Where - ä½¿ç”¨åœ°ç‚¹]:
{get_fmt_with_evidence(context.get('where', {}))}

[When - ä½¿ç”¨æ—¶æœº]:
{get_fmt_with_evidence(context.get('when', {}))}

[Why - è´­ä¹°åŠ¨æœº]:
{get_fmt_with_evidence(context.get('why', {}))}

[What - ç”¨æˆ·ä»»åŠ¡]:
{get_fmt_with_evidence(context.get('what', {}))}

=== ğŸ“‰ PART 2: Deep Insights (å¾®è§‚æ´å¯Ÿ - 5ç±») ===
åŸºäºè¯„è®ºå†…å®¹æå–çš„æ·±åº¦æ´å¯Ÿï¼Œæ¯ä¸ªæ´å¯Ÿéƒ½æœ‰è¯æ®æ”¯æŒã€‚

**æ¦‚è§ˆ:**
- Strength (ä¼˜åŠ¿/å–ç‚¹): {get_fmt_simple(insight.get('strength', {}))}
- Weakness (ç—›ç‚¹/é—®é¢˜): {get_fmt_simple(insight.get('weakness', {}))}
- Suggestion (ç”¨æˆ·å»ºè®®): {get_fmt_simple(insight.get('suggestion', {}))}
- Scenario (ä½¿ç”¨åœºæ™¯): {get_fmt_simple(insight.get('scenario', {}))}
- Emotion (æƒ…ç»ªåé¦ˆ): {get_fmt_simple(insight.get('emotion', {}))}

**è¯¦ç»†æ•°æ®ï¼ˆå«è¯æ®ï¼Œç”¨äºå¼•ç”¨ï¼‰:**

[Strength - äº§å“ä¼˜åŠ¿/å–ç‚¹]:
{get_fmt_with_evidence(insight.get('strength', {}))}
*ç”¨é€”ï¼šListing äº”ç‚¹æè¿°ã€å¹¿å‘Šæ–‡æ¡ˆã€å·®å¼‚åŒ–å–ç‚¹*

[Weakness - ç—›ç‚¹/é—®é¢˜]:
{get_fmt_with_evidence(insight.get('weakness', {}))}
*ç”¨é€”ï¼šäº§å“æ”¹è¿›ã€å®¢æœ QAã€å·®è¯„é¢„é˜²*

[Suggestion - ç”¨æˆ·å»ºè®®]:
{get_fmt_with_evidence(insight.get('suggestion', {}))}
*ç”¨é€”ï¼šäº§å“è·¯çº¿å›¾ã€åŠŸèƒ½éœ€æ±‚ã€ç”¨æˆ·æœŸæœ›*

[Scenario - ä½¿ç”¨åœºæ™¯]:
{get_fmt_with_evidence(insight.get('scenario', {}))}
*ç”¨é€”ï¼šè¾¹ç¼˜åœºæ™¯å‘ç°ã€è¥é”€æ•…äº‹ç´ æ*

[Emotion - æƒ…ç»ªåé¦ˆ]:
{get_fmt_with_evidence(insight.get('emotion', {}))}
*ç”¨é€”ï¼šå…¬å…³é¢„è­¦ã€å®¢æœé‡ç‚¹å…³æ³¨ã€NPS åˆ†æ*

=== ğŸ“‹ åˆ†ææŒ‡ä»¤ ===
1. **äº¤å‰åˆ†æ**: ç»“åˆ PART 1 ç”¨æˆ·ç”»åƒå’Œ PART 2 æ´å¯Ÿè¿›è¡Œå…³è”åˆ†æ
   - ä¾‹å¦‚ï¼šè€äººç”¨æˆ· + æŒ‰é”®å°ç—›ç‚¹ = é€‚è€åŒ–è®¾è®¡ç¼ºé™·
   - ä¾‹å¦‚ï¼šé€ç¤¼åœºæ™¯ + åŒ…è£…é—®é¢˜ = ç¤¼å“åŒ…è£…ä¼˜åŒ–éœ€æ±‚

2. **è¯æ®å¼•ç”¨**: æ¯ä¸ªåˆ†æç»“è®ºå¿…é¡»å¼•ç”¨çœŸå®çš„ review_id å’Œ quote
   - ä»ä¸Šè¿° evidence åˆ—è¡¨ä¸­é€‰å–
   - ä¸¥ç¦ç¼–é€ ä¸å­˜åœ¨çš„è¯æ®

3. **ç½®ä¿¡åº¦è¯„ä¼°**: åŸºäºè¯æ®æ•°é‡å’Œå¼ºåº¦è¯„ä¼°æ¯ä¸ªç»“è®ºçš„ç½®ä¿¡åº¦
   - high: â‰¥5æ¡è¯„è®ºæ˜ç¡®æ”¯æŒï¼Œå æ¯”â‰¥15%
   - medium: 2-4æ¡è¯„è®ºæ”¯æŒï¼Œå æ¯”10-15%
   - low: 1æ¡è¯„è®ºæˆ–å æ¯”<10%

4. **ä¸“ä¸šæ·±åº¦**: ä½¿ç”¨ä¸“ä¸šæœ¯è¯­ï¼Œç»™å‡ºå¯æ‰§è¡Œå»ºè®®
   - PMFï¼ˆäº§å“å¸‚åœºåŒ¹é…åº¦ï¼‰
   - JTBDï¼ˆç”¨æˆ·ä»»åŠ¡ï¼‰
   - NPSï¼ˆå‡€æ¨èå€¼è¶‹åŠ¿ï¼‰
   - CAC/LTVï¼ˆè·å®¢æˆæœ¬/ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸä»·å€¼ï¼‰
        """
    
    # --- æ•°æ®èšåˆæ–¹æ³• (è¿”å› ECharts æ ¼å¼) ---
    
    def _add_stats_metadata(self, items: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è¾…åŠ©æ–¹æ³•ï¼š
        1. è®¡ç®—æ€»æ•° (total_count)
        2. è®¡ç®—æ¯é¡¹å æ¯” (percent)
        3. å°è£…æˆå‰ç«¯å‹å¥½çš„ç»“æ„
        
        Return: {
            "total_count": 150,
            "items": [{"name": "è€äºº", "value": 45, "percent": 30.0, "evidence": [...]}]
        }
        """
        total_count = sum(item['value'] for item in items)
        
        for item in items:
            # è®¡ç®—å æ¯”ï¼Œä¿ç•™1ä½å°æ•°
            item['percent'] = round((item['value'] / total_count * 100), 1) if total_count > 0 else 0.0
        
        return {
            "total_count": total_count,  # è¯¥ç»´åº¦çš„æ€»æ ·æœ¬æ•°
            "items": items               # å·²æ’åºçš„åˆ—è¡¨ (å¸¦ percent)
        }
    
    async def _aggregate_5w_stats(self, product_id: UUID) -> Dict[str, Any]:
        """
        [Traceable] èšåˆ 5W æ•°æ®ï¼ŒåŒ…å«åŸæ–‡è¯æ®é”šç‚¹
        
        Return: {
            "who": {
                "total_count": 150,
                "items": [
                    {
                        "name": "è€äºº", 
                        "value": 45,
                        "percent": 30.0,
                        "evidence": [
                            {"review_id": "uuid-1", "quote": "ä½œä¸ºè€å¹´äºº...", "rating": 3, "date": "2024-01-15"},
                            ...
                        ]
                    }, 
                    ...
                ]
            },
            ...
        }
        """
        # æŸ¥è¯¢è¯¥äº§å“æ‰€æœ‰çš„ theme highlightsï¼ŒåŒæ—¶ JOIN Review è·å–åŸæ–‡
        review_ids_subquery = (
            select(Review.id)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.COMPLETED.value,
                    Review.is_deleted == False
                )
            )
        )
        
        result = await self.db.execute(
            select(ReviewThemeHighlight, Review)
            .join(Review, ReviewThemeHighlight.review_id == Review.id)
            .where(ReviewThemeHighlight.review_id.in_(review_ids_subquery))
        )
        rows = result.all()  # [(highlight, review), ...]
        
        # ç»“æ„: stats[type][tag_name] = {"count": 0, "samples": []}
        stats = defaultdict(lambda: defaultdict(lambda: {"count": 0, "samples": []}))
        
        for h, r in rows:
            name = ""
            quote = ""
            
                # æ–°ç‰ˆæ•°æ®ç»“æ„ï¼šä½¿ç”¨ label_name å­—æ®µ
            if h.label_name:
                name = h.label_name
                # ä¼˜å…ˆä½¿ç”¨ç¿»è¯‘åçš„ quoteï¼Œå¦åˆ™ä½¿ç”¨åŸæ–‡
                quote = h.quote_translated or h.quote or (r.body_translated[:80] if r.body_translated else (r.body_original[:80] if r.body_original else ""))
                quote_original = h.quote or (r.body_original[:80] if r.body_original else "")
            # å…¼å®¹æ—§ç‰ˆæ•°æ®ç»“æ„ï¼šä½¿ç”¨ items å­—æ®µ
            elif h.items:
                items_list = h.items if isinstance(h.items, list) else []
                for item in items_list:
                    if isinstance(item, dict):
                        name = item.get('content') or item.get('tag') or ""
                        quote = item.get('content_translated') or item.get('content_original') or item.get('quote') or (r.body_translated[:80] if r.body_translated else (r.body_original[:80] if r.body_original else ""))
                        quote_original = item.get('content_original') or item.get('quote') or (r.body_original[:80] if r.body_original else "")
                    elif isinstance(item, str):
                        name = item
                        quote = r.body_translated[:80] if r.body_translated else (r.body_original[:80] if r.body_original else "")
                        quote_original = r.body_original[:80] if r.body_original else ""
                    
                    if name:
                        entry = stats[h.theme_type][name]
                        entry["count"] += 1
                        # åªä¿ç•™å‰ 5 æ¡ä½œä¸ºç›´æ¥è¯æ® (é¿å… JSON è¿‡å¤§)
                        if len(entry["samples"]) < 5:
                            entry["samples"].append({
                                "review_id": str(r.id),
                                "quote": quote[:150],  # é™åˆ¶é•¿åº¦ï¼Œä¼˜å…ˆä½¿ç”¨ç¿»è¯‘
                                "quote_original": quote_original[:150] if quote_original != quote else None,  # å¦‚æœç¿»è¯‘å’ŒåŸæ–‡ä¸åŒï¼Œä¿å­˜åŸæ–‡
                                "rating": r.rating,
                                "date": r.review_date.strftime('%Y-%m-%d') if r.review_date else None
                            })
                continue  # items å¾ªç¯å¤„ç†å®Œæ¯•ï¼Œè·³è¿‡åç»­
            
            # å¤„ç† label_name çš„æƒ…å†µ
            if name:
                entry = stats[h.theme_type][name]
                entry["count"] += 1
                if len(entry["samples"]) < 5:
                    quote_original = h.quote or (r.body_original[:80] if r.body_original else "")
                    entry["samples"].append({
                        "review_id": str(r.id),
                        "quote": quote[:150],  # ä¼˜å…ˆä½¿ç”¨ç¿»è¯‘
                        "quote_original": quote_original[:150] if quote_original != quote else None,  # å¦‚æœç¿»è¯‘å’ŒåŸæ–‡ä¸åŒï¼Œä¿å­˜åŸæ–‡
                        "rating": r.rating,
                        "date": r.review_date.strftime('%Y-%m-%d') if r.review_date else None
                    })
        
        def get_top(theme_key: str, top_n: int = 10) -> List[Dict[str, Any]]:
            """è·å– Top Nï¼ŒåŒ…å«è¯æ® (é»˜è®¤ Top 10ï¼Œé€‚é…å°æ ·æœ¬)"""
            data = stats.get(theme_key, {})
            # [å…³é”®] ä¸¥æ ¼å€’åº + Top 10
            sorted_items = sorted(data.items(), key=lambda x: x[1]['count'], reverse=True)[:top_n]
            
            return [{
                "name": k, 
                "value": v["count"],
                "evidence": v["samples"]  # <--- æ³¨å…¥è¯æ®
            } for k, v in sorted_items]
        
        # è¿”å›å¸¦ total_count å’Œ percent çš„ç»“æ„
        # 2026-01-14: æ·»åŠ  buyer å’Œ user ç±»å‹ï¼Œå°† who æ‹†åˆ†ä¸ºè´­ä¹°è€…å’Œä½¿ç”¨è€…
        return {
            "buyer": self._add_stats_metadata(get_top(ThemeType.BUYER.value if hasattr(ThemeType, 'BUYER') else "buyer")),
            "user": self._add_stats_metadata(get_top(ThemeType.USER.value if hasattr(ThemeType, 'USER') else "user")),
            "who": self._add_stats_metadata(get_top(ThemeType.WHO.value if hasattr(ThemeType, 'WHO') else "who")),  # å…¼å®¹æ—§æ•°æ®
            "where": self._add_stats_metadata(get_top(ThemeType.WHERE.value if hasattr(ThemeType, 'WHERE') else "where")),
            "when": self._add_stats_metadata(get_top(ThemeType.WHEN.value if hasattr(ThemeType, 'WHEN') else "when")),
            "why": self._add_stats_metadata(get_top(ThemeType.WHY.value if hasattr(ThemeType, 'WHY') else "why")),
            "what": self._add_stats_metadata(get_top(ThemeType.WHAT.value if hasattr(ThemeType, 'WHAT') else "what"))
        }
    
    async def _aggregate_insight_stats(self, product_id: UUID) -> Dict[str, Any]:
        """
        [Traceable] èšåˆ 5 ç±» Insight æ•°æ®ï¼ŒåŒ…å«åŸæ–‡è¯æ®é”šç‚¹
        
        5ç±»æ´å¯Ÿç±»å‹ï¼š
        - strength: äº§å“ä¼˜åŠ¿/å–ç‚¹
        - weakness: æ”¹è¿›ç©ºé—´/ç—›ç‚¹  
        - suggestion: ç”¨æˆ·å»ºè®®/Feature Request
        - scenario: å…·ä½“ä½¿ç”¨åœºæ™¯/è¡Œä¸ºæ•…äº‹
        - emotion: å¼ºçƒˆæƒ…æ„Ÿæ´å¯Ÿ
        
        Return: {
            "strength": {
                "total_count": 80,
                "items": [
                    {
                        "name": "ç”µæ± ç»­èˆª", 
                        "value": 30,
                        "percent": 37.5,
                        "evidence": [
                            {"review_id": "uuid-1", "quote": "ç”µæ± èƒ½ç”¨å¾ˆä¹…...", "analysis": "ç”¨æˆ·ç§°èµç»­èˆª", "rating": 5},
                            ...
                        ]
                    }, 
                    ...
                ]
            },
            ...
        }
        """
        # æŸ¥è¯¢è¯¥äº§å“æ‰€æœ‰çš„ insightsï¼ŒåŒæ—¶ JOIN Review è·å–åŸæ–‡
        review_ids_subquery = (
            select(Review.id)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.COMPLETED.value,
                    Review.is_deleted == False
                )
            )
        )
        
        result = await self.db.execute(
            select(ReviewInsight, Review)
            .join(Review, ReviewInsight.review_id == Review.id)
            .where(ReviewInsight.review_id.in_(review_ids_subquery))
        )
        rows = result.all()  # [(insight, review), ...]
        
        # ç»“æ„: stats[insight_type][dimension] = {"count": 0, "samples": []}
        stats = defaultdict(lambda: defaultdict(lambda: {"count": 0, "samples": []}))
        
        # æ”¯æŒçš„ 5 ç±»æ´å¯Ÿç±»å‹
        valid_types = ["strength", "weakness", "suggestion", "scenario", "emotion"]
        
        for i, r in rows:
            if not i.insight_type or i.insight_type not in valid_types:
                continue
            
            # ç»´åº¦æ¸…æ´— (å¤„ç†ç©ºå€¼)
            dim_name = i.dimension if i.dimension and i.dimension not in ["å…¶ä»–", "Other", "å…¶å®ƒ"] else "General"
            
            entry = stats[i.insight_type][dim_name]
            entry["count"] += 1
            
            # åªä¿ç•™å‰ 5 æ¡ä½œä¸ºç›´æ¥è¯æ®
            if len(entry["samples"]) < 5:
                # ä¼˜å…ˆä½¿ç”¨ç¿»è¯‘åçš„å¼•ç”¨
                quote = i.quote_translated or i.quote or (r.body_translated[:100] if r.body_translated else (r.body_original[:100] if r.body_original else ""))
                quote_original = i.quote or (r.body_original[:100] if r.body_original else "")
                
                entry["samples"].append({
                    "review_id": str(r.id),
                    "quote": quote[:150],  # é™åˆ¶é•¿åº¦ï¼Œä¼˜å…ˆä½¿ç”¨ç¿»è¯‘
                    "quote_original": quote_original[:150] if quote_original != quote else None,  # å¦‚æœç¿»è¯‘å’ŒåŸæ–‡ä¸åŒï¼Œä¿å­˜åŸæ–‡
                    "analysis": i.analysis[:100] if i.analysis else None,  # AI å¯¹å•æ¡çš„åˆ†æ
                    "rating": r.rating,
                    "sentiment": r.sentiment if hasattr(r, 'sentiment') else None
                })
        
        def get_top(itype: str, top_n: int = 10) -> List[Dict[str, Any]]:
            """è·å– Top Nï¼ŒåŒ…å«è¯æ® (é»˜è®¤ Top 10ï¼Œé€‚é…å°æ ·æœ¬)"""
            data = stats.get(itype, {})
            # [å…³é”®] ä¸¥æ ¼å€’åº + Top 10
            sorted_items = sorted(data.items(), key=lambda x: x[1]['count'], reverse=True)[:top_n]
            
            return [{
                "name": k, 
                "value": v["count"],
                "evidence": v["samples"]  # <--- æ³¨å…¥è¯æ®
            } for k, v in sorted_items]
        
        # è¿”å›æ‰€æœ‰ 5 ä¸ªç±»å‹çš„æ•°æ®ï¼Œå¸¦ total_count å’Œ percent
        return {
            "strength": self._add_stats_metadata(get_top("strength")),
            "weakness": self._add_stats_metadata(get_top("weakness")),
            "suggestion": self._add_stats_metadata(get_top("suggestion")),
            "scenario": self._add_stats_metadata(get_top("scenario")),
            "emotion": self._add_stats_metadata(get_top("emotion"))
        }
    
    # --- æŠ¥å‘ŠæŸ¥è¯¢æ–¹æ³• ---
    
    async def get_latest_report(
        self, 
        product_id: UUID, 
        report_type: Optional[str] = None
    ) -> Optional[ProductReport]:
        """
        è·å–è¯¥äº§å“æœ€è¿‘çš„ä¸€ä»½æŠ¥å‘Šï¼ˆç§’å¼€ï¼Œä¸ç”¨é‡æ–°ç”Ÿæˆï¼‰
        
        Args:
            product_id: äº§å“ UUID
            report_type: å¯é€‰ï¼ŒæŒ‰ç±»å‹ç­›é€‰
            
        Returns:
            ProductReport å¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
        """
        stmt = select(ProductReport).where(
            and_(
                ProductReport.product_id == product_id,
                ProductReport.status == ReportStatus.COMPLETED.value
            )
        )
        
        if report_type:
            stmt = stmt.where(ProductReport.report_type == report_type)
        
        stmt = stmt.order_by(desc(ProductReport.created_at)).limit(1)
        
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()
    
    async def get_report_history(
        self, 
        product_id: UUID, 
        limit: int = 10,
        report_type: Optional[str] = None
    ) -> List[ProductReport]:
        """
        è·å–è¯¥äº§å“çš„å†å²æŠ¥å‘Šåˆ—è¡¨
        
        Args:
            product_id: äº§å“ UUID
            limit: è¿”å›æ•°é‡ï¼ˆé»˜è®¤ 10ï¼‰
            report_type: å¯é€‰ï¼ŒæŒ‰ç±»å‹ç­›é€‰
            
        Returns:
            ProductReport å¯¹è±¡åˆ—è¡¨
        """
        stmt = select(ProductReport).where(ProductReport.product_id == product_id)
        
        if report_type:
            stmt = stmt.where(ProductReport.report_type == report_type)
        
        stmt = stmt.order_by(desc(ProductReport.created_at)).limit(limit)
        
        result = await self.db.execute(stmt)
        return list(result.scalars().all())
    
    async def get_report_by_id(self, report_id: UUID) -> Optional[ProductReport]:
        """æ ¹æ® ID è·å–æŠ¥å‘Š"""
        result = await self.db.execute(
            select(ProductReport).where(ProductReport.id == report_id)
        )
        return result.scalar_one_or_none()
    
    async def delete_report(self, report_id: UUID) -> bool:
        """åˆ é™¤æŠ¥å‘Š"""
        report = await self.get_report_by_id(report_id)
        if not report:
            return False
        
        await self.db.delete(report)
        await self.db.commit()
        return True
    
    async def _get_product(self, product_id: UUID) -> Optional[Product]:
        """è·å–äº§å“ä¿¡æ¯"""
        result = await self.db.execute(
            select(Product).where(Product.id == product_id)
        )
        return result.scalar_one_or_none()
    
    async def _count_translated_reviews(self, product_id: UUID) -> int:
        """ç»Ÿè®¡å·²ç¿»è¯‘è¯„è®ºæ•°"""
        result = await self.db.execute(
            select(func.count(Review.id)).where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.COMPLETED.value,
                    Review.is_deleted == False
                )
            )
        )
        return result.scalar() or 0
    
    # --- å…¼å®¹æ—§ç‰ˆ API çš„æ–¹æ³• ---
    
    async def _aggregate_5w_stats_with_lists(self, product_id: UUID) -> tuple:
        """
        èšåˆ 5W æ•°æ®ï¼ˆå…¼å®¹æ—§ç‰ˆï¼ŒåŒæ—¶è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²å’Œåˆ—è¡¨ï¼‰
        """
        stats = await self._aggregate_5w_stats(product_id)
        
        # è¾…åŠ©å‡½æ•°ï¼šä»æ–°æ ¼å¼ä¸­æå– items åˆ—è¡¨
        def get_items(data: Any) -> List[Dict[str, Any]]:
            if isinstance(data, dict) and 'items' in data:
                return data.get('items', [])
            elif isinstance(data, list):
                return data
            else:
                return []
        
        def fmt_top(data: Any, top_n: int = 5) -> str:
            items = get_items(data)
            if not items:
                return "æ— "
            return ", ".join([f"{x['name']}({x['value']})" for x in items[:top_n]])
        
        def get_list(data: Any, top_n: int = 10) -> List[Dict[str, Any]]:
            items = get_items(data)
            return [{"name": x['name'], "count": x['value']} for x in items[:top_n]]
        
        # åˆå¹¶ Where å’Œ When ä¸º Scene
        where_str = fmt_top(stats.get('where', {}))
        when_str = fmt_top(stats.get('when', {}))
        
        formatted_stats = {
            "buyer": fmt_top(stats.get('buyer', {})),
            "user": fmt_top(stats.get('user', {})),
            "who": fmt_top(stats.get('who', {})),  # å…¼å®¹æ—§æ•°æ®
            "scene": f"{where_str} / {when_str}",
            "why": fmt_top(stats.get('why', {})),
            "what": fmt_top(stats.get('what', {}))
        }
        
        lists = {
            "buyer": get_list(stats.get('buyer', {})),
            "user": get_list(stats.get('user', {})),
            "who": get_list(stats.get('who', {})),  # å…¼å®¹æ—§æ•°æ®
            "where": get_list(stats.get('where', {})),
            "when": get_list(stats.get('when', {})),
            "why": get_list(stats.get('why', {})),
            "what": get_list(stats.get('what', {}))
        }
        
        return formatted_stats, lists
    
    async def _aggregate_insight_stats_with_lists(self, product_id: UUID) -> tuple:
        """
        èšåˆ 5 ç±» Insight æ•°æ®ï¼ˆå…¼å®¹æ—§ç‰ˆï¼ŒåŒæ—¶è¿”å›æ ¼å¼åŒ–å­—ç¬¦ä¸²å’Œåˆ—è¡¨ï¼‰
        
        5ç±»æ´å¯Ÿç±»å‹ï¼š
        - strength: äº§å“ä¼˜åŠ¿/å–ç‚¹
        - weakness: æ”¹è¿›ç©ºé—´/ç—›ç‚¹  
        - suggestion: ç”¨æˆ·å»ºè®®/Feature Request
        - scenario: å…·ä½“ä½¿ç”¨åœºæ™¯/è¡Œä¸ºæ•…äº‹
        - emotion: å¼ºçƒˆæƒ…æ„Ÿæ´å¯Ÿ
        """
        # æŸ¥è¯¢è¯¥äº§å“æ‰€æœ‰çš„ insightsï¼ˆéœ€è¦å®Œæ•´æ•°æ®ä»¥è·å– quotesï¼‰
        review_ids_subquery = (
            select(Review.id)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.COMPLETED.value,
                    Review.is_deleted == False
                )
            )
        )
        
        result = await self.db.execute(
            select(ReviewInsight)
            .where(ReviewInsight.review_id.in_(review_ids_subquery))
        )
        insights = result.scalars().all()
        
        # stats[insight_type][dimension] = {"count": 0, "quotes": []}
        data = defaultdict(lambda: defaultdict(lambda: {"count": 0, "quotes": []}))
        
        # æ”¯æŒçš„ 5 ç±»æ´å¯Ÿç±»å‹
        valid_types = ["strength", "weakness", "suggestion", "scenario", "emotion"]
        
        for insight in insights:
            if not insight.insight_type or insight.insight_type not in valid_types:
                continue
            
            # ç»´åº¦æ¸…æ´—
            dim = insight.dimension if insight.dimension and insight.dimension not in ["å…¶ä»–", "Other", "å…¶å®ƒ"] else "General"
            
            entry = data[insight.insight_type][dim]
            entry["count"] += 1
            
            # åªä¿ç•™å‰ 3 æ¡åŸæ–‡ä½œä¸ºè¯æ®
            if len(entry["quotes"]) < 3:
                quote = insight.quote_translated or insight.quote
                if quote and quote.strip():
                    entry["quotes"].append(quote[:50] + "..." if len(quote) > 50 else quote)
        
        def fmt_section(insight_type: str) -> str:
            sorted_dims = sorted(
                data[insight_type].items(),
                key=lambda x: x[1]["count"],
                reverse=True
            )[:6]
            
            if not sorted_dims:
                return "  - æš‚æ— æ˜¾è‘—æ•°æ®"
            
            lines = []
            for dim, info in sorted_dims:
                quotes_str = " | ".join([f'"{q}"' for q in info["quotes"][:2]])
                if quotes_str:
                    lines.append(f"  - **{dim}** ({info['count']}æ¬¡): {quotes_str}")
                else:
                    lines.append(f"  - **{dim}** ({info['count']}æ¬¡)")
            
            return "\n".join(lines)
        
        def get_list(insight_type: str, top_n: int = 10) -> list:
            sorted_dims = sorted(
                data[insight_type].items(),
                key=lambda x: x[1]["count"],
                reverse=True
            )[:top_n]
            
            return [
                {
                    "dimension": dim, 
                    "count": info["count"], 
                    "quotes": info["quotes"]
                } 
                for dim, info in sorted_dims
            ]
        
        # è¿”å›æ‰€æœ‰ 5 ç±»æ•°æ®
        formatted_stats = {
            "strength": fmt_section("strength"),
            "weakness": fmt_section("weakness"),
            "suggestion": fmt_section("suggestion"),
            "scenario": fmt_section("scenario"),
            "emotion": fmt_section("emotion")
        }
        
        lists = {
            "strength": get_list("strength"),
            "weakness": get_list("weakness"),
            "suggestion": get_list("suggestion"),
            "scenario": get_list("scenario"),
            "emotion": get_list("emotion")
        }
        
        return formatted_stats, lists
    
    async def get_report_preview(self, product_id: UUID) -> dict:
        """
        è·å–æŠ¥å‘Šé¢„è§ˆæ•°æ®ï¼ˆä¸è°ƒç”¨ AIï¼Œåªè¿”å›ç»Ÿè®¡æ•°æ®ï¼‰
        
        ç”¨äºå‰ç«¯å±•ç¤º"æ­£åœ¨åˆ†æ..."æ—¶çš„è¿›åº¦æç¤ºï¼Œ
        ä¹Ÿç”¨äºè°ƒè¯•å’ŒæŸ¥çœ‹åŸå§‹èšåˆæ•°æ®ã€‚
        """
        product = await self._get_product(product_id)
        if not product:
            return {"success": False, "error": "äº§å“ä¸å­˜åœ¨"}
        
        total_reviews = await self._count_translated_reviews(product_id)
        
        # è·å– ECharts æ ¼å¼çš„æ•°æ®
        context_stats = await self._aggregate_5w_stats(product_id)
        insight_stats = await self._aggregate_insight_stats(product_id)
        
        # åŒæ—¶è·å–æ—§ç‰ˆæ ¼å¼ï¼ˆç”¨äºå‰ç«¯å…¼å®¹ï¼‰
        context_formatted, context_lists = await self._aggregate_5w_stats_with_lists(product_id)
        insight_formatted, insight_lists = await self._aggregate_insight_stats_with_lists(product_id)
        
        # åŒæ—¶æ£€æŸ¥æ˜¯å¦æœ‰å†å²æŠ¥å‘Š
        latest_report = await self.get_latest_report(product_id)
        
        # è·å–å„ç±»å‹æŠ¥å‘Šæ•°é‡
        report_counts = {}
        for rt in [ReportType.COMPREHENSIVE.value, ReportType.OPERATIONS.value, 
                   ReportType.PRODUCT.value, ReportType.SUPPLY_CHAIN.value]:
            stmt = select(func.count(ProductReport.id)).where(
                and_(
                    ProductReport.product_id == product_id,
                    ProductReport.report_type == rt
                )
            )
            result = await self.db.execute(stmt)
            report_counts[rt] = result.scalar() or 0
        
        return {
            "success": True,
            "product": {
                "id": str(product.id),
                "asin": product.asin,
                "title": product.title_translated or product.title
            },
            "stats": {
                "total_reviews": total_reviews,
                # ECharts æ ¼å¼ï¼ˆæ–°ç‰ˆ - 5ç±» Insightï¼‰
                "context": context_stats,
                "insight": insight_stats,
                # å­—ç¬¦ä¸²æ ¼å¼ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰
                "context_stats": context_formatted,
                "insight_stats": insight_formatted,
                # åˆ—è¡¨æ ¼å¼ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰- 5W Context
                "top_buyer": context_lists.get("buyer", [])[:5],
                "top_user": context_lists.get("user", [])[:5],
                "top_who": context_lists.get("who", [])[:5],  # å…¼å®¹æ—§æ•°æ®
                "top_where": context_lists.get("where", [])[:5],
                "top_when": context_lists.get("when", [])[:5],
                "top_why": context_lists.get("why", [])[:5],
                "top_what": context_lists.get("what", [])[:5],
                # åˆ—è¡¨æ ¼å¼ï¼ˆå…¼å®¹æ—§ç‰ˆï¼‰- 5ç±» Insight
                "top_strengths": insight_lists.get("strength", [])[:5],
                "top_weaknesses": insight_lists.get("weakness", [])[:5],
                "top_suggestions": insight_lists.get("suggestion", [])[:5],
                "top_scenarios": insight_lists.get("scenario", [])[:5],
                "top_emotions": insight_lists.get("emotion", [])[:5]
            },
            "report_counts": report_counts,
            "has_existing_report": latest_report is not None,
            "latest_report_id": str(latest_report.id) if latest_report else None,
            "latest_report_date": latest_report.created_at.isoformat() if latest_report else None,
            "latest_report_type": latest_report.report_type if latest_report else None
        }
