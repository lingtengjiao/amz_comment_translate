"""
åˆ†äº«æœåŠ¡ (Share Service)

æä¾›åˆ†äº«é“¾æ¥çš„åˆ›å»ºã€éªŒè¯ã€æ’¤é”€ç­‰åŠŸèƒ½ã€‚
æ”¯æŒå°†è¯„è®ºè¯¦æƒ…é¡µã€æŠ¥å‘Šè¯¦æƒ…é¡µã€ç«å“å¯¹æ¯”åˆ†æã€å¸‚åœºå“ç±»åˆ†æã€Rufus è°ƒç ”è¯¦æƒ…é¡µ
åˆ†äº«ç»™æœªç™»å½•ç”¨æˆ·æŸ¥çœ‹ã€‚

æ€§èƒ½ä¼˜åŒ–ï¼š
- Redis ç¼“å­˜ï¼šåˆ†äº«æ•°æ®ç¼“å­˜ 5 åˆ†é’Ÿ
- åˆ†é¡µåŠ è½½ï¼šè¯„è®ºåˆ—è¡¨å»¶è¿ŸåŠ è½½ï¼Œæ”¯æŒåˆ†é¡µ
"""
import json
import logging
from datetime import datetime, timezone, timedelta
from typing import Optional, List, Dict, Any, Tuple
from uuid import UUID

from sqlalchemy import select, update, and_, func
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from app.models.share_link import ShareLink, ShareResourceType

# ==========================================
# åˆ†äº«æ•°æ®ç¼“å­˜é…ç½®
# ==========================================
CACHE_PREFIX_SHARE = "cache:share:"
CACHE_TTL_SHARE_DATA = 300  # åˆ†äº«æ•°æ®ç¼“å­˜ 5 åˆ†é’Ÿ
CACHE_TTL_SHARE_REVIEWS = 300  # åˆ†é¡µè¯„è®ºç¼“å­˜ 5 åˆ†é’Ÿ
from app.models.product import Product
from app.models.report import ProductReport
from app.models.analysis import AnalysisProject
from app.models.rufus_conversation import RufusConversation
from app.models.review import Review
from app.models.keyword_collection import KeywordCollection
from app.models.collection_product import CollectionProduct
from app.models.insight import ReviewInsight
from app.models.theme_highlight import ReviewThemeHighlight
from app.models.product_dimension import ProductDimension
from app.models.product_context_label import ProductContextLabel

logger = logging.getLogger(__name__)


class ShareService:
    """åˆ†äº«æœåŠ¡"""
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    # ==========================================
    # åˆ›å»ºåˆ†äº«é“¾æ¥
    # ==========================================
    
    async def create_share_link(
        self,
        user_id: UUID,
        resource_type: ShareResourceType,
        resource_id: Optional[UUID] = None,
        asin: Optional[str] = None,
        title: Optional[str] = None,
        expires_in_days: Optional[int] = None
    ) -> ShareLink:
        """
        åˆ›å»ºåˆ†äº«é“¾æ¥
        
        Args:
            user_id: åˆ›å»ºè€…ç”¨æˆ· ID
            resource_type: èµ„æºç±»å‹
            resource_id: èµ„æº IDï¼ˆæŠ¥å‘Š/åˆ†æé¡¹ç›®/ä¼šè¯ UUIDï¼‰
            asin: ASINï¼ˆç”¨äºè¯„è®ºè¯¦æƒ…/æŠ¥å‘Šï¼‰
            title: åˆ†äº«æ ‡é¢˜
            expires_in_days: è¿‡æœŸå¤©æ•°ï¼ˆNone è¡¨ç¤ºæ°¸ä¹…ï¼‰
            
        Returns:
            åˆ›å»ºçš„ ShareLink å¯¹è±¡
        """
        # éªŒè¯èµ„æºæ˜¯å¦å­˜åœ¨
        await self._validate_resource_exists(resource_type, resource_id, asin)
        
        # è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not title:
            title = await self._generate_title(resource_type, resource_id, asin)
        
        # è®¡ç®—è¿‡æœŸæ—¶é—´
        expires_at = None
        if expires_in_days:
            expires_at = datetime.now(timezone.utc) + timedelta(days=expires_in_days)
        
        # åˆ›å»ºåˆ†äº«é“¾æ¥
        share_link = ShareLink(
            user_id=user_id,
            resource_type=resource_type.value,
            resource_id=resource_id,
            asin=asin,
            title=title,
            expires_at=expires_at
        )
        
        self.db.add(share_link)
        await self.db.commit()
        await self.db.refresh(share_link)
        
        logger.info(f"åˆ›å»ºåˆ†äº«é“¾æ¥: token={share_link.token}, type={resource_type.value}, user={user_id}")
        return share_link
    
    async def _validate_resource_exists(
        self,
        resource_type: ShareResourceType,
        resource_id: Optional[UUID],
        asin: Optional[str]
    ) -> None:
        """éªŒè¯èµ„æºæ˜¯å¦å­˜åœ¨"""
        if resource_type == ShareResourceType.REVIEW_READER:
            if not asin:
                raise ValueError("è¯„è®ºè¯¦æƒ…é¡µåˆ†äº«éœ€è¦æä¾› ASIN")
            result = await self.db.execute(
                select(Product).where(Product.asin == asin)
            )
            if not result.scalar_one_or_none():
                raise ValueError(f"äº§å“ä¸å­˜åœ¨: {asin}")
                
        elif resource_type == ShareResourceType.REPORT:
            if not resource_id:
                raise ValueError("æŠ¥å‘Šåˆ†äº«éœ€è¦æä¾›æŠ¥å‘Š ID")
            result = await self.db.execute(
                select(ProductReport).where(ProductReport.id == resource_id)
            )
            if not result.scalar_one_or_none():
                raise ValueError(f"æŠ¥å‘Šä¸å­˜åœ¨: {resource_id}")
                
        elif resource_type == ShareResourceType.ANALYSIS_PROJECT:
            if not resource_id:
                raise ValueError("åˆ†æé¡¹ç›®åˆ†äº«éœ€è¦æä¾›é¡¹ç›® ID")
            result = await self.db.execute(
                select(AnalysisProject).where(AnalysisProject.id == resource_id)
            )
            if not result.scalar_one_or_none():
                raise ValueError(f"åˆ†æé¡¹ç›®ä¸å­˜åœ¨: {resource_id}")
                
        elif resource_type == ShareResourceType.RUFUS_SESSION:
            # Rufus ä½¿ç”¨è™šæ‹Ÿ session_id æ ¼å¼:
            # - asin_XXXXX: äº§å“è¯¦æƒ…é¡µå¯¹è¯
            # - keyword_XXXXX: å…³é”®è¯æœç´¢å¯¹è¯
            # - æ™®é€š session_id: é¦–é¡µå¯¹è¯
            if not asin:
                raise ValueError("Rufus ä¼šè¯åˆ†äº«éœ€è¦æä¾› session_id")
            
            # æ ¹æ®è™šæ‹Ÿ session_id æ ¼å¼æ„å»ºæŸ¥è¯¢
            if asin.startswith('asin_'):
                # æŒ‰ ASIN æŸ¥è¯¢äº§å“è¯¦æƒ…é¡µå¯¹è¯
                real_asin = asin[5:]  # å»æ‰ "asin_" å‰ç¼€
                result = await self.db.execute(
                    select(RufusConversation).where(
                        RufusConversation.asin == real_asin,
                        RufusConversation.page_type == 'product_detail'
                    ).limit(1)
                )
            elif asin.startswith('keyword_'):
                # æŒ‰å…³é”®è¯æŸ¥è¯¢æœç´¢é¡µå¯¹è¯
                keyword = asin[8:]  # å»æ‰ "keyword_" å‰ç¼€
                result = await self.db.execute(
                    select(RufusConversation).where(
                        RufusConversation.keyword == keyword,
                        RufusConversation.page_type == 'keyword_search'
                    ).limit(1)
                )
            else:
                # æ™®é€š session_id
                result = await self.db.execute(
                    select(RufusConversation).where(RufusConversation.session_id == asin).limit(1)
                )
            
            if not result.scalar_one_or_none():
                raise ValueError(f"Rufus ä¼šè¯ä¸å­˜åœ¨: {asin}")
                
        elif resource_type == ShareResourceType.KEYWORD_COLLECTION:
            if not resource_id:
                raise ValueError("äº§å“ç”»æ¿åˆ†äº«éœ€è¦æä¾›é›†åˆ ID")
            result = await self.db.execute(
                select(KeywordCollection).where(KeywordCollection.id == resource_id)
            )
            if not result.scalar_one_or_none():
                raise ValueError(f"äº§å“ç”»æ¿ä¸å­˜åœ¨: {resource_id}")
    
    async def _generate_title(
        self,
        resource_type: ShareResourceType,
        resource_id: Optional[UUID],
        asin: Optional[str]
    ) -> str:
        """è‡ªåŠ¨ç”Ÿæˆåˆ†äº«æ ‡é¢˜"""
        if resource_type == ShareResourceType.REVIEW_READER:
            result = await self.db.execute(
                select(Product).where(Product.asin == asin)
            )
            product = result.scalar_one_or_none()
            if product:
                title = product.title_translated or product.title or asin
                return f"è¯„è®ºè¯¦æƒ… - {title[:50]}"
            return f"è¯„è®ºè¯¦æƒ… - {asin}"
            
        elif resource_type == ShareResourceType.REPORT:
            result = await self.db.execute(
                select(ProductReport).where(ProductReport.id == resource_id)
            )
            report = result.scalar_one_or_none()
            if report and report.title:
                return report.title
            return "äº§å“åˆ†ææŠ¥å‘Š"
            
        elif resource_type == ShareResourceType.ANALYSIS_PROJECT:
            result = await self.db.execute(
                select(AnalysisProject).where(AnalysisProject.id == resource_id)
            )
            project = result.scalar_one_or_none()
            if project:
                return project.title
            return "ç«å“å¯¹æ¯”åˆ†æ"
            
        elif resource_type == ShareResourceType.RUFUS_SESSION:
            return "Rufus AI è°ƒç ”"
            
        elif resource_type == ShareResourceType.KEYWORD_COLLECTION:
            result = await self.db.execute(
                select(KeywordCollection).where(KeywordCollection.id == resource_id)
            )
            collection = result.scalar_one_or_none()
            if collection:
                return f"å¸‚åœºæ ¼å±€åˆ†æ - {collection.keyword}"
            return "å¸‚åœºæ ¼å±€åˆ†æ"
            
        return "åˆ†äº«é“¾æ¥"
    
    # ==========================================
    # è·å–åˆ†äº«é“¾æ¥
    # ==========================================
    
    async def get_share_link_by_token(self, token: str) -> Optional[ShareLink]:
        """é€šè¿‡ä»¤ç‰Œè·å–åˆ†äº«é“¾æ¥"""
        result = await self.db.execute(
            select(ShareLink).where(ShareLink.token == token)
        )
        return result.scalar_one_or_none()
    
    async def get_user_share_links(
        self,
        user_id: UUID,
        resource_type: Optional[ShareResourceType] = None,
        include_expired: bool = False
    ) -> List[ShareLink]:
        """è·å–ç”¨æˆ·åˆ›å»ºçš„åˆ†äº«é“¾æ¥åˆ—è¡¨"""
        conditions = [ShareLink.user_id == user_id]
        
        if resource_type:
            conditions.append(ShareLink.resource_type == resource_type.value)
        
        if not include_expired:
            conditions.append(ShareLink.is_active == True)
        
        result = await self.db.execute(
            select(ShareLink)
            .where(and_(*conditions))
            .order_by(ShareLink.created_at.desc())
        )
        return list(result.scalars().all())
    
    # ==========================================
    # éªŒè¯å¹¶è·å–èµ„æºæ•°æ®
    # ==========================================
    
    async def validate_and_get_resource(self, token: str, skip_increment: bool = False) -> Dict[str, Any]:
        """
        éªŒè¯åˆ†äº«ä»¤ç‰Œå¹¶è¿”å›èµ„æºæ•°æ®ï¼ˆå¸¦ Redis ç¼“å­˜ï¼‰
        
        Args:
            token: åˆ†äº«ä»¤ç‰Œ
            skip_increment: æ˜¯å¦è·³è¿‡è®¿é—®æ¬¡æ•°å¢åŠ ï¼ˆç”¨äºåˆ·æ–°é¡µé¢ç­‰åœºæ™¯ï¼‰
            
        Returns:
            åŒ…å«èµ„æºç±»å‹å’Œæ•°æ®çš„å­—å…¸
            
        Raises:
            ValueError: é“¾æ¥æ— æ•ˆæˆ–å·²è¿‡æœŸ
        """
        share_link = await self.get_share_link_by_token(token)
        
        if not share_link:
            raise ValueError("åˆ†äº«é“¾æ¥ä¸å­˜åœ¨")
        
        if not share_link.is_active:
            raise ValueError("åˆ†äº«é“¾æ¥å·²è¢«æ’¤é”€")
        
        if share_link.is_expired:
            raise ValueError("åˆ†äº«é“¾æ¥å·²è¿‡æœŸ")
        
        # å¢åŠ è®¿é—®æ¬¡æ•°ï¼ˆä»…åœ¨é¦–æ¬¡è®¿é—®æ—¶ï¼‰
        if not skip_increment:
            share_link.view_count += 1
            await self.db.commit()
        
        # å°è¯•ä»ç¼“å­˜è·å–æ•°æ®
        cache_key = f"{CACHE_PREFIX_SHARE}data:{token}"
        cached_data = await self._get_from_cache(cache_key)
        if cached_data:
            logger.debug(f"åˆ†äº«æ•°æ®å‘½ä¸­ç¼“å­˜: {token}")
            # æ›´æ–° view_countï¼ˆç¼“å­˜ä¸­çš„å¯èƒ½è¿‡æ—¶ï¼‰
            cached_data["view_count"] = share_link.view_count
            return cached_data
        
        # æ ¹æ®èµ„æºç±»å‹è·å–æ•°æ®
        resource_type = ShareResourceType(share_link.resource_type)
        data = await self._get_resource_data(resource_type, share_link.resource_id, share_link.asin)
        
        result = {
            "resource_type": resource_type.value,
            "title": share_link.title,
            "created_at": share_link.created_at.isoformat() if share_link.created_at else None,
            "view_count": share_link.view_count,
            "data": data
        }
        
        # å†™å…¥ç¼“å­˜
        await self._set_to_cache(cache_key, result, CACHE_TTL_SHARE_DATA)
        logger.info(f"åˆ†äº«æ•°æ®å†™å…¥ç¼“å­˜: {token}")
        
        return result
    
    async def _get_from_cache(self, key: str) -> Optional[Dict[str, Any]]:
        """ä» Redis è·å–ç¼“å­˜æ•°æ®"""
        try:
            from app.core.cache import get_cache_service
            cache = await get_cache_service()
            return await cache.get(key)
        except Exception as e:
            logger.warning(f"è·å–ç¼“å­˜å¤±è´¥ {key}: {e}")
            return None
    
    async def _set_to_cache(self, key: str, value: Dict[str, Any], ttl: int) -> bool:
        """å†™å…¥ Redis ç¼“å­˜"""
        try:
            from app.core.cache import get_cache_service
            cache = await get_cache_service()
            return await cache.set(key, value, ttl)
        except Exception as e:
            logger.warning(f"å†™å…¥ç¼“å­˜å¤±è´¥ {key}: {e}")
            return False
    
    async def invalidate_share_cache(self, token: str) -> bool:
        """ä½¿åˆ†äº«æ•°æ®ç¼“å­˜å¤±æ•ˆ"""
        try:
            from app.core.cache import get_cache_service
            cache = await get_cache_service()
            await cache.delete(f"{CACHE_PREFIX_SHARE}data:{token}")
            await cache.delete_pattern(f"{CACHE_PREFIX_SHARE}reviews:{token}:*")
            logger.info(f"å·²æ¸…é™¤åˆ†äº«ç¼“å­˜: {token}")
            return True
        except Exception as e:
            logger.warning(f"æ¸…é™¤ç¼“å­˜å¤±è´¥ {token}: {e}")
            return False
    
    async def _get_resource_data(
        self,
        resource_type: ShareResourceType,
        resource_id: Optional[UUID],
        asin: Optional[str]
    ) -> Dict[str, Any]:
        """è·å–èµ„æºçš„å®Œæ•´æ•°æ®"""
        if resource_type == ShareResourceType.REVIEW_READER:
            return await self._get_review_reader_data(asin)
        elif resource_type == ShareResourceType.REPORT:
            return await self._get_report_data(resource_id)
        elif resource_type == ShareResourceType.ANALYSIS_PROJECT:
            return await self._get_analysis_project_data(resource_id)
        elif resource_type == ShareResourceType.RUFUS_SESSION:
            return await self._get_rufus_session_data(asin)
        elif resource_type == ShareResourceType.KEYWORD_COLLECTION:
            return await self._get_keyword_collection_data(resource_id)
        
        return {}
    
    async def _get_review_reader_data(self, asin: str) -> Dict[str, Any]:
        """è·å–è¯„è®ºè¯¦æƒ…é¡µæ•°æ®ï¼ˆåŒ…å«å®Œæ•´æ´å¯Ÿå’Œä¸»é¢˜ä¿¡æ¯ï¼‰"""
        import json
        from collections import defaultdict
        
        # è·å–äº§å“ä¿¡æ¯
        result = await self.db.execute(
            select(Product).where(Product.asin == asin)
        )
        product = result.scalar_one_or_none()
        
        if not product:
            raise ValueError(f"äº§å“ä¸å­˜åœ¨: {asin}")
        
        # è·å–è¯„è®ºåˆ—è¡¨ï¼ˆé€šè¿‡ product_id å…³è”ï¼‰
        review_result = await self.db.execute(
            select(Review)
            .where(Review.product_id == product.id)
            .order_by(Review.review_date.desc().nullslast())
            .limit(500)  # é™åˆ¶æ•°é‡
        )
        reviews = list(review_result.scalars().all())
        review_ids = [r.id for r in reviews]
        
        # è·å–æ‰€æœ‰è¯„è®ºçš„ insights
        insights_result = await self.db.execute(
            select(ReviewInsight)
            .where(ReviewInsight.review_id.in_(review_ids))
        )
        insights_map = defaultdict(list)
        for insight in insights_result.scalars().all():
            insights_map[insight.review_id].append({
                "type": insight.insight_type,
                "quote": insight.quote,
                "quote_translated": insight.quote_translated,
                "analysis": insight.analysis,
                "dimension": insight.dimension,
                "confidence": insight.confidence or "high",
            })
        
        # ğŸš€ è·å–é¢„è§ˆè¯„è®ºçš„ theme_highlightsï¼ˆç”¨äºè¯„è®ºè¯¦æƒ…å±•ç¤ºï¼‰
        themes_result = await self.db.execute(
            select(ReviewThemeHighlight)
            .where(ReviewThemeHighlight.review_id.in_(review_ids))
        )
        themes_map = defaultdict(list)
        for theme in themes_result.scalars().all():
            # æ„å»º items æ•°ç»„ï¼ˆå‘åå…¼å®¹æ—§æ ¼å¼ï¼‰
            items = []
            if theme.label_name:
                items.append({
                    "content": theme.label_name,
                    "content_original": theme.quote,
                    "quote_translated": theme.quote_translated,
                    "explanation": theme.explanation,
                    "confidence": theme.confidence or "high",
                })
            elif theme.items:
                items = theme.items if isinstance(theme.items, list) else []
            
            themes_map[theme.review_id].append({
                "theme_type": theme.theme_type,
                "label_name": theme.label_name,
                "items": items,
            })
        
        # è§£æ bullet_points
        bullet_points = []
        if product.bullet_points_translated:
            try:
                bullet_points = json.loads(product.bullet_points_translated)
                if not isinstance(bullet_points, list):
                    bullet_points = []
            except:
                bullet_points = []
        
        # è®¡ç®—è¯„åˆ†åˆ†å¸ƒ
        rating_distribution = {5: 0, 4: 0, 3: 0, 2: 0, 1: 0}
        for r in reviews:
            if 1 <= r.rating <= 5:
                rating_distribution[r.rating] += 1
        
        # è®¡ç®—æƒ…æ„Ÿåˆ†å¸ƒ
        sentiment_distribution = {"positive": 0, "neutral": 0, "negative": 0}
        for r in reviews:
            if r.sentiment in sentiment_distribution:
                sentiment_distribution[r.sentiment] += 1
        
        # èšåˆ insights
        aggregated_insights = {
            "strengths": [],
            "weaknesses": [],
            "suggestions": [],
            "scenarios": [],
            "emotions": [],
        }
        for review_id, insights_list in insights_map.items():
            for insight in insights_list:
                insight_type = insight["type"]
                if insight_type == "strength":
                    aggregated_insights["strengths"].append({
                        "review_id": str(review_id),
                        "quote": insight["quote"],
                        "quote_translated": insight["quote_translated"],
                        "analysis": insight["analysis"],
                        "dimension": insight["dimension"],
                    })
                elif insight_type == "weakness":
                    aggregated_insights["weaknesses"].append({
                        "review_id": str(review_id),
                        "quote": insight["quote"],
                        "quote_translated": insight["quote_translated"],
                        "analysis": insight["analysis"],
                        "dimension": insight["dimension"],
                    })
                elif insight_type == "suggestion":
                    aggregated_insights["suggestions"].append({
                        "review_id": str(review_id),
                        "quote": insight["quote"],
                        "quote_translated": insight["quote_translated"],
                        "analysis": insight["analysis"],
                        "dimension": insight["dimension"],
                    })
                elif insight_type == "scenario":
                    aggregated_insights["scenarios"].append({
                        "review_id": str(review_id),
                        "quote": insight["quote"],
                        "quote_translated": insight["quote_translated"],
                        "analysis": insight["analysis"],
                        "dimension": insight["dimension"],
                    })
                elif insight_type == "emotion":
                    aggregated_insights["emotions"].append({
                        "review_id": str(review_id),
                        "quote": insight["quote"],
                        "quote_translated": insight["quote_translated"],
                        "analysis": insight["analysis"],
                        "dimension": insight["dimension"],
                    })
        
        # ğŸš€ è·å–äº§å“æ‰€æœ‰è¯„è®ºçš„ theme_highlightsï¼ˆç”¨äºæ„å»ºå®Œæ•´çš„ aggregated_themesï¼‰
        # è¿™é‡Œä½¿ç”¨ JOIN æŸ¥è¯¢ï¼Œä¸å†é™åˆ¶äºé¢„è§ˆè¯„è®º
        all_themes_result = await self.db.execute(
            select(ReviewThemeHighlight)
            .join(Review, ReviewThemeHighlight.review_id == Review.id)
            .where(Review.product_id == product.id)
        )
        
        # èšåˆ themesï¼ˆä»äº§å“æ‰€æœ‰è¯„è®ºæ„å»ºï¼Œç¡®ä¿æ•°æ®å®Œæ•´ï¼‰
        aggregated_themes = {
            "buyer": defaultdict(lambda: {"count": 0, "review_ids": []}),
            "user": defaultdict(lambda: {"count": 0, "review_ids": []}),
            "who": defaultdict(lambda: {"count": 0, "review_ids": []}),
            "where": defaultdict(lambda: {"count": 0, "review_ids": []}),
            "when": defaultdict(lambda: {"count": 0, "review_ids": []}),
            "why": defaultdict(lambda: {"count": 0, "review_ids": []}),
            "what": defaultdict(lambda: {"count": 0, "review_ids": []}),
        }
        
        for theme in all_themes_result.scalars().all():
            theme_type = theme.theme_type
            label_name = theme.label_name
            review_id = str(theme.review_id)
            
            if theme_type in aggregated_themes and label_name:
                if review_id not in aggregated_themes[theme_type][label_name]["review_ids"]:
                    aggregated_themes[theme_type][label_name]["count"] += 1
                    aggregated_themes[theme_type][label_name]["review_ids"].append(review_id)
        
        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        for theme_type in aggregated_themes:
            aggregated_themes[theme_type] = [
                {
                    "label": label,
                    "count": data["count"],
                    "review_ids": data["review_ids"],
                }
                for label, data in aggregated_themes[theme_type].items()
            ]
            # æŒ‰æ•°é‡æ’åº
            aggregated_themes[theme_type].sort(key=lambda x: x["count"], reverse=True)
        
        # è·å–äº§å“ç»´åº¦ï¼ˆproduct_dimensionsï¼‰
        dimensions_result = await self.db.execute(
            select(ProductDimension)
            .where(ProductDimension.product_id == product.id)
            .order_by(ProductDimension.created_at)
        )
        product_dimensions = [
            {
                "id": str(d.id),
                "name": d.name,
                "description": d.description,
                "dimension_type": d.dimension_type,
                "is_ai_generated": d.is_ai_generated,
            }
            for d in dimensions_result.scalars().all()
        ]
        
        # è·å–äº§å“ä¸Šä¸‹æ–‡æ ‡ç­¾ï¼ˆproduct_context_labelsï¼‰- å·²èšåˆçš„5Wæ•°æ®
        context_labels_result = await self.db.execute(
            select(ProductContextLabel)
            .where(ProductContextLabel.product_id == product.id)
            .order_by(ProductContextLabel.count.desc())
        )
        context_labels = {}
        for label in context_labels_result.scalars().all():
            label_type = label.type
            if label_type not in context_labels:
                context_labels[label_type] = []
            context_labels[label_type].append({
                "id": str(label.id),
                "name": label.name,
                "description": label.description,
                "count": label.count,
            })
        
        # æŒ‰ç»´åº¦ç»Ÿè®¡ insightsï¼ˆç”¨äºç»´åº¦å¯¹æ¯”å¯è§†åŒ–ï¼‰
        dimension_insights = {}
        for insight_type in ["strengths", "weaknesses", "suggestions"]:
            for insight in aggregated_insights.get(insight_type, []):
                dim = insight.get("dimension") or "å…¶ä»–"
                if dim not in dimension_insights:
                    dimension_insights[dim] = {"strengths": 0, "weaknesses": 0, "suggestions": 0}
                dimension_insights[dim][insight_type] += 1
        
        # è·å–ç»´åº¦æ€»ç»“ï¼ˆä¸­è§‚å±‚AIåˆ†æï¼‰
        from app.models import ProductDimensionSummary
        summaries_result = await self.db.execute(
            select(ProductDimensionSummary)
            .where(ProductDimensionSummary.product_id == product.id)
            .order_by(ProductDimensionSummary.created_at)
        )
        dimension_summaries = [
            s.to_dict() for s in summaries_result.scalars().all()
        ]
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šé¦–æ¬¡åªè¿”å›å‰10æ¡è¯„è®ºä½œä¸ºé¢„è§ˆï¼Œå®Œæ•´åˆ—è¡¨é€šè¿‡åˆ†é¡µæ¥å£åŠ è½½
        preview_reviews = reviews[:10]
        
        return {
            "product": {
                "asin": product.asin,
                "title": product.title_translated or product.title,
                "image_url": product.image_url,
                "marketplace": product.marketplace,
                "average_rating": float(product.average_rating) if product.average_rating else None,
                "review_count": len(reviews),
                "bullet_points_translated": product.bullet_points_translated,
            },
            "bullet_points": bullet_points,
            # åªè¿”å›å‰10æ¡è¯„è®ºé¢„è§ˆï¼Œå®Œæ•´åˆ—è¡¨é€šè¿‡ /{token}/reviews åˆ†é¡µæ¥å£è·å–
            "reviews": [
                {
                    "id": str(r.id),
                    "title": r.title_translated or r.title_original or "",
                    "content": r.body_translated or r.body_original or "",
                    "rating": r.rating,
                    "author": r.author or "Anonymous",
                    "date": r.review_date.isoformat() if r.review_date else None,
                    "sentiment": r.sentiment,
                    "verified": r.verified_purchase,
                    "helpful_votes": r.helpful_votes or 0,
                    "has_media": r.has_video or r.has_images,
                    "review_url": r.review_url,
                    "insights": insights_map.get(r.id, []),
                    "theme_highlights": themes_map.get(r.id, []),
                }
                for r in preview_reviews
            ],
            "reviews_pagination": {
                "total": len(reviews),
                "preview_count": len(preview_reviews),
                "has_more": len(reviews) > 10,
                "page_size": 50,  # åˆ†é¡µæ¥å£æ¯é¡µæ•°é‡
            },
            "stats": {
                "total_reviews": len(reviews),
                "average_rating": sum(r.rating for r in reviews) / len(reviews) if reviews else 0,
                "rating_distribution": rating_distribution,
                "sentiment_distribution": sentiment_distribution,
            },
            "aggregated_insights": aggregated_insights,
            "aggregated_themes": aggregated_themes,
            "product_dimensions": product_dimensions,
            "context_labels": context_labels,
            "dimension_insights": dimension_insights,
            "dimension_summaries": dimension_summaries,  # AIç”Ÿæˆçš„ç»´åº¦æ€»ç»“
        }
    
    async def _get_report_data(self, report_id: UUID) -> Dict[str, Any]:
        """è·å–æŠ¥å‘Šæ•°æ®"""
        result = await self.db.execute(
            select(ProductReport).where(ProductReport.id == report_id)
        )
        report = result.scalar_one_or_none()
        
        if not report:
            raise ValueError(f"æŠ¥å‘Šä¸å­˜åœ¨: {report_id}")
        
        # è·å–äº§å“ä¿¡æ¯
        product_result = await self.db.execute(
            select(Product).where(Product.id == report.product_id)
        )
        product = product_result.scalar_one_or_none()
        
        return {
            "report": report.to_dict(),
            "product": {
                "asin": product.asin if product else None,
                "title": product.title_translated or product.title if product else None,
                "image_url": product.image_url if product else None,
            } if product else None
        }
    
    async def _get_analysis_project_data(self, project_id: UUID) -> Dict[str, Any]:
        """è·å–åˆ†æé¡¹ç›®æ•°æ®"""
        result = await self.db.execute(
            select(AnalysisProject)
            .options(selectinload(AnalysisProject.items))
            .where(AnalysisProject.id == project_id)
        )
        project = result.scalar_one_or_none()
        
        if not project:
            raise ValueError(f"åˆ†æé¡¹ç›®ä¸å­˜åœ¨: {project_id}")
        
        # è·å–å…³è”äº§å“ä¿¡æ¯
        items_data = []
        for item in project.items:
            product_result = await self.db.execute(
                select(Product).where(Product.id == item.product_id)
            )
            product = product_result.scalar_one_or_none()
            items_data.append({
                "id": str(item.id),
                "role_label": item.role_label,
                "display_order": item.display_order,
                "product": {
                    "id": str(product.id) if product else None,
                    "asin": product.asin if product else None,
                    "title": product.title_translated or product.title if product else None,
                    "image_url": product.image_url if product else None,
                } if product else None
            })
        
        return {
            "project": {
                "id": str(project.id),
                "title": project.title,
                "description": project.description,
                "analysis_type": project.analysis_type,
                "status": project.status,
                "result_content": project.result_content,
                "raw_data_snapshot": project.raw_data_snapshot,
                "created_at": project.created_at.isoformat() if project.created_at else None,
            },
            "items": items_data
        }
    
    async def _get_rufus_session_data(self, session_id: str) -> Dict[str, Any]:
        """è·å– Rufus ä¼šè¯æ•°æ®
        
        æ”¯æŒè™šæ‹Ÿ session_id æ ¼å¼:
        - asin_XXXXX: äº§å“è¯¦æƒ…é¡µå¯¹è¯
        - keyword_XXXXX: å…³é”®è¯æœç´¢å¯¹è¯
        - æ™®é€š session_id: é¦–é¡µå¯¹è¯
        """
        # æ ¹æ®è™šæ‹Ÿ session_id æ ¼å¼æ„å»ºæŸ¥è¯¢
        if session_id.startswith('asin_'):
            # æŒ‰ ASIN æŸ¥è¯¢äº§å“è¯¦æƒ…é¡µå¯¹è¯
            real_asin = session_id[5:]  # å»æ‰ "asin_" å‰ç¼€
            result = await self.db.execute(
                select(RufusConversation)
                .where(
                    RufusConversation.asin == real_asin,
                    RufusConversation.page_type == 'product_detail'
                )
                .order_by(RufusConversation.created_at.asc())
            )
        elif session_id.startswith('keyword_'):
            # æŒ‰å…³é”®è¯æŸ¥è¯¢æœç´¢é¡µå¯¹è¯
            keyword = session_id[8:]  # å»æ‰ "keyword_" å‰ç¼€
            result = await self.db.execute(
                select(RufusConversation)
                .where(
                    RufusConversation.keyword == keyword,
                    RufusConversation.page_type == 'keyword_search'
                )
                .order_by(RufusConversation.created_at.asc())
            )
        else:
            # æ™®é€š session_id
            result = await self.db.execute(
                select(RufusConversation)
                .where(RufusConversation.session_id == session_id)
                .order_by(RufusConversation.created_at.asc())
            )
        
        conversations = list(result.scalars().all())
        
        if not conversations:
            raise ValueError(f"Rufus ä¼šè¯ä¸å­˜åœ¨: {session_id}")
        
        # è·å–ä¼šè¯çš„åŸºæœ¬ä¿¡æ¯ï¼ˆä»ç¬¬ä¸€æ¡å¯¹è¯ä¸­æå–ï¼‰
        first_conv = conversations[0]
        
        return {
            "session": {
                "session_id": session_id,
                "page_type": first_conv.page_type,
                "asin": first_conv.asin,
                "keyword": first_conv.keyword,
                "product_title": first_conv.product_title,
                "product_image": first_conv.product_image,
                "marketplace": first_conv.marketplace,
                "created_at": first_conv.created_at.isoformat() if first_conv.created_at else None,
            },
            "conversations": [
                {
                    "id": str(c.id),
                    "question": c.question,
                    "answer": c.answer,
                    "question_type": c.question_type,
                    "question_index": c.question_index,
                    "ai_summary": c.ai_summary,
                    "created_at": c.created_at.isoformat() if c.created_at else None,
                }
                for c in conversations
            ]
        }
    
    async def _get_keyword_collection_data(self, collection_id: UUID) -> Dict[str, Any]:
        """è·å–äº§å“ç”»æ¿ï¼ˆå¸‚åœºæ ¼å±€åˆ†æï¼‰æ•°æ®"""
        result = await self.db.execute(
            select(KeywordCollection).where(KeywordCollection.id == collection_id)
        )
        collection = result.scalar_one_or_none()
        
        if not collection:
            raise ValueError(f"äº§å“ç”»æ¿ä¸å­˜åœ¨: {collection_id}")
        
        # è·å–å…³è”äº§å“
        products_result = await self.db.execute(
            select(CollectionProduct)
            .where(CollectionProduct.collection_id == collection_id)
            .order_by(CollectionProduct.created_at.asc())
        )
        collection_products = list(products_result.scalars().all())
        
        # ç›´æ¥ä½¿ç”¨ CollectionProduct çš„å¿«ç…§æ•°æ®
        products_data = []
        for cp in collection_products:
            # è§£æä»·æ ¼ï¼ˆå¯èƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¦‚ "$19.99"ï¼‰
            price_value = None
            if cp.price:
                try:
                    # å°è¯•æå–æ•°å­—éƒ¨åˆ†
                    import re
                    price_match = re.search(r'[\d.]+', cp.price)
                    if price_match:
                        price_value = float(price_match.group())
                except:
                    pass
            
            products_data.append({
                "id": str(cp.id),
                "product_id": None,  # CollectionProduct æ˜¯å¿«ç…§ï¼Œä¸å…³è” Product è¡¨
                "asin": cp.asin,
                "title": cp.title,
                "image_url": cp.image_url,
                "price": price_value,
                "average_rating": float(cp.rating) if cp.rating else None,
                "review_count": cp.review_count,
                "marketplace": collection.marketplace,  # ä½¿ç”¨ collection çš„ marketplace
                # CollectionProduct æ‰©å±•å­—æ®µ
                "brand": cp.brand,
                "year": cp.year,
                "sales_volume": cp.sales_volume,
                "sales_volume_manual": cp.sales_volume_manual,
                "major_category_rank": cp.major_category_rank,
                "minor_category_rank": cp.minor_category_rank,
                "major_category_name": cp.major_category_name,
                "minor_category_name": cp.minor_category_name,
            })
        
        return {
            "collection": {
                "id": str(collection.id),
                "keyword": collection.keyword,
                "marketplace": collection.marketplace,
                "description": collection.description,
                "product_count": len(products_data),
                "created_at": collection.created_at.isoformat() if collection.created_at else None,
                # è§†å›¾é…ç½®
                "board_config": collection.board_config,
                "view_config": collection.view_config,
            },
            "products": products_data
        }
    
    # ==========================================
    # æ’¤é”€åˆ†äº«é“¾æ¥
    # ==========================================
    
    async def revoke_share_link(self, token: str, user_id: UUID) -> bool:
        """
        æ’¤é”€åˆ†äº«é“¾æ¥
        
        Args:
            token: åˆ†äº«ä»¤ç‰Œ
            user_id: æ“ä½œç”¨æˆ· IDï¼ˆå¿…é¡»æ˜¯åˆ›å»ºè€…ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        share_link = await self.get_share_link_by_token(token)
        
        if not share_link:
            raise ValueError("åˆ†äº«é“¾æ¥ä¸å­˜åœ¨")
        
        if share_link.user_id != user_id:
            raise ValueError("æ— æƒæ’¤é”€æ­¤åˆ†äº«é“¾æ¥")
        
        share_link.is_active = False
        await self.db.commit()
        
        logger.info(f"æ’¤é”€åˆ†äº«é“¾æ¥: token={token}, user={user_id}")
        return True
    
    async def delete_share_link(self, token: str, user_id: UUID) -> bool:
        """
        åˆ é™¤åˆ†äº«é“¾æ¥ï¼ˆç‰©ç†åˆ é™¤ï¼‰
        
        Args:
            token: åˆ†äº«ä»¤ç‰Œ
            user_id: æ“ä½œç”¨æˆ· IDï¼ˆå¿…é¡»æ˜¯åˆ›å»ºè€…ï¼‰
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        share_link = await self.get_share_link_by_token(token)
        
        if not share_link:
            raise ValueError("åˆ†äº«é“¾æ¥ä¸å­˜åœ¨")
        
        if share_link.user_id != user_id:
            raise ValueError("æ— æƒåˆ é™¤æ­¤åˆ†äº«é“¾æ¥")
        
        await self.db.delete(share_link)
        await self.db.commit()
        
        logger.info(f"åˆ é™¤åˆ†äº«é“¾æ¥: token={token}, user={user_id}")
        return True
    
    # ==========================================
    # è·å–åˆ†äº«é“¾æ¥å…ƒä¿¡æ¯ï¼ˆå…¬å¼€æ¥å£ç”¨ï¼‰
    # ==========================================
    
    async def get_share_meta(self, token: str) -> Optional[Dict[str, Any]]:
        """
        è·å–åˆ†äº«é“¾æ¥çš„å…ƒä¿¡æ¯ï¼ˆä¸åŒ…å«å®Œæ•´æ•°æ®ï¼Œç”¨äºé¢„è§ˆï¼‰
        
        Args:
            token: åˆ†äº«ä»¤ç‰Œ
            
        Returns:
            åˆ†äº«é“¾æ¥çš„åŸºæœ¬ä¿¡æ¯
        """
        share_link = await self.get_share_link_by_token(token)
        
        if not share_link:
            return None
        
        return {
            "token": share_link.token,
            "resource_type": share_link.resource_type,
            "resource_id": str(share_link.resource_id) if share_link.resource_id else None,
            "asin": share_link.asin,
            "title": share_link.title,
            "is_valid": share_link.is_valid,
            "is_expired": share_link.is_expired,
            "expires_at": share_link.expires_at.isoformat() if share_link.expires_at else None,
            "view_count": share_link.view_count,
            "created_at": share_link.created_at.isoformat() if share_link.created_at else None,
        }
    
    # ==========================================
    # åˆ†é¡µè·å–è¯„è®ºï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
    # ==========================================
    
    async def get_share_reviews_paginated(
        self,
        token: str,
        page: int = 1,
        page_size: int = 50,
        rating: Optional[int] = None,
        sentiment: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        åˆ†é¡µè·å–åˆ†äº«é“¾æ¥çš„è¯„è®ºåˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            token: åˆ†äº«ä»¤ç‰Œ
            page: é¡µç ï¼ˆä»1å¼€å§‹ï¼‰
            page_size: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤50ï¼Œæœ€å¤§100ï¼‰
            rating: ç­›é€‰è¯„åˆ†ï¼ˆ1-5ï¼‰
            sentiment: ç­›é€‰æƒ…æ„Ÿï¼ˆpositive/neutral/negativeï¼‰
            
        Returns:
            åˆ†é¡µçš„è¯„è®ºåˆ—è¡¨
        """
        from collections import defaultdict
        
        # éªŒè¯åˆ†äº«é“¾æ¥
        share_link = await self.get_share_link_by_token(token)
        if not share_link:
            raise ValueError("åˆ†äº«é“¾æ¥ä¸å­˜åœ¨")
        if not share_link.is_active:
            raise ValueError("åˆ†äº«é“¾æ¥å·²è¢«æ’¤é”€")
        if share_link.is_expired:
            raise ValueError("åˆ†äº«é“¾æ¥å·²è¿‡æœŸ")
        
        # åªæ”¯æŒ review_reader ç±»å‹
        if share_link.resource_type != ShareResourceType.REVIEW_READER.value:
            raise ValueError("è¯¥åˆ†äº«ç±»å‹ä¸æ”¯æŒè¯„è®ºåˆ†é¡µ")
        
        asin = share_link.asin
        if not asin:
            raise ValueError("åˆ†äº«é“¾æ¥ç¼ºå°‘ ASIN")
        
        # é™åˆ¶ page_size
        page_size = min(max(page_size, 10), 100)
        
        # å°è¯•ä»ç¼“å­˜è·å–
        cache_key = f"{CACHE_PREFIX_SHARE}reviews:{token}:p{page}:s{page_size}"
        if rating:
            cache_key += f":r{rating}"
        if sentiment:
            cache_key += f":st_{sentiment}"
        
        cached_data = await self._get_from_cache(cache_key)
        if cached_data:
            logger.debug(f"åˆ†é¡µè¯„è®ºå‘½ä¸­ç¼“å­˜: {cache_key}")
            return cached_data
        
        # è·å–äº§å“
        result = await self.db.execute(
            select(Product).where(Product.asin == asin)
        )
        product = result.scalar_one_or_none()
        if not product:
            raise ValueError(f"äº§å“ä¸å­˜åœ¨: {asin}")
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = [Review.product_id == product.id]
        if rating:
            conditions.append(Review.rating == rating)
        if sentiment:
            conditions.append(Review.sentiment == sentiment)
        
        # è·å–æ€»æ•°
        count_result = await self.db.execute(
            select(func.count(Review.id)).where(and_(*conditions))
        )
        total = count_result.scalar() or 0
        
        # åˆ†é¡µæŸ¥è¯¢
        offset = (page - 1) * page_size
        review_result = await self.db.execute(
            select(Review)
            .where(and_(*conditions))
            .order_by(Review.review_date.desc().nullslast())
            .offset(offset)
            .limit(page_size)
        )
        reviews = list(review_result.scalars().all())
        review_ids = [r.id for r in reviews]
        
        # è·å– insights
        insights_map = defaultdict(list)
        if review_ids:
            insights_result = await self.db.execute(
                select(ReviewInsight).where(ReviewInsight.review_id.in_(review_ids))
            )
            for insight in insights_result.scalars().all():
                insights_map[insight.review_id].append({
                    "type": insight.insight_type,
                    "quote": insight.quote,
                    "quote_translated": insight.quote_translated,
                    "analysis": insight.analysis,
                    "dimension": insight.dimension,
                    "confidence": insight.confidence or "high",
                })
        
        # è·å– theme_highlights
        themes_map = defaultdict(list)
        if review_ids:
            themes_result = await self.db.execute(
                select(ReviewThemeHighlight).where(ReviewThemeHighlight.review_id.in_(review_ids))
            )
            for theme in themes_result.scalars().all():
                items = []
                if theme.label_name:
                    items.append({
                        "content": theme.label_name,
                        "content_original": theme.quote,
                        "quote_translated": theme.quote_translated,
                        "explanation": theme.explanation,
                        "confidence": theme.confidence or "high",
                    })
                elif theme.items:
                    items = theme.items if isinstance(theme.items, list) else []
                
                themes_map[theme.review_id].append({
                    "theme_type": theme.theme_type,
                    "label_name": theme.label_name,
                    "items": items,
                })
        
        # æ„å»ºè¿”å›æ•°æ®
        reviews_data = [
            {
                "id": str(r.id),
                "title": r.title_translated or r.title_original or "",
                "content": r.body_translated or r.body_original or "",
                "rating": r.rating,
                "author": r.author or "Anonymous",
                "date": r.review_date.isoformat() if r.review_date else None,
                "sentiment": r.sentiment,
                "verified": r.verified_purchase,
                "helpful_votes": r.helpful_votes or 0,
                "has_media": r.has_video or r.has_images,
                "review_url": r.review_url,
                "insights": insights_map.get(r.id, []),
                "theme_highlights": themes_map.get(r.id, []),
            }
            for r in reviews
        ]
        
        result_data = {
            "reviews": reviews_data,
            "pagination": {
                "page": page,
                "page_size": page_size,
                "total": total,
                "total_pages": (total + page_size - 1) // page_size,
                "has_next": offset + len(reviews) < total,
                "has_prev": page > 1,
            },
            "filters": {
                "rating": rating,
                "sentiment": sentiment,
            }
        }
        
        # å†™å…¥ç¼“å­˜
        await self._set_to_cache(cache_key, result_data, CACHE_TTL_SHARE_REVIEWS)
        
        return result_data
