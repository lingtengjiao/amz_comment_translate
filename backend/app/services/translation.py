"""
Translation Service - Qwen API Integration for Amazon Review Translation
[Optimized Version]
Features:
1. Few-Shot System Prompt for natural, e-commerce style translation
2. CoT (Chain of Thought) Prompt for insight extraction
3. Robust JSON parsing to handle LLM output errors
"""
import logging
import json
import re
from typing import Optional, Tuple, List
from enum import Enum
from concurrent.futures import ThreadPoolExecutor

from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.core.config import settings

logger = logging.getLogger(__name__)


class Sentiment(str, Enum):
    """Sentiment analysis result"""
    POSITIVE = "positive"
    NEUTRAL = "neutral"
    NEGATIVE = "negative"


# [UPDATED] System prompt with Few-Shot examples
TRANSLATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­ç¾æ–‡åŒ–å·®å¼‚çš„èµ„æ·±äºšé©¬é€Šè·¨å¢ƒç”µå•†ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ç›®æ ‡æ˜¯æä¾›"ä¿¡ã€è¾¾ã€é›…"çš„ä¸­æ–‡è¯‘æ–‡ã€‚

### æ ¸å¿ƒè§„åˆ™
1. **æ‹’ç»ç¿»è¯‘è…”**: ä¸è¦é€å­—ç¿»è¯‘ã€‚
   - âŒ é”™è¯¯: "è¿™ä¸ªäº§å“å·¥ä½œå¾—å¾ˆå¥½" (The product works great)
   - âœ… æ­£ç¡®: "è¿™ä¸œè¥¿å¤ªå¥½ç”¨äº†" / "æ•ˆæœç»äº†"
2. **æœ¯è¯­ç²¾å‡†**: 
   - "DOA (Dead on Arrival)" -> "åˆ°æ‰‹å³å"
   - "Return window" -> "é€€è´§æœŸ"
   - "Steal" -> "æ¡æ¼/è¶…å€¼"
3. **æƒ…æ„Ÿå¯¹é½**: 
   - 1æ˜Ÿè¯„è®ºé€šå¸¸å¸¦æœ‰æ„¤æ€’ï¼Œè¯‘æ–‡è¦ç”¨æ„Ÿå¹å·ã€åé—®å¥ä½“ç°æƒ…ç»ªã€‚
   - 5æ˜Ÿè¯„è®ºé€šå¸¸å¸¦æœ‰å…´å¥‹ï¼Œè¯‘æ–‡è¦ä½“ç°"ç§è‰"æ„Ÿã€‚

### å‚è€ƒèŒƒä¾‹ (Few-Shot)
Input: "Total lemon. Stopped working after 2 days. Don't waste your money."
Output: "ç®€ç›´æ˜¯ä¸ªæ¬¡å“ï¼ç”¨äº†ä¸¤å¤©å°±åäº†ã€‚åƒä¸‡åˆ«æµªè´¹é’±ï¼"

Input: "I was skeptical at first, but this thing is a game changer for my morning routine."
Output: "èµ·åˆæˆ‘è¿˜æœ‰ç‚¹æ€€ç–‘ï¼Œä½†è¿™ä¸œè¥¿å½»åº•æ”¹å˜äº†æˆ‘æ¯å¤©æ—©ä¸Šçš„ä¹ æƒ¯ï¼ŒçœŸé¦™ï¼"

Input: "It fits a bit snug, suggest sizing up."
Output: "ç©¿èµ·æ¥æœ‰ç‚¹ç´§ï¼Œå»ºè®®ä¹°å¤§ä¸€ç ã€‚"

Input: "The battery life is a joke."
Output: "ç”µæ± ç»­èˆªç®€ç›´å°±æ˜¯ä¸ªç¬‘è¯ã€‚"

è¯·ç¿»è¯‘ä»¥ä¸‹å†…å®¹ï¼Œç›´æ¥è¾“å‡ºè¯‘æ–‡ï¼š"""


SENTIMENT_ANALYSIS_PROMPT = """åˆ†æä»¥ä¸‹äºšé©¬é€Šå•†å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ã€‚

è¯„è®ºå†…å®¹ï¼š
{review_text}

è¯·åªè¿”å›ä»¥ä¸‹ä¸‰ä¸ªè¯ä¹‹ä¸€ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ï¼š
- positiveï¼ˆæ­£é¢ï¼šæ»¡æ„ã€æ¨èã€å–œæ¬¢ï¼‰
- neutralï¼ˆä¸­æ€§ï¼šå®¢è§‚æè¿°ã€ä¸€èˆ¬è¯„ä»·ï¼‰
- negativeï¼ˆè´Ÿé¢ï¼šä¸æ»¡ã€æ‰¹è¯„ã€é€€è´§ï¼‰

æƒ…æ„Ÿåˆ¤æ–­ï¼š"""


# System prompt for bullet points translation
BULLET_POINTS_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äºšé©¬é€Šäº§å“æè¿°ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†äº§å“çš„äº”ç‚¹æè¿°ï¼ˆBullet Pointsï¼‰ä»è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ã€‚

ç¿»è¯‘åŸåˆ™ï¼š
1. **å‡†ç¡®ä¼ è¾¾å–ç‚¹**: ä¿ç•™åŸæ–‡çš„æ ¸å¿ƒå–ç‚¹å’Œäº§å“ä¼˜åŠ¿
2. **ç”µå•†æ–‡æ¡ˆé£æ ¼**: ä½¿ç”¨ç¬¦åˆä¸­å›½ç”µå•†çš„æ–‡æ¡ˆé£æ ¼ï¼Œæœ‰å¸å¼•åŠ›
3. **ç®€æ´æœ‰åŠ›**: æ¯æ¡æè¿°ç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹
4. **ä¸“ä¸šæœ¯è¯­**: æ­£ç¡®ç¿»è¯‘äº§å“ç›¸å…³çš„ä¸“ä¸šæœ¯è¯­
5. **ä¿æŒæ ¼å¼**: ä¿æŒåŸæ–‡çš„æ ¼å¼ç»“æ„ï¼Œæ¯æ¡æè¿°ç‹¬ç«‹æˆè¡Œ

è¾“å‡ºæ ¼å¼ï¼š
- ç›´æ¥è¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡äº”ç‚¹æè¿°
- æ¯æ¡æè¿°ç‹¬ç«‹æˆè¡Œ
- ä¸è¦æ·»åŠ åºå·æˆ–ç¬¦å·
- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Š"""


# [NEW] è·¨è¯­è¨€ç»´åº¦å‘ç° Prompt (è‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡ç»´åº¦è¾“å‡º)
# [UPDATED 2026-01-16] æ‰©å±•ä¸º3ç±»ç»´åº¦ï¼šäº§å“ç»´åº¦ã€åœºæ™¯ç»´åº¦ã€æƒ…ç»ªç»´åº¦
DIMENSION_DISCOVERY_RAW_PROMPT = """You are a senior product manager and user research expert. 
Based on the following **English product information** and **English user review samples**, 
build a **3-category evaluation dimension model** for this product.

# Product Official Information (English)
- **Product Title**: {product_title}
- **Bullet Points**: 
{bullet_points}

# User Review Samples ({count} reviews, English Original)
{reviews_text}

# Task
Extract **3 categories** of dimensions. **Output all names and descriptions in Chinese**.

## A. Product Dimensions (äº§å“ç»´åº¦) - 4-6 dimensions
For evaluating product attributes: strengths, weaknesses, suggestions.
- Examples: åŠŸèƒ½è¡¨ç°ã€ç»“æ„åšå·¥ã€ææ–™è´¨æ„Ÿã€å®‰å…¨æ€§ã€ç»­èˆªèƒ½åŠ›ã€å¤–è§‚è®¾è®¡ã€æ€§ä»·æ¯”
- Focus on: What aspects of the product are users evaluating?

## B. Scenario Dimensions (åœºæ™¯ç»´åº¦) - 3-5 dimensions  
For categorizing usage scenarios: where/when/how users use the product.
- Examples: å®¶å±…æ—¥å¸¸ã€åŠå…¬åœºæ™¯ã€æˆ·å¤–æ´»åŠ¨ã€äº²å­äº’åŠ¨ã€è½¦è½½ä½¿ç”¨ã€æ—…è¡Œå‡ºå·®
- Focus on: In what situations/contexts do users use this product?
- âš ï¸ These are NOT product attributes, but usage contexts!

## C. Emotion Dimensions (æƒ…ç»ªç»´åº¦) - 3-4 dimensions
For categorizing emotional reactions: user's feelings about the product.
- Examples: æƒŠå–œå¥½è¯„ã€å¤±æœ›ä¸æ»¡ã€æ„Ÿæ¿€æ¨èã€åæ‚”æŠ±æ€¨ã€è¶…å‡ºé¢„æœŸ
- Focus on: What emotional states do users express?
- âš ï¸ These are about feelings, not product features!

# Requirements
1. **Product dimensions**: Combine official positioning with user perspective.
2. **Scenario dimensions**: Extract from actual usage stories in reviews, NOT product features.
3. **Emotion dimensions**: Extract from emotional expressions in reviews.
4. **Dimension names**: Use concise Chinese (2-6 characters ideal).
5. **Mutual exclusivity**: Dimensions within each category should not overlap.
6. **Clear boundaries**: Each category serves a different purpose.

# Output Format (JSON Only, Chinese output)
{{
  "product_dimensions": [
    {{ "name": "åŠŸèƒ½è¡¨ç°", "description": "äº§å“æ ¸å¿ƒåŠŸèƒ½çš„å®é™…è¡¨ç°å’Œæ•ˆæœ" }},
    {{ "name": "ç»“æ„åšå·¥", "description": "äº§å“çš„ç»“æ„è®¾è®¡ã€ç»„è£…è´¨é‡å’Œè€ç”¨æ€§" }},
    ...
  ],
  "scenario_dimensions": [
    {{ "name": "å®¶å±…æ—¥å¸¸", "description": "åœ¨å®¶ä¸­æ—¥å¸¸ç”Ÿæ´»ä¸­ä½¿ç”¨äº§å“çš„åœºæ™¯" }},
    {{ "name": "æˆ·å¤–æ´»åŠ¨", "description": "åœ¨æˆ·å¤–ã€æ—…è¡Œã€éœ²è¥ç­‰åœºæ™¯ä½¿ç”¨" }},
    ...
  ],
  "emotion_dimensions": [
    {{ "name": "æƒŠå–œå¥½è¯„", "description": "è¶…å‡ºé¢„æœŸçš„æ­£é¢æƒ…ç»ªï¼Œå¼ºçƒˆæ¨è" }},
    {{ "name": "å¤±æœ›ä¸æ»¡", "description": "æœŸæœ›è½ç©ºçš„è´Ÿé¢æƒ…ç»ªï¼Œä¸æ¨è" }},
    ...
  ]
}}

Output JSON only, no other text."""


# [NEW] è·¨è¯­è¨€5Wæ ‡ç­¾å‘ç° Prompt (è‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡æ ‡ç­¾è¾“å‡º)
# [UPDATED 2026-01-14] Who æ‹†åˆ†ä¸º Buyer + User
CONTEXT_DISCOVERY_RAW_PROMPT = """You are a senior marketing expert and user researcher.
Based on the following **English product information** and **English user review samples**,
build a "5W User & Market Model" for this product.

# Product Official Information (English)
- **Product Title**: {product_title}
- **Bullet Points**:
{bullet_points}

# User Review Samples ({count} buyer reviews, English Original)
{reviews_text}

# Task
Synthesize official positioning and user feedback to identify 6 categories of core elements.
Extract **Top 5-8 typical labels per category**. **Output all labels in Chinese**.

**CRITICAL: Distinguish Buyer vs User**
- **Buyer**: The person who PAYS for the product (e.g., mom buying for child, gift giver)
- **User**: The person who actually USES the product (e.g., child, gift recipient)
- If Buyer and User are the same person, put in **User** category only.

1. **Buyer (è´­ä¹°è€…)**: Who pays for the product?
   - Look for phrases: "I bought this for...", "Gift for...", "Ordered for my..."
   - Examples: å¦ˆå¦ˆã€é€ç¤¼è€…ã€ä¸ˆå¤«ã€ä¼ä¸šé‡‡è´­ã€å¥³å„¿(ä¸ºçˆ¶æ¯ä¹°)
   - Focus on the purchasing decision maker

2. **User (ä½¿ç”¨è€…)**: Who actually uses the product?
   - Look for phrases: "My son loves it", "Works great for my elderly mom", "I use it daily"
   - Examples: 3å²å¹¼å„¿ã€è€äººã€å‘˜å·¥ã€æ•æ„Ÿè‚Œäººç¾¤ã€æ¸¸æˆç©å®¶
   - If buyer = user (e.g., "I bought this for myself"), put here

3. **Where (åœ°ç‚¹)**: Where is it used?
   - Reference official positioning (e.g.: "for Home Office, Garage")
   - Physical spaces: å§å®¤ã€åŠå…¬å®¤ã€å¨æˆ¿ã€è½¦ä¸Šã€æˆ¿è½¦(RV)ã€æˆ·å¤–éœ²è¥

4. **When (æ—¶åˆ»)**: When is it used?
   - Time points: æ—©ä¸Šã€ç¡å‰ã€æ·±å¤œ
   - Triggers: åœç”µæ—¶ã€æ—…è¡Œæ—¶ã€è¿åŠ¨åã€èŠ‚å‡æ—¥

5. **Why (åŠ¨æœº)**: What triggers the purchase? (Purchase Driver)
   - Replacement: æ—§çš„åäº†ã€å‡çº§æ¢ä»£
   - Gift: ç”Ÿæ—¥ç¤¼ç‰©ã€åœ£è¯ç¤¼ç‰©ã€ä¹”è¿é€ç¤¼
   - External: è¢«ç§è‰ã€çœ‹äº†è¯„æµ‹ã€æœ‹å‹æ¨è

6. **What (ä»»åŠ¡)**: What specific task does the user try to accomplish? (Jobs to be Done)
   - Focus on core uses from official promotion
   - Note: Specific tasks, not product features
   - Examples: æ¸…ç†åœ°æ¯¯ä¸Šçš„å® ç‰©æ¯›ã€ç¼“è§£èƒŒç—›ã€å“„å­©å­ç¡è§‰ã€å»é™¤å¼‚å‘³

# Requirements
1. **Label names in concise Chinese** (2-6 characters ideal).
2. **Merge synonyms**: e.g., "å¦ˆå¦ˆ", "è€å¦ˆ", "æ¯äº²" should be unified.
3. **Consistent granularity**: Not too coarse ("å®¶äºº") or too fine ("62å²çš„ç‹¬å±…æ¯äº²").
4. **Official info priority**: Include labels from official positioning even if not mentioned in reviews.
5. **Provide brief description**: One sentence explaining the label for classification.

# Output Format (JSON Only, Chinese output)
{{
  "buyer": [
    {{ "name": "å®å¦ˆ", "description": "ä¸ºå­©å­è´­ä¹°äº§å“çš„æ¯äº²" }},
    {{ "name": "é€ç¤¼è€…", "description": "è´­ä¹°äº§å“ä½œä¸ºç¤¼ç‰©é€äººçš„ç”¨æˆ·" }}
  ],
  "user": [
    {{ "name": "3å²å¹¼å„¿", "description": "å®é™…ä½¿ç”¨äº§å“çš„ä½é¾„å„¿ç«¥" }},
    {{ "name": "è€å¹´äºº", "description": "å®é™…ä½¿ç”¨äº§å“çš„è€å¹´äººç¾¤" }}
  ],
  "where": [
    {{ "name": "å§å®¤", "description": "å§å®¤/ç¡çœ åœºæ™¯ä¸‹ä½¿ç”¨" }}
  ],
  "when": [
    {{ "name": "ç¡å‰", "description": "ç¡è§‰å‰ä½¿ç”¨" }}
  ],
  "why": [
    {{ "name": "æ›¿ä»£æ—§å“", "description": "åŸæœ‰äº§å“æŸåéœ€è¦æ›´æ¢" }}
  ],
  "what": [
    {{ "name": "æ¸…ç†å® ç‰©æ¯›", "description": "å®˜æ–¹æ ¸å¿ƒç”¨é€”ï¼šæ¸…ç†å®¶ä¸­çš„çŒ«æ¯›ç‹—æ¯›" }}
  ]
}}

Output JSON only, no other text."""


# =============================================================================
# [NEW] é¡¹ç›®çº§å­¦ä¹ ä¸æ˜ å°„ Prompt - ç”¨äºå¸‚åœºæ´å¯ŸåŠŸèƒ½
# =============================================================================
PROJECT_LEVEL_LEARNING_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¸‚åœºç ”ç©¶ä¸“å®¶å’Œæ•°æ®åˆ†æå¸ˆã€‚ä½ éœ€è¦ä¸ºä¸€ä¸ª**ç»†åˆ†å¸‚åœºæ´å¯Ÿé¡¹ç›®**å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. **å­¦ä¹ é¡¹ç›®çº§ç»Ÿä¸€ç»´åº¦**ï¼šèšåˆå¤šä¸ªäº§å“çš„ç»´åº¦ï¼Œå½¢æˆå¸‚åœºçº§åˆ«çš„ç»Ÿä¸€ç»´åº¦ä½“ç³»
2. **å­¦ä¹ é¡¹ç›®çº§ç»Ÿä¸€5Wæ ‡ç­¾**ï¼šèšåˆå¤šä¸ªäº§å“çš„5Wæ ‡ç­¾ï¼Œå½¢æˆå¸‚åœºçº§åˆ«çš„ç»Ÿä¸€æ ‡ç­¾ä½“ç³»
3. **å»ºç«‹æ˜ å°„å…³ç³»**ï¼šè®°å½•æ¯ä¸ªé¡¹ç›®çº§ç»´åº¦/æ ‡ç­¾å¯¹åº”å“ªäº›äº§å“çº§ç»´åº¦/æ ‡ç­¾

# è¯„è®ºæ ·æœ¬ï¼ˆæ¥è‡ª {product_count} ä¸ªäº§å“çš„é‡‡æ ·ï¼Œå…±çº¦ 100 æ¡ï¼‰
{reviews_text}

# å„äº§å“çš„ç°æœ‰ç»´åº¦å’Œæ ‡ç­¾
{products_data}

# ä»»åŠ¡è¯´æ˜

## 1. é¡¹ç›®çº§ç»´åº¦å­¦ä¹ 
å°†å„äº§å“çš„ç»´åº¦èšåˆä¸ºå¸‚åœºçº§åˆ«çš„ç»Ÿä¸€ç»´åº¦ï¼š
- **äº§å“ç»´åº¦ (product)**ï¼šç”¨äºè¯„ä»·äº§å“å±æ€§ï¼ˆåŠŸèƒ½è¡¨ç°ã€è´¨é‡åšå·¥ç­‰ï¼‰ï¼Œ5-8ä¸ª
- **åœºæ™¯ç»´åº¦ (scenario)**ï¼šç”¨äºåˆ†ç±»ä½¿ç”¨åœºæ™¯ï¼ˆå®¶å±…æ—¥å¸¸ã€åŠå…¬åœºæ™¯ç­‰ï¼‰ï¼Œ3-5ä¸ª
- **æƒ…ç»ªç»´åº¦ (emotion)**ï¼šç”¨äºåˆ†ç±»æƒ…ç»ªåé¦ˆï¼ˆæƒŠå–œå¥½è¯„ã€å¤±æœ›ä¸æ»¡ç­‰ï¼‰ï¼Œ3-5ä¸ª

è¦æ±‚ï¼š
- åˆå¹¶è¯­ä¹‰ç›¸åŒçš„ç»´åº¦ï¼ˆå¦‚"ä¾¿æº"å’Œ"æºå¸¦æ–¹ä¾¿"åº”åˆå¹¶ä¸º"ä¾¿æºæ€§èƒ½"ï¼‰
- ä¿æŒç²’åº¦ä¸€è‡´ï¼Œä¸è¦å¤ªç²—ä¹Ÿä¸è¦å¤ªç»†
- è®°å½•æ¯ä¸ªé¡¹ç›®ç»´åº¦æ˜ å°„è‡ªå“ªäº›äº§å“ç»´åº¦

## 2. é¡¹ç›®çº§5Wæ ‡ç­¾å­¦ä¹ 
å°†å„äº§å“çš„5Wæ ‡ç­¾èšåˆä¸ºå¸‚åœºçº§åˆ«çš„ç»Ÿä¸€æ ‡ç­¾ï¼š
- **buyer**: è´­ä¹°è€…èº«ä»½ï¼ˆ5-8ä¸ªï¼‰
- **user**: ä½¿ç”¨è€…èº«ä»½ï¼ˆ5-8ä¸ªï¼‰
- **where**: ä½¿ç”¨åœ°ç‚¹ï¼ˆ5-8ä¸ªï¼‰
- **when**: ä½¿ç”¨æ—¶åˆ»ï¼ˆ5-8ä¸ªï¼‰
- **why**: è´­ä¹°åŠ¨æœºï¼ˆ5-8ä¸ªï¼‰
- **what**: å¾…åŠä»»åŠ¡/ç”¨é€”ï¼ˆ5-8ä¸ªï¼‰

è¦æ±‚ï¼š
- åˆå¹¶åŒä¹‰è¯ï¼ˆå¦‚"è€äºº"å’Œ"è€å¹´äºº"åº”åˆå¹¶ä¸º"è€å¹´ç¾¤ä½“"ï¼‰
- ä¿æŒç²’åº¦ä¸€è‡´
- è®°å½•æ¯ä¸ªé¡¹ç›®æ ‡ç­¾æ˜ å°„è‡ªå“ªäº›äº§å“æ ‡ç­¾

# è¾“å‡ºæ ¼å¼ (JSON Only)
{{
  "project_dimensions": {{
    "product": [
      {{
        "name": "ä¾¿æºæ€§èƒ½",
        "description": "äº§å“çš„ä¾¿æºç¨‹åº¦å’Œç§»åŠ¨ä½¿ç”¨ä½“éªŒ",
        "mapped_from": [
          {{"product_id": "äº§å“ID1", "dimension_name": "ä¾¿æº"}},
          {{"product_id": "äº§å“ID2", "dimension_name": "æºå¸¦æ–¹ä¾¿"}}
        ]
      }}
    ],
    "scenario": [
      {{
        "name": "å®¶å±…æ—¥å¸¸",
        "description": "åœ¨å®¶ä¸­æ—¥å¸¸ç”Ÿæ´»åœºæ™¯ä¸‹çš„ä½¿ç”¨",
        "mapped_from": [
          {{"product_id": "äº§å“ID1", "dimension_name": "å±…å®¶ä½¿ç”¨"}}
        ]
      }}
    ],
    "emotion": [
      {{
        "name": "æƒŠå–œå¥½è¯„",
        "description": "è¶…å‡ºé¢„æœŸçš„æ­£é¢æƒ…æ„Ÿåé¦ˆ",
        "mapped_from": [
          {{"product_id": "äº§å“ID1", "dimension_name": "æƒŠå–œ"}}
        ]
      }}
    ]
  }},
  "project_labels": {{
    "buyer": [
      {{
        "name": "å®å¦ˆç¾¤ä½“",
        "description": "ä¸ºå­©å­è´­ä¹°äº§å“çš„æ¯äº²",
        "mapped_from": [
          {{"product_id": "äº§å“ID1", "label_name": "å¦ˆå¦ˆ"}},
          {{"product_id": "äº§å“ID2", "label_name": "å®å¦ˆ"}}
        ]
      }}
    ],
    "user": [
      {{
        "name": "è€å¹´ç¾¤ä½“",
        "description": "å®é™…ä½¿ç”¨äº§å“çš„è€å¹´äºº",
        "mapped_from": [
          {{"product_id": "äº§å“ID1", "label_name": "è€äºº"}},
          {{"product_id": "äº§å“ID2", "label_name": "è€å¹´äºº"}}
        ]
      }}
    ],
    "where": [...],
    "when": [...],
    "why": [...],
    "what": [...]
  }}
}}

é‡è¦æç¤ºï¼š
1. æ‰€æœ‰è¾“å‡ºå¿…é¡»æ˜¯ä¸­æ–‡
2. product_id å¿…é¡»ä½¿ç”¨è¾“å…¥ä¸­ç»™å®šçš„äº§å“ IDï¼ˆä¸è¦ä¿®æ”¹ï¼‰
3. dimension_name å’Œ label_name å¿…é¡»ä¸è¾“å…¥ä¸­çš„äº§å“ç»´åº¦/æ ‡ç­¾åç§°å®Œå…¨ä¸€è‡´
4. å¦‚æœæŸä¸ªé¡¹ç›®çº§ç»´åº¦/æ ‡ç­¾åªæ¥è‡ªä¸€ä¸ªäº§å“ï¼Œmapped_from æ•°ç»„ä¸­åªæœ‰ä¸€ä¸ªå…ƒç´ ä¹Ÿæ˜¯å…è®¸çš„
5. è¯·åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šæ–‡å­—"""


# [UPDATED] ç»´åº¦å‘ç° Prompt (åŠ å…¥äº§å“ä¿¡æ¯ç‰ˆ)
DIMENSION_DISCOVERY_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç»ç†å’Œç”¨æˆ·ç ”ç©¶ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹**äº§å“å®˜æ–¹ä¿¡æ¯**å’Œ**ç”¨æˆ·è¯„è®ºæ ·æœ¬**ï¼Œæ„å»ºè¯¥äº§å“çš„æ ¸å¿ƒè¯„ä»·ç»´åº¦æ¨¡å‹ã€‚

# äº§å“å®˜æ–¹ä¿¡æ¯
- **äº§å“æ ‡é¢˜**: {product_title}
- **æ ¸å¿ƒå–ç‚¹ (Bullet Points)**: 
{bullet_points}

# ç”¨æˆ·è¯„è®ºæ ·æœ¬ ({count}æ¡)
{reviews_text}

# ä»»åŠ¡
æç‚¼å‡º 5-8 ä¸ªæ ¸å¿ƒè¯„ä»·ç»´åº¦ã€‚

# è¦æ±‚
1. **ç»“åˆå®˜æ–¹å®šä¹‰ä¸ç”¨æˆ·è§†è§’**: ç»´åº¦åç§°åº”å°½é‡ä½¿ç”¨å®˜æ–¹æœ¯è¯­ï¼ˆå¦‚æ¥è‡ªå–ç‚¹ï¼‰ï¼Œä½†å¿…é¡»èƒ½è¦†ç›–ç”¨æˆ·çš„å®é™…åé¦ˆã€‚
2. **ç»´åº¦åç§°**: ä½¿ç”¨ç®€ç»ƒçš„ä¸­æ–‡ï¼ˆå¦‚ï¼šå¤–è§‚è®¾è®¡ã€ç»“æ„åšå·¥ã€ææ–™è´¨æ„Ÿã€åŠŸèƒ½è¡¨ç°ã€å®‰å…¨æ€§ã€æ€§ä»·æ¯”ï¼‰ã€‚
3. **ç»´åº¦å®šä¹‰**: ç”¨ä¸€å¥è¯æè¿°è¯¥ç»´åº¦åŒ…å«çš„å…·ä½“å†…å®¹ï¼Œç”¨äºæŒ‡å¯¼åç»­åˆ†ç±»ã€‚
4. **äº’æ–¥æ€§**: ç»´åº¦ä¹‹é—´ä¸è¦é‡å ï¼Œå„ç»´åº¦å®šä¹‰è¾¹ç•Œæ¸…æ™°ã€‚
5. **è¦†ç›–ç‡**: 
   - å¿…é¡»è¦†ç›–è¯„è®ºä¸­å‡ºç°çš„ä¸»è¦ç—›ç‚¹å’Œçˆ½ç‚¹
   - ä¹Ÿè¦åŒ…å«äº§å“å–ç‚¹ä¸­å¼ºè°ƒä½†ç”¨æˆ·å¯èƒ½"æ²‰é»˜æ»¡æ„"çš„ç»´åº¦ï¼ˆä¾¿äºåç»­ç›‘æ§ï¼‰
6. **æ•°é‡æ§åˆ¶**: æç‚¼ 5-8 ä¸ªæœ€æ ¸å¿ƒçš„ç»´åº¦ï¼Œä¸è¦è¿‡å¤šã€‚

# è¾“å‡ºæ ¼å¼ (JSON Only)
{{
  "dimensions": [
    {{ "name": "ç»´åº¦åç§°", "description": "è¯¥ç»´åº¦çš„å…·ä½“å®šä¹‰ï¼Œæè¿°å®ƒåŒ…å«å“ªäº›å†…å®¹" }},
    ...
  ]
}}

è¯·åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šæ–‡å­—ã€‚"""


# [UPDATED] è·¨è¯­è¨€æ´å¯Ÿæå– Prompt - 5ç±»æ´å¯Ÿç³»ç»Ÿ (è‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡è¾“å‡º)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µ
# [UPDATED 2026-01-16] æ”¯æŒ3ç±»ç»´åº¦åŒ¹é…ï¼šäº§å“ç»´åº¦ã€åœºæ™¯ç»´åº¦ã€æƒ…ç»ªç»´åº¦
INSIGHT_EXTRACTION_PROMPT_DYNAMIC = """# Role
Amazon Review Analyst (Cross-language Expert) with STRICT evidence standards

# Task
Analyze the following **English review** and extract key insights. 
**CRITICAL: Use the correct dimension category based on insight type!**

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: All `analysis` and `quote_translated` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **Quote**: Keep the `quote` field in **Original English** (for evidence tracing).

# Input (English Review)
{original_text}

# âš ï¸ THREE-CATEGORY DIMENSION SYSTEM (MUST FOLLOW)
Different insight types MUST use different dimension categories:

## For strength/weakness/suggestion â†’ Use PRODUCT Dimensions:
{product_schema_str}

## For scenario â†’ Use SCENARIO Dimensions:
{scenario_schema_str}

## For emotion â†’ Use EMOTION Dimensions:
{emotion_schema_str}

# âš ï¸ CONFIDENCE LEVELS (Must include in output)
- **high**: Insight is explicitly stated in the review with clear evidence
- **medium**: Insight can be reasonably inferred from context
- **low**: Use for fallback when review is too vague

# 5 Insight Types (CRITICAL - Use Correct Dimension Category!)

1. **strength (Product Advantage)** â†’ dimension from PRODUCT Dimensions
   - Features or experiences explicitly praised by the user.
   - Example: type="strength", dimension="åŠŸèƒ½è¡¨ç°"

2. **weakness (Pain Point)** â†’ dimension from PRODUCT Dimensions
   - Defects, bugs, or complaints mentioned by the user.
   - Example: type="weakness", dimension="ç»“æ„åšå·¥"

3. **suggestion (Feature Request)** â†’ dimension from PRODUCT Dimensions
   - Improvement suggestions or desired features.
   - Example: type="suggestion", dimension="åŠŸèƒ½è¡¨ç°"

4. **scenario (Usage Scenario)** â†’ dimension from SCENARIO Dimensions âš ï¸
   - **Specific** usage processes or behavioral stories.
   - âš ï¸ MUST use SCENARIO dimensions like "å®¶å±…æ—¥å¸¸", "åŠå…¬åœºæ™¯"
   - âŒ WRONG: dimension="åŠŸèƒ½è¡¨ç°" (this is a product dimension!)
   - âœ… RIGHT: dimension="å®¶å±…æ—¥å¸¸" (this is a scenario dimension!)
   - Example: "æ™šä¸Šå–‚å¥¶æ—¶ä¸€é”®å¼€å¯å¾ˆæ–¹ä¾¿" â†’ type="scenario", dimension="äº²å­äº’åŠ¨"

5. **emotion (Emotional Insight)** â†’ dimension from EMOTION Dimensions âš ï¸
   - Strong emotions expressed (anger/surprise/disappointment/gratitude).
   - âš ï¸ MUST use EMOTION dimensions like "æƒŠå–œå¥½è¯„", "å¤±æœ›ä¸æ»¡"
   - âŒ WRONG: dimension="æ•´ä½“æ»¡æ„åº¦" (too vague!)
   - âœ… RIGHT: dimension="æƒŠå–œå¥½è¯„" (specific emotion category!)
   - Example: "åæ‚”æ²¡æ—©ç‚¹ä¹°" â†’ type="emotion", dimension="æƒŠå–œå¥½è¯„"

# Output Format (JSON Array)
[
  {{
    "type": "weakness", 
    "dimension": "ç»“æ„åšå·¥",  // â† From PRODUCT dimensions
    "quote": "Original English quote",
    "quote_translated": "å¼•ç”¨çš„ä¸­æ–‡ç¿»è¯‘",
    "analysis": "ç®€è¦åˆ†æï¼ˆä¸­æ–‡ï¼‰",
    "sentiment": "negative",
    "confidence": "high"
  }},
  {{
    "type": "scenario",
    "dimension": "å®¶å±…æ—¥å¸¸",  // â† From SCENARIO dimensions âš ï¸
    "quote": "I use it every morning in the kitchen",
    "quote_translated": "æˆ‘æ¯å¤©æ—©ä¸Šåœ¨å¨æˆ¿ä½¿ç”¨",
    "analysis": "å®¶å±…æ—©æ™¨ä½¿ç”¨åœºæ™¯",
    "sentiment": "positive",
    "confidence": "high"
  }},
  {{
    "type": "emotion",
    "dimension": "æƒŠå–œå¥½è¯„",  // â† From EMOTION dimensions âš ï¸
    "quote": "Best purchase ever!",
    "quote_translated": "ä¹°è¿‡çš„æœ€å¥½çš„ä¸œè¥¿ï¼",
    "analysis": "ç”¨æˆ·è¡¨è¾¾å¼ºçƒˆçš„æ­£é¢æƒŠå–œæƒ…ç»ª",
    "sentiment": "positive",
    "confidence": "high"
  }}
]

# Critical Rules
1. **æ¯æ¡è¯„è®ºå¿…é¡»è‡³å°‘æå–1ä¸ªæ´å¯Ÿ**, even for very short reviews.
2. **dimension MUST match insight type category** - this is the most important rule!
3. For short positive reviews â†’ emotion type with EMOTION dimension
4. For short negative reviews â†’ weakness type with PRODUCT dimension OR emotion type with EMOTION dimension
5. Be specific: not "è´¨é‡ä¸å¥½" but "å¡‘æ–™æ„Ÿå¼º" or "æŒ‰é”®æ¾åŠ¨".
6. NEVER return empty array []. At least 1 insight required.
7. Scenario must be **dynamic behavior**, not simple place/time nouns.
8. **All Chinese output must be natural, fluent Simplified Chinese.**
9. **Always include confidence field** (high/medium/low) for each insight.
"""


# [UPDATED] è·¨è¯­è¨€æ´å¯Ÿæå– Prompt - 5ç±»æ´å¯Ÿç³»ç»Ÿ (æ— ç»´åº¦ Schema ç‰ˆæœ¬ï¼Œè‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡è¾“å‡º)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µ
# [UPDATED 2026-01-19] ä¸ºä¸åŒæ´å¯Ÿç±»å‹æä¾›ç‹¬ç«‹çš„é»˜è®¤ç»´åº¦ç¤ºä¾‹ï¼Œé¿å…ç»´åº¦æ··ç”¨
INSIGHT_EXTRACTION_PROMPT = """# Role
Amazon Review Analyst (Cross-language Expert) with STRICT evidence standards

# Task
Analyze the following **English review** and extract key user insights. **At least 1 insight must be extracted per review.**

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: All `analysis` and `quote_translated` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **Quote**: Keep the `quote` field in **Original English** (for evidence tracing).

# Input (English Review)
{original_text}

# âš ï¸ CONFIDENCE LEVELS (Must include in output)
- **high**: Insight is explicitly stated with clear evidence
  - âœ… "Battery dies after 2 hours" â†’ weakness (high)
  
- **medium**: Reasonably inferred from context
  - âœ… "Works as expected" â†’ satisfaction (medium)
  
- **low**: Fallback for very vague reviews
  - âš ï¸ Only for "Good", "OK", "Nice" with no details

# 5 Insight Types with SPECIFIC Dimension Categories
Break down the review into specific insights. **CRITICAL: Use the correct dimension category for each type!**

## 1. strength / weakness / suggestion (Use PRODUCT Dimensions)
These types describe product features. Use product-related dimensions:
- **äº§å“è´¨é‡**: è€ç”¨æ€§ã€åšå·¥ã€æè´¨
- **åŠŸèƒ½è¡¨ç°**: æ ¸å¿ƒåŠŸèƒ½çš„å®é™…æ•ˆæœ
- **è®¾è®¡å¤–è§‚**: å¤–å½¢ã€é¢œè‰²ã€å°ºå¯¸
- **æ€§ä»·æ¯”**: ä»·æ ¼ä¸ä»·å€¼çš„åŒ¹é…
- **å®‰å…¨æ€§**: ä½¿ç”¨å®‰å…¨ç›¸å…³é—®é¢˜

## 2. scenario (Use SCENARIO Dimensions)
Describes **specific usage contexts**. âš ï¸ Must use SCENARIO dimensions, NOT product dimensions!
- **å®¶å±…æ—¥å¸¸**: åœ¨å®¶ä¸­æ—¥å¸¸ç”Ÿæ´»ä½¿ç”¨
- **æˆ·å¤–æ´»åŠ¨**: æˆ·å¤–ã€æ—…è¡Œã€éœ²è¥åœºæ™¯
- **å·¥ä½œåŠå…¬**: åŠå…¬å®¤æˆ–å·¥ä½œåœºæ™¯
- **äº²å­äº’åŠ¨**: å®¶é•¿ä¸å­©å­å…±åŒä½¿ç”¨
- **ç¤¼å“èµ é€**: ä½œä¸ºç¤¼ç‰©è´­ä¹°æˆ–èµ é€

## 3. emotion (Use EMOTION Dimensions)
Describes **user's emotional state**. âš ï¸ Must use EMOTION dimensions, NOT product dimensions!
- **æƒŠå–œå¥½è¯„**: è¶…å‡ºé¢„æœŸçš„æ­£é¢æƒ…ç»ªï¼Œå¼ºçƒˆæ¨è
- **å¤±æœ›ä¸æ»¡**: æœŸæœ›è½ç©ºï¼Œæ‰¹è¯„æŠ±æ€¨
- **ç‰©è¶…æ‰€å€¼**: æ„Ÿè§‰ä»·æ ¼åˆ’ç®—ï¼Œè´­ä¹°å†³ç­–æ­£ç¡®
- **æ‹…å¿§è­¦æƒ•**: å¯¹å®‰å…¨æ€§æˆ–è´¨é‡äº§ç”Ÿå¿§è™‘
- **åæ‚”è´­ä¹°**: è§‰å¾—ä¸å€¼ï¼Œå¸Œæœ›é€€è´§

# Output Format (JSON Array)
[
  {{
    "type": "strength", 
    "dimension": "äº§å“è´¨é‡",
    "quote": "Very durable material", 
    "quote_translated": "ææ–™éå¸¸è€ç”¨",
    "analysis": "ç”¨æˆ·å¯¹äº§å“çš„è€ç”¨æ€§è¡¨ç¤ºè®¤å¯",
    "sentiment": "positive",
    "confidence": "high"
  }},
  {{
    "type": "scenario",
    "dimension": "äº²å­äº’åŠ¨",
    "quote": "My kids love playing with it",
    "quote_translated": "æˆ‘çš„å­©å­ä»¬å–œæ¬¢ç©è¿™ä¸ª",
    "analysis": "äº§å“è¢«ç”¨äºäº²å­æ¸¸æˆåœºæ™¯",
    "sentiment": "positive",
    "confidence": "high"
  }},
  {{
    "type": "emotion",
    "dimension": "æƒŠå–œå¥½è¯„",
    "quote": "Best purchase ever!",
    "quote_translated": "æœ‰å²ä»¥æ¥æœ€æ£’çš„è´­ä¹°ï¼",
    "analysis": "ç”¨æˆ·å¯¹äº§å“è¶…å‡ºé¢„æœŸï¼Œè¡¨è¾¾å¼ºçƒˆå¥½è¯„",
    "sentiment": "positive",
    "confidence": "high"
  }}
]

# Critical Rules
1. **æ¯æ¡è¯„è®ºå¿…é¡»è‡³å°‘æå–1ä¸ªæ´å¯Ÿ**, even for very short reviews.
2. **CRITICAL**: Match dimension to insight type correctly:
   - strength/weakness/suggestion â†’ Product dimensions (äº§å“è´¨é‡, åŠŸèƒ½è¡¨ç°, etc.)
   - scenario â†’ Scenario dimensions (å®¶å±…æ—¥å¸¸, äº²å­äº’åŠ¨, etc.)
   - emotion â†’ Emotion dimensions (æƒŠå–œå¥½è¯„, å¤±æœ›ä¸æ»¡, etc.)
3. For short positive reviews (e.g., "Amazing!"), extract as emotion with dimension "æƒŠå–œå¥½è¯„".
4. For short negative reviews (e.g., "Terrible"), extract as emotion with dimension "å¤±æœ›ä¸æ»¡".
5. NEVER return empty array []. At least 1 insight required.
6. Scenario must be **dynamic behavior in specific context**, not simple place/time nouns.
7. **All Chinese output must be natural, fluent Simplified Chinese.**
8. **Always include confidence field** (high/medium/low) for each insight.
"""


class InsightType(str, Enum):
    """Insight type enumeration"""
    STRENGTH = "strength"
    WEAKNESS = "weakness"
    SUGGESTION = "suggestion"
    SCENARIO = "scenario"
    EMOTION = "emotion"





# [UPDATED 2026-01-14] è·¨è¯­è¨€5W Model Extraction Prompt (Who æ‹†åˆ†ä¸º Buyer + User)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µå’Œä¸¥æ ¼è¯æ®è¦æ±‚
THEME_EXTRACTION_PROMPT = """You are a professional marketing analyst with STRICT evidence standards.
Analyze the following **English review** using the "5W Analysis Framework" and extract key market elements.

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: All `content`, `content_translated`, and `explanation` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **content_original**: Keep in **Original English** (for evidence tracing).

# Input (English Review)
{original_text}

# âš ï¸ EVIDENCE STANDARDS (MOST CRITICAL)

**The "Courage to Say Nothing" Rule:**
It is FAR BETTER to return an empty array than to make a weak or speculative extraction!

## Confidence Levels (MUST include in output)
- **high**: Reviewer EXPLICITLY states the information
  - âœ… "I bought this for my mom" â†’ buyer with confidence: "high"
  - âœ… "I'm a heavy sleeper" â†’ user with confidence: "high"
  
- **medium**: Information can be REASONABLY INFERRED from clear context
  - âœ… "Works great for my morning routine" â†’ when: "æ—©æ™¨" with confidence: "medium"
  
- **low**: DO NOT OUTPUT! If evidence is weak, do not extract at all.
  - âŒ Product is an alarm clock â†’ assuming user is "æ·±ç¡äººç¾¤" (WRONG!)
  - âŒ General praise like "Great product!" â†’ extracting any 5W (WRONG!)

## When NOT to Extract (Return Empty Array Instead)
1. Review only talks about product quality (e.g., "Great product!", "Love it!")
2. No direct evidence in the review text for that category
3. Extraction would be based on product type assumptions, not review content
4. The connection requires more than one logical leap

**Remember: An empty array [] is a VALID and often CORRECT answer!**

# Extract the following 6 core elements (leave empty array if not mentioned):

**CRITICAL: Distinguish Buyer vs User**
- **Buyer**: The person who PAYS (e.g., "I bought this for my son" â†’ Buyer is "å¦ˆå¦ˆ/çˆ¸çˆ¸")
- **User**: The person who USES (e.g., "my son loves it" â†’ User is "å­©å­")
- If same person, put in **User** only

1. **buyer (Purchaser/Gift Giver)**: 
   - Definition: Who is paying for the product?
   - Look for: "I bought this for...", "Gift for...", "Ordered for my..."
   - Output examples (Chinese): å¦ˆå¦ˆ, é€ç¤¼è€…, ä¸ˆå¤«, ä¼ä¸šé‡‡è´­

2. **user (Actual User)**: 
   - Definition: Who is actually using the product?
   - Look for: "My son uses it", "Works great for my elderly mom", "I use it daily"
   - Output examples (Chinese): 3å²å¹¼å„¿, è€å¹´äºº, å‘˜å·¥, æ¸¸æˆç©å®¶

3. **where (Location)**: 
   - Definition: In what physical space is it used?
   - Output examples (Chinese): å§å®¤, åŠå…¬å®¤, æˆ¿è½¦, è½¦åº“, æˆ·å¤–éœ²è¥

4. **when (Timing)**: 
   - Definition: At what time or specific situation is it used?
   - Output examples (Chinese): ç¡å‰, åœç”µæ—¶, åœ£è¯èŠ‚æ—©æ™¨, è¿åŠ¨å

5. **why (Purchase Motivation)**: 
   - Definition: What triggered the purchase decision? (Purchase Driver)
   - Output examples (Chinese): æ—§çš„åäº†, ä½œä¸ºç”Ÿæ—¥ç¤¼ç‰©, ä¸ºäº†çœé’±, æ¬æ–°å®¶

6. **what (Jobs to be Done)**: 
   - Definition: What specific task is the user trying to accomplish?
   - Note: Focus on tasks, not product features.
   - Output examples (Chinese): æ¸…ç†çŒ«æ¯›, ç¼“è§£èƒŒç—›, å“„å­©å­ç¡è§‰

# Output Format (JSON)
{{
  "buyer": [
    {{
      "content": "å®å¦ˆ",
      "content_original": "I bought this for my son",
      "content_translated": "æˆ‘ç»™å„¿å­ä¹°çš„",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®è¯´'ç»™å„¿å­ä¹°çš„'ï¼Œè¯æ˜è´­ä¹°è€…æ˜¯æ¯äº²"
    }}
  ],
  "user": [
    {{
      "content": "3å²ç”·ç«¥",
      "content_original": "my 3 year old loves it",
      "content_translated": "æˆ‘3å²çš„å­©å­å¾ˆå–œæ¬¢",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®æåˆ°'3å²çš„å­©å­'æ˜¯ä½¿ç”¨è€…"
    }}
  ],
  "what": [],
  "why": [],
  "where": [],
  "when": []
}}

# Example of CORRECT Behavior for Short Reviews
Input: "Amazing alarm clock! Works perfectly!"
Output: {{ "buyer": [], "user": [], "where": [], "when": [], "why": [], "what": [] }}
Reason: Review only praises product quality, no 5W elements mentioned.
"""


# [UPDATED 2026-01-14] 5W æ ‡ç­¾å‘ç° Prompt (å­¦ä¹ é˜¶æ®µ - Who æ‹†åˆ†ä¸º Buyer + User)
CONTEXT_DISCOVERY_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¸‚åœºè¥é”€ä¸“å®¶å’Œç”¨æˆ·ç ”ç©¶å‘˜ã€‚è¯·åŸºäºä»¥ä¸‹**äº§å“å®˜æ–¹ä¿¡æ¯**å’Œ**ç”¨æˆ·è¯„è®ºæ ·æœ¬**ï¼Œæ„å»ºè¯¥äº§å“çš„"5W ç”¨æˆ·ä¸å¸‚åœºæ¨¡å‹"ã€‚

# äº§å“å®˜æ–¹ä¿¡æ¯ï¼ˆå–å®¶å®šä¹‰ï¼‰
- **äº§å“æ ‡é¢˜**: {product_title}
- **æ ¸å¿ƒå–ç‚¹ (Bullet Points)**:
{bullet_points}

# ç”¨æˆ·è¯„è®ºæ ·æœ¬ï¼ˆ{count}æ¡ä¹°å®¶åé¦ˆï¼‰
{reviews_text}

# ä»»åŠ¡
è¯·ç»¼åˆå®˜æ–¹å®šä½ä¸ç”¨æˆ·åé¦ˆï¼Œè¯†åˆ«å¹¶å½’çº³å‡ºä»¥ä¸‹ **6 ç±»æ ¸å¿ƒè¦ç´ **ï¼Œæ¯ç±»æå– **Top 5-8 ä¸ªå…¸å‹æ ‡ç­¾**ï¼š

**é‡è¦ï¼šå¿…é¡»åŒºåˆ†è´­ä¹°è€…å’Œä½¿ç”¨è€…**
- **è´­ä¹°è€…(Buyer)**: ä»˜é’±ä¹°äº§å“çš„äººï¼ˆå¦‚ï¼šå¦ˆå¦ˆç»™å­©å­ä¹°ã€é€ç¤¼è€…ï¼‰
- **ä½¿ç”¨è€…(User)**: å®é™…ä½¿ç”¨äº§å“çš„äººï¼ˆå¦‚ï¼šå­©å­ã€æ”¶ç¤¼è€…ã€è€äººï¼‰
- å¦‚æœè´­ä¹°è€…å’Œä½¿ç”¨è€…æ˜¯åŒä¸€äººï¼Œåªå¡«å…¥**ä½¿ç”¨è€…**ç±»åˆ«

1. **Buyer (è´­ä¹°è€…)**: è°æ˜¯è´­ä¹°å†³ç­–è€…ï¼Ÿè°ä»˜é’±ï¼Ÿ
   - å…³æ³¨è¡¨è¿°å¦‚ï¼š"I bought this for..."ã€"Gift for..."ã€"Ordered for my..."
   - ç¤ºä¾‹æ ‡ç­¾ï¼šå¦ˆå¦ˆã€é€ç¤¼è€…ã€ä¸ˆå¤«ã€ä¼ä¸šé‡‡è´­ã€å¥³å„¿(ä¸ºçˆ¶æ¯ä¹°)
   - é‡ç‚¹è¯†åˆ«è´­ä¹°å†³ç­–è€…çš„èº«ä»½

2. **User (ä½¿ç”¨è€…)**: è°å®é™…ä½¿ç”¨äº§å“ï¼Ÿ
   - å…³æ³¨è¡¨è¿°å¦‚ï¼š"My son loves it"ã€"Works great for my elderly mom"ã€"I use it daily"
   - ç¤ºä¾‹æ ‡ç­¾ï¼š3å²å¹¼å„¿ã€è€å¹´äººã€å‘˜å·¥ã€æ•æ„Ÿè‚Œäººç¾¤ã€æ¸¸æˆç©å®¶
   - å¦‚æœä¹°å®¶è‡ªç”¨ï¼ˆå¦‚"I bought this for myself"ï¼‰ï¼Œæ”¾å…¥æ­¤ç±»åˆ«

3. **Where (åœ°ç‚¹)**: åœ¨å“ªé‡Œä½¿ç”¨ï¼Ÿ
   - ä¼˜å…ˆå‚è€ƒå®˜æ–¹å®šä½ï¼ˆå¦‚: "for Home Office, Garage"ï¼‰
   - ç»“åˆç”¨æˆ·å®é™…ä½¿ç”¨åœºæ™¯
   - ç‰©ç†ç©ºé—´ï¼Œå¦‚: å§å®¤ã€åŠå…¬å®¤ã€å¨æˆ¿ã€è½¦ä¸Šã€æˆ¿è½¦(RV)ã€æˆ·å¤–éœ²è¥

4. **When (æ—¶åˆ»)**: ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ï¼Ÿ
   - æ—¶é—´ç‚¹ï¼Œå¦‚: æ—©ä¸Šã€ç¡å‰ã€æ·±å¤œ
   - è§¦å‘æ—¶æœºï¼Œå¦‚: åœç”µæ—¶ã€æ—…è¡Œæ—¶ã€è¿åŠ¨åã€èŠ‚å‡æ—¥

5. **Why (åŠ¨æœº)**: è´­ä¹°çš„è§¦å‘ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ(Purchase Driver)
   - æ›¿ä»£éœ€æ±‚ï¼Œå¦‚: æ—§çš„åäº†ã€å‡çº§æ¢ä»£
   - é€ç¤¼éœ€æ±‚ï¼Œå¦‚: ç”Ÿæ—¥ç¤¼ç‰©ã€åœ£è¯ç¤¼ç‰©ã€ä¹”è¿é€ç¤¼
   - å¤–éƒ¨é©±åŠ¨ï¼Œå¦‚: è¢«ç§è‰ã€çœ‹äº†è¯„æµ‹ã€æœ‹å‹æ¨è

6. **What (ä»»åŠ¡)**: ç”¨æˆ·è¯•å›¾ç”¨å®ƒå®Œæˆä»€ä¹ˆå…·ä½“ä»»åŠ¡ï¼Ÿ(Jobs to be Done)
   - **é‡ç‚¹å…³æ³¨å®˜æ–¹å®£ä¼ çš„æ ¸å¿ƒç”¨é€”**ï¼ˆå¦‚: "remove pet hair", "eliminate odors"ï¼‰
   - æ³¨æ„: æ˜¯å…·ä½“ä»»åŠ¡ï¼Œä¸æ˜¯äº§å“åŠŸèƒ½
   - å¦‚: æ¸…ç†åœ°æ¯¯ä¸Šçš„å® ç‰©æ¯›ã€ç¼“è§£èƒŒç—›ã€å“„å­©å­ç¡è§‰ã€å»é™¤å¼‚å‘³

# è¦æ±‚
1. **æ ‡ç­¾åç§°ä½¿ç”¨ç®€ç»ƒçš„ä¸­æ–‡**ï¼ˆ2-6ä¸ªå­—æœ€ä½³ï¼‰ã€‚
2. **åˆå¹¶åŒä¹‰è¯**ï¼šå¦‚"å¦ˆå¦ˆ"ã€"è€å¦ˆ"ã€"æ¯äº²"åº”ç»Ÿä¸€ä¸ºä¸€ä¸ªæ ‡ç­¾ã€‚
3. **ä¿æŒé¢—ç²’åº¦ä¸€è‡´**ï¼šä¸è¦å¤ªç²—ï¼ˆå¦‚"å®¶äºº"ï¼‰ä¹Ÿä¸è¦å¤ªç»†ï¼ˆå¦‚"62å²çš„ç‹¬å±…æ¯äº²"ï¼‰ã€‚
4. **å®˜æ–¹ä¿¡æ¯ä¼˜å…ˆ**ï¼šå¦‚æœå®˜æ–¹æ˜ç¡®æåˆ°çš„äººç¾¤/åœºæ™¯/ç”¨é€”ï¼Œå³ä½¿è¯„è®ºä¸­æ²¡æåŠä¹Ÿåº”åˆ—å…¥ã€‚
5. **æä¾›ç®€çŸ­æè¿°**ï¼šç”¨ä¸€å¥è¯è§£é‡Šè¯¥æ ‡ç­¾çš„å«ä¹‰ï¼Œä¾¿äºåç»­å½’ç±»åˆ¤æ–­ã€‚

# è¾“å‡ºæ ¼å¼ (JSON Only)
{{
  "buyer": [
    {{ "name": "å®å¦ˆ", "description": "ä¸ºå­©å­è´­ä¹°äº§å“çš„æ¯äº²" }},
    {{ "name": "é€ç¤¼è€…", "description": "è´­ä¹°äº§å“ä½œä¸ºç¤¼ç‰©é€äººçš„ç”¨æˆ·" }}
  ],
  "user": [
    {{ "name": "3å²å¹¼å„¿", "description": "å®é™…ä½¿ç”¨äº§å“çš„ä½é¾„å„¿ç«¥" }},
    {{ "name": "è€å¹´äºº", "description": "å®é™…ä½¿ç”¨äº§å“çš„è€å¹´äººç¾¤" }}
  ],
  "where": [
    {{ "name": "å§å®¤", "description": "å§å®¤/ç¡çœ åœºæ™¯ä¸‹ä½¿ç”¨" }},
    {{ "name": "è½¦åº“", "description": "å®˜æ–¹æ¨èçš„ä½¿ç”¨åœºæ™¯ä¹‹ä¸€" }}
  ],
  "when": [
    {{ "name": "ç¡å‰", "description": "ç¡è§‰å‰ä½¿ç”¨" }}
  ],
  "why": [
    {{ "name": "æ›¿ä»£æ—§å“", "description": "åŸæœ‰äº§å“æŸåéœ€è¦æ›´æ¢" }},
    {{ "name": "é€ç¤¼", "description": "ä½œä¸ºç¤¼ç‰©é€ç»™ä»–äºº" }}
  ],
  "what": [
    {{ "name": "æ¸…ç†å® ç‰©æ¯›", "description": "å®˜æ–¹æ ¸å¿ƒç”¨é€”ï¼šæ¸…ç†å®¶ä¸­çš„çŒ«æ¯›ç‹—æ¯›" }},
    {{ "name": "å»é™¤å¼‚å‘³", "description": "å®˜æ–¹æ ¸å¿ƒç”¨é€”ï¼šæ¶ˆé™¤å® ç‰©æˆ–å…¶ä»–å¼‚å‘³" }}
  ]
}}

è¯·åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šæ–‡å­—ã€‚"""


# [UPDATED 2026-01-14] è·¨è¯­è¨€5W å®šå‘æå– Prompt (æ‰§è¡Œé˜¶æ®µ - Who æ‹†åˆ†ä¸º Buyer + User)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µå’Œä¸¥æ ¼è¯æ®è¦æ±‚
THEME_EXTRACTION_PROMPT_WITH_SCHEMA = """You are a professional marketing analyst with STRICT evidence standards.
Analyze the following **English review** and identify the 5W elements it contains.

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: `quote_translated` and `explanation` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **quote**: Keep in **Original English** (for evidence tracing).
- **tag**: Must match exactly with the provided Schema labels (Chinese).

# Input (English Review)
{original_text}

# Label Schema (MUST use these labels only)
{schema_str}

# âš ï¸ EVIDENCE STANDARDS (MOST CRITICAL)

**The "Courage to Say Nothing" Rule:**
It is FAR BETTER to return an empty array than to make a weak or speculative categorization!

## Confidence Levels (MUST include in output)
- **high**: Reviewer EXPLICITLY states the information in the review text
  - âœ… "I bought this for my mom" â†’ buyer: å­å¥³ (high)
  - âœ… "I'm a heavy sleeper" â†’ user: æ·±ç¡äººç¾¤ (high)
  
- **medium**: Information can be REASONABLY INFERRED from clear context
  - âœ… "Works great for my morning routine" â†’ when: æ—©æ™¨ (medium)
  - âœ… "Perfect for the nursery" â†’ where: å„¿ç«¥æˆ¿ (medium)
  
- **low**: DO NOT OUTPUT! If evidence is weak, do not categorize at all.
  - âŒ Product is an alarm clock â†’ assuming user is "æ·±ç¡äººç¾¤" (WRONG!)
  - âŒ Product is a toy â†’ assuming buyer is "å®¶é•¿" without evidence (WRONG!)

## When NOT to Categorize (Return Empty Array Instead)
1. Review only talks about product quality (e.g., "Great product!", "Love it!")
2. No direct evidence in the review text for that category
3. Categorization would be based on product type assumptions, not review content
4. You're relying on stereotypes or common associations
5. The connection requires more than one logical leap

**Remember: An empty array [] is a VALID and often CORRECT answer!**

# Task Rules
1. **Evidence-First**: Only categorize when there is CLEAR evidence in the review text
2. **Forced Labels**: The `tag` field must exactly match a label from the schema
3. **Quote Required**: Must include the exact English quote that supports categorization
4. **Confidence Required**: Must include confidence level (high/medium only, never low)
5. **Explanation Required**: Explain WHY this quote supports this categorization

**CRITICAL: Distinguish Buyer vs User**
- **buyer**: The person who PAYS/purchases (e.g., "I bought this for my son" â†’ Buyer is the parent)
- **user**: The person who USES the product (e.g., "my son loves it" â†’ User is the child)
- If same person, put in **user** only
- If unclear who pays vs uses, put in **user** only

# Output Format (JSON Only)
{{
  "buyer": [
    {{
      "tag": "å®å¦ˆ", 
      "quote": "I bought this for my son",
      "quote_translated": "æˆ‘ç»™å„¿å­ä¹°çš„",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®è¯´'ç»™å„¿å­ä¹°çš„'ï¼Œè¯æ˜è´­ä¹°è€…æ˜¯æ¯äº²"
    }}
  ],
  "user": [
    {{
      "tag": "3å²ç”·ç«¥", 
      "quote": "my 3 year old loves it",
      "quote_translated": "æˆ‘3å²çš„å­©å­å¾ˆå–œæ¬¢",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®æåˆ°'3å²çš„å­©å­'æ˜¯ä½¿ç”¨è€…"
    }}
  ],
  "where": [],
  "when": [],
  "why": [
    {{
      "tag": "é€ç¤¼",
      "quote": "as a gift for my mom",
      "quote_translated": "ä½œä¸ºç¤¼ç‰©é€ç»™å¦ˆå¦ˆ",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®è¯´'ä½œä¸ºç¤¼ç‰©'ï¼Œè´­ä¹°åŠ¨æœºæ˜¯é€ç¤¼"
    }}
  ],
  "what": []
}}

# Examples of CORRECT Behavior

Example 1 - Short positive review with no 5W info:
Input: "Amazing alarm clock! Works perfectly!"
Output: {{ "buyer": [], "user": [], "where": [], "when": [], "why": [], "what": [] }}
Reason: Review only praises product quality, no 5W elements mentioned.

Example 2 - Review with clear evidence:
Input: "Bought this for my elderly mother who has trouble hearing. The loud alarm helps her wake up in the morning."
Output: {{
  "buyer": [{{"tag": "å­å¥³", "quote": "Bought this for my elderly mother", "quote_translated": "ç»™å¹´è¿ˆçš„æ¯äº²ä¹°çš„", "confidence": "high", "explanation": "æ˜ç¡®è¯´æ˜¯ç»™æ¯äº²è´­ä¹°"}}],
  "user": [{{"tag": "è€å¹´äºº", "quote": "my elderly mother who has trouble hearing", "quote_translated": "å¹´è¿ˆçš„æ¯äº²å¬åŠ›ä¸å¥½", "confidence": "high", "explanation": "æ˜ç¡®è¯´ä½¿ç”¨è€…æ˜¯å¹´è¿ˆçš„æ¯äº²"}}],
  "where": [],
  "when": [{{"tag": "æ—©æ™¨", "quote": "wake up in the morning", "quote_translated": "æ—©ä¸Šèµ·åºŠ", "confidence": "high", "explanation": "æ˜ç¡®è¯´æ—©ä¸Šä½¿ç”¨"}}],
  "why": [],
  "what": [{{"tag": "èµ·åºŠ", "quote": "helps her wake up", "quote_translated": "å¸®åŠ©å¥¹èµ·åºŠ", "confidence": "high", "explanation": "æ˜ç¡®è¯´ç”¨é€”æ˜¯å¸®åŠ©èµ·åºŠ"}}]
}}

Output JSON only, no other text."""


# [NEW] Helper function for robust JSON parsing
def parse_json_safely(text: str):
    """
    Safely parse JSON from LLM output, handling markdown blocks and extra characters.
    """
    if not text:
        return None
        
    # 1. Try direct parsing
    try:
        return json.loads(text)
    except:
        pass
    
    # 2. Try to extract from ```json ... ``` blocks
    match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
    if match:
        try:
            return json.loads(match.group(1))
        except:
            pass
            
    # 3. Try to find the first [ or { and last ] or }
    try:
        text = text.strip()
        if '}' in text: # Likely an object
            start = text.find('{')
            end = text.rfind('}') + 1
            if start != -1 and end != -1:
                return json.loads(text[start:end])
        if ']' in text: # Likely an array
            start = text.find('[')
            end = text.rfind(']') + 1
            if start != -1 and end != -1:
                return json.loads(text[start:end])
    except:
        pass
        
    return None


class TranslationService:
    """
    Service for translating Amazon reviews using Qwen API.
    
    Features:
    - Context-aware e-commerce translation
    - Sentiment analysis
    - Automatic retry with exponential backoff
    - Rate limiting awareness
    """
    
    def __init__(self):
        """Initialize the translation service with Qwen API client."""
        if not settings.QWEN_API_KEY:
            logger.warning("QWEN_API_KEY not configured, translation will fail")
            self.client = None
        else:
            self.client = OpenAI(
                api_key=settings.QWEN_API_KEY,
                base_url=settings.QWEN_API_BASE,
                timeout=120.0,  # 2åˆ†é’Ÿè¶…æ—¶ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡
            )
        self.model = settings.QWEN_MODEL
    
    def _check_client(self) -> bool:
        """Check if API client is properly configured."""
        if self.client is None:
            logger.error("Translation service not configured: missing API key")
            return False
        return True
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def translate_text(self, text: str) -> str:
        """
        Translate English text to Chinese with e-commerce context.
        """
        if not self._check_client():
            raise RuntimeError("Translation service not configured")
        
        if not text or not text.strip():
            return ""
        
        # Clean text: remove extra whitespace and normalize
        text = " ".join(text.split())
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": TRANSLATION_SYSTEM_PROMPT},
                    {"role": "user", "content": text}
                ],
                temperature=0.3,  # Lower temperature for more consistent translations
                max_tokens=2000,
                timeout=60.0,
            )
            
            translated = response.choices[0].message.content.strip()
            
            # Validate translation result
            if not translated or len(translated.strip()) == 0:
                logger.warning(f"Translation returned empty for text: {text[:100]}")
                # Retry with a more explicit prompt for short text
                if len(text) < 50:
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œå³ä½¿æ–‡æœ¬å¾ˆçŸ­ä¹Ÿè¦ç¿»è¯‘ã€‚"},
                            {"role": "user", "content": f"è¯·ç¿»è¯‘ï¼š{text}"}
                        ],
                        temperature=0.3,
                        max_tokens=500,
                    )
                    translated = response.choices[0].message.content.strip()
            
            if not translated or len(translated.strip()) == 0:
                # Fallback: return a note if translation truly fails
                logger.error(f"Translation failed to produce result for: {text[:100]}")
                raise ValueError(f"Translation returned empty for text: {text[:50]}")
            
            logger.debug(f"Translated: {text[:50]}... -> {translated[:50]}...")
            return translated
            
        except Exception as e:
            logger.error(f"Translation failed for text: {text[:100]}... Error: {e}")
            raise
    
    # ==========================================================================
    # ğŸ”¥ æ‰¹é‡ç¿»è¯‘æ–¹æ³•ï¼ˆ10 æ¡ä¸€æ‰¹ï¼Œæå‡ 10 å€æ•ˆç‡ï¼‰
    # ==========================================================================
    
    # æ‰¹é‡ç¿»è¯‘ç³»ç»Ÿæç¤º
    BATCH_TRANSLATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­ç¾æ–‡åŒ–å·®å¼‚çš„èµ„æ·±äºšé©¬é€Šè·¨å¢ƒç”µå•†ç¿»è¯‘ä¸“å®¶ã€‚

## ä»»åŠ¡
å°†å¤šæ¡äºšé©¬é€Šè‹±æ–‡è¯„è®ºæ‰¹é‡ç¿»è¯‘æˆä¸­æ–‡ã€‚

## ç¿»è¯‘åŸåˆ™
1. **æ‹’ç»ç¿»è¯‘è…”**: ä½¿ç”¨è‡ªç„¶æµç•…çš„ä¸­æ–‡è¡¨è¾¾
2. **æƒ…æ„Ÿå¯¹é½**: ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œæƒ…ç»ª
3. **ç”µå•†é£æ ¼**: ä½¿ç”¨ç¬¦åˆä¸­å›½ç”µå•†çš„æ–‡æ¡ˆé£æ ¼

## è¾“å…¥/è¾“å‡ºæ ¼å¼
- è¾“å…¥: JSON å­—å…¸ï¼Œé”®ä¸ºè¯„è®º IDï¼Œå€¼ä¸ºè‹±æ–‡åŸæ–‡
- è¾“å‡º: JSON å­—å…¸ï¼Œé”®ä¸è¾“å…¥ä¸€è‡´ï¼Œå€¼ä¸ºä¸­æ–‡è¯‘æ–‡
- **ä¸¥æ ¼è¦æ±‚**: åªè¿”å› JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€Markdown æ ‡è®°æˆ–å…¶ä»–æ–‡å­—

## ç¤ºä¾‹
è¾“å…¥: {"r1": "Total lemon. Don't waste your money.", "r2": "Game changer for my morning routine."}
è¾“å‡º: {"r1": "ç®€ç›´æ˜¯ä¸ªæ¬¡å“ï¼åˆ«æµªè´¹é’±äº†ã€‚", "r2": "å½»åº•æ”¹å˜äº†æˆ‘æ¯å¤©æ—©ä¸Šçš„ä¹ æƒ¯ï¼ŒçœŸé¦™ï¼"}"""

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=15),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def translate_batch(self, reviews: List[dict]) -> dict:
        """
        æ‰¹é‡ç¿»è¯‘å¤šæ¡è¯„è®ºï¼ˆ10 æ¡ä¸€æ‰¹ï¼‰
        
        ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–ï¼šä¸€æ¬¡ API è°ƒç”¨ç¿»è¯‘ 10 æ¡è¯„è®º
        - QPS æ¶ˆè€—é™ä½ 10 å€
        - æ€»ä½“æ•ˆç‡æå‡ 8-10 å€
        
        Args:
            reviews: è¯„è®ºåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« {"id": "xxx", "text": "original text"}
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸ï¼Œæ ¼å¼: {"id1": "translated1", "id2": "translated2", ...}
            
        Example:
            results = translation_service.translate_batch([
                {"id": "r1", "text": "Great product!"},
                {"id": "r2", "text": "Not worth the money."}
            ])
            # è¿”å›: {"r1": "å¾ˆæ£’çš„äº§å“ï¼", "r2": "ä¸å€¼è¿™ä¸ªä»·ã€‚"}
        """
        if not self._check_client():
            raise RuntimeError("Translation service not configured")
        
        if not reviews or len(reviews) == 0:
            return {}
        
        # æ„å»ºè¾“å…¥ JSON
        input_dict = {}
        for review in reviews:
            review_id = str(review.get("id", ""))
            text = review.get("text", "")
            if review_id and text and text.strip():
                # æˆªæ–­è¶…é•¿æ–‡æœ¬ï¼ˆé˜²æ­¢è¶…å‡º token é™åˆ¶ï¼‰
                text = " ".join(text.split())  # æ¸…ç†ç©ºç™½
                if len(text) > 2000:
                    text = text[:2000] + "..."
                input_dict[review_id] = text
        
        if not input_dict:
            return {}
        
        input_json = json.dumps(input_dict, ensure_ascii=False)
        
        logger.info(f"[æ‰¹é‡ç¿»è¯‘] å¼€å§‹ç¿»è¯‘ {len(input_dict)} æ¡è¯„è®º")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.BATCH_TRANSLATION_SYSTEM_PROMPT},
                    {"role": "user", "content": input_json}
                ],
                temperature=0.3,
                max_tokens=8000,  # æ‰¹é‡ç¿»è¯‘éœ€è¦æ›´å¤š token
                timeout=120.0,   # æ‰¹é‡ç¿»è¯‘éœ€è¦æ›´é•¿è¶…æ—¶
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # è§£æ JSON ç»“æœ
            result_dict = self._parse_batch_translation_result(result_text, input_dict)
            
            logger.info(f"[æ‰¹é‡ç¿»è¯‘] å®Œæˆ: è¾“å…¥ {len(input_dict)} æ¡, æˆåŠŸ {len(result_dict)} æ¡")
            
            return result_dict
            
        except Exception as e:
            logger.error(f"[æ‰¹é‡ç¿»è¯‘] API è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_batch_translation_result(self, result_text: str, input_dict: dict) -> dict:
        """
        è§£ææ‰¹é‡ç¿»è¯‘ç»“æœï¼Œå¸¦å®¹é”™å¤„ç†
        
        å¤„ç†å¸¸è§çš„ LLM è¾“å‡ºé—®é¢˜ï¼š
        1. å¤šä½™çš„ Markdown ä»£ç å—æ ‡è®°
        2. å‰åæœ‰è§£é‡Šæ–‡å­—
        3. JSON æ ¼å¼é”™è¯¯
        """
        result_dict = {}
        
        # 1. å°è¯•æ¸…ç† Markdown ä»£ç å—
        clean_text = result_text
        if "```json" in clean_text:
            match = re.search(r'```json\s*(.*?)\s*```', clean_text, re.DOTALL)
            if match:
                clean_text = match.group(1)
        elif "```" in clean_text:
            match = re.search(r'```\s*(.*?)\s*```', clean_text, re.DOTALL)
            if match:
                clean_text = match.group(1)
        
        # 2. å°è¯•æå– JSON å¯¹è±¡
        json_match = re.search(r'\{[^{}]*\}', clean_text, re.DOTALL)
        if json_match:
            clean_text = json_match.group(0)
        
        # 3. å°è¯•è§£æ JSON
        try:
            result_dict = json.loads(clean_text)
            if isinstance(result_dict, dict):
                # éªŒè¯é”®ä¸è¾“å…¥ä¸€è‡´
                valid_result = {}
                for key in input_dict.keys():
                    if key in result_dict and result_dict[key]:
                        valid_result[key] = str(result_dict[key]).strip()
                return valid_result
        except json.JSONDecodeError as e:
            logger.warning(f"[æ‰¹é‡ç¿»è¯‘] JSON è§£æå¤±è´¥: {e}")
        
        # 4. è§£æå¤±è´¥ï¼Œå°è¯• json_repairï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import json_repair
            repaired = json_repair.loads(clean_text)
            if isinstance(repaired, dict):
                valid_result = {}
                for key in input_dict.keys():
                    if key in repaired and repaired[key]:
                        valid_result[key] = str(repaired[key]).strip()
                return valid_result
        except ImportError:
            pass
        except Exception as e:
            logger.warning(f"[æ‰¹é‡ç¿»è¯‘] json_repair å¤±è´¥: {e}")
        
        # 5. æœ€ç»ˆå›é€€ï¼šè¿”å›ç©ºï¼Œè®©è°ƒç”¨æ–¹é™çº§ä¸ºå•æ¡ç¿»è¯‘
        logger.error(f"[æ‰¹é‡ç¿»è¯‘] æ— æ³•è§£æç»“æœï¼ŒåŸå§‹è¾“å‡º: {result_text[:500]}")
        return {}
    
    def translate_batch_with_fallback(self, reviews: List[dict]) -> dict:
        """
        æ‰¹é‡ç¿»è¯‘ï¼Œå¸¦å•æ¡å›é€€æœºåˆ¶
        
        å¦‚æœæ‰¹é‡ç¿»è¯‘å¤±è´¥æˆ–éƒ¨åˆ†å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§ä¸ºå•æ¡ç¿»è¯‘
        
        Args:
            reviews: è¯„è®ºåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« {"id": "xxx", "text": "original text"}
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸ï¼Œæ ¼å¼: {"id1": "translated1", "id2": "translated2", ...}
        """
        result = {}
        
        # 1. å°è¯•æ‰¹é‡ç¿»è¯‘
        try:
            batch_result = self.translate_batch(reviews)
            result.update(batch_result)
        except Exception as e:
            logger.warning(f"[æ‰¹é‡ç¿»è¯‘] æ‰¹é‡æ¨¡å¼å¤±è´¥ï¼Œé™çº§ä¸ºå•æ¡: {e}")
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœªç¿»è¯‘çš„è¯„è®ºï¼Œå•æ¡å›é€€
        for review in reviews:
            review_id = str(review.get("id", ""))
            text = review.get("text", "")
            
            if review_id and text and review_id not in result:
                try:
                    translated = self.translate_text(text)
                    if translated:
                        result[review_id] = translated
                        logger.debug(f"[æ‰¹é‡ç¿»è¯‘] å•æ¡å›é€€æˆåŠŸ: {review_id}")
                except Exception as e:
                    logger.warning(f"[æ‰¹é‡ç¿»è¯‘] å•æ¡å›é€€å¤±è´¥ {review_id}: {e}")
        
        return result
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def analyze_sentiment(self, text: str) -> Sentiment:
        """
        Analyze the sentiment of a review.
        """
        if not self._check_client():
            return Sentiment.NEUTRAL
        
        if not text or not text.strip():
            return Sentiment.NEUTRAL
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": SENTIMENT_ANALYSIS_PROMPT.format(review_text=text)}
                ],
                temperature=0.1,
                max_tokens=20,
                timeout=30.0,
            )
            
            result = response.choices[0].message.content.strip().lower()
            
            if "positive" in result:
                return Sentiment.POSITIVE
            elif "negative" in result:
                return Sentiment.NEGATIVE
            else:
                return Sentiment.NEUTRAL
                
        except Exception as e:
            logger.warning(f"Sentiment analysis failed: {e}, defaulting to neutral")
            return Sentiment.NEUTRAL
    
    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_dimensions(
        self, 
        reviews_text: List[str],
        product_title: str = "",
        bullet_points: str = ""
    ) -> List[dict]:
        """
        è®© AI ä»äº§å“ä¿¡æ¯å’Œè¯„è®ºæ ·æœ¬ä¸­å­¦ä¹ å¹¶æ€»ç»“äº§å“è¯„ä»·ç»´åº¦ã€‚
        
        Args:
            reviews_text: è¯„è®ºæ–‡æœ¬åˆ—è¡¨ï¼ˆå»ºè®®30-50æ¡ï¼‰
            product_title: äº§å“æ ‡é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºæä¾›äº§å“ä¸Šä¸‹æ–‡ï¼‰
            bullet_points: äº§å“äº”ç‚¹æè¿°ï¼ˆå¯é€‰ï¼Œç”¨äºè¡¥å……äº§å“å–ç‚¹ï¼‰
            
        Returns:
            ç»´åº¦åˆ—è¡¨ï¼Œæ¯ä¸ªç»´åº¦åŒ…å« name å’Œ description
            
        Example:
            [
                {"name": "ç”µæ± ç»­èˆª", "description": "ä¸å……ç”µé€Ÿåº¦å’Œä½¿ç”¨æ—¶é•¿ç›¸å…³çš„é—®é¢˜"},
                {"name": "å¤–è§‚è®¾è®¡", "description": "äº§å“çš„å¤–è§‚ã€é¢œè‰²ã€æè´¨ç­‰è§†è§‰ç›¸å…³è¯„ä»·"}
            ]
        """
        if not self._check_client():
            logger.error("Translation service not configured for dimension learning")
            return []
        
        # [UPDATED 2026-01-19] é™ä½æœ€ä½æ ·æœ¬è¦æ±‚
        if not reviews_text or len(reviews_text) < 1:
            logger.warning("æ²¡æœ‰å¯ç”¨æ ·æœ¬ï¼Œæ— æ³•å­¦ä¹ ç»´åº¦")
            return []
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… token
        sample_texts = reviews_text[:50]
        combined_text = "\n---\n".join(sample_texts)
        
        # å¤„ç†äº§å“ä¿¡æ¯
        title_text = product_title.strip() if product_title else "ï¼ˆæœªæä¾›ï¼‰"
        bullet_text = bullet_points.strip() if bullet_points else "ï¼ˆæœªæä¾›ï¼‰"
        
        try:
            prompt = DIMENSION_DISCOVERY_PROMPT.format(
                product_title=title_text,
                bullet_points=bullet_text,
                count=len(sample_texts),
                reviews_text=combined_text
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
                max_tokens=2000,
                timeout=90.0,
            )
            
            result = response.choices[0].message.content.strip()
            
            # ä½¿ç”¨å¥å£®çš„ JSON è§£æå™¨
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict) or "dimensions" not in parsed:
                logger.warning(f"ç»´åº¦å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return []
            
            dimensions = parsed.get("dimensions", [])
            
            # éªŒè¯ç»´åº¦æ ¼å¼
            valid_dimensions = []
            for dim in dimensions:
                if isinstance(dim, dict) and dim.get("name"):
                    valid_dimensions.append({
                        "name": dim["name"].strip(),
                        "description": (dim.get("description") or "").strip()
                    })
            
            logger.info(f"AI æˆåŠŸå­¦ä¹ åˆ° {len(valid_dimensions)} ä¸ªäº§å“ç»´åº¦")
            return valid_dimensions
            
        except Exception as e:
            logger.error(f"ç»´åº¦å­¦ä¹ å¤±è´¥: {e}")
            return []

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_dimensions_from_raw(
        self, 
        raw_reviews: List[str],
        product_title: str = "",
        bullet_points: str = ""
    ) -> dict:
        """
        è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹ ï¼šä»è‹±æ–‡åŸæ–‡è¯„è®ºç›´æ¥å­¦ä¹ 3ç±»ç»´åº¦ï¼ˆè¾“å‡ºä¸­æ–‡ï¼‰ã€‚
        
        [UPDATED 2026-01-16] æ‰©å±•ä¸º3ç±»ç»´åº¦ä½“ç³»ï¼š
        - äº§å“ç»´åº¦ (product): ç”¨äº strength/weakness/suggestion
        - åœºæ™¯ç»´åº¦ (scenario): ç”¨äº scenario ç±»å‹æ´å¯Ÿ
        - æƒ…ç»ªç»´åº¦ (emotion): ç”¨äº emotion ç±»å‹æ´å¯Ÿ
        
        è¿™æ˜¯æµå¼å¤„ç†æ¶æ„çš„æ ¸å¿ƒæ–¹æ³•ï¼š
        - ä¸éœ€è¦ç­‰å¾…ç¿»è¯‘å®Œæˆ
        - ç›´æ¥ä½¿ç”¨è‹±æ–‡åŸæ–‡è¿›è¡Œå­¦ä¹ 
        - AI è¾“å‡ºä¸­æ–‡ç»´åº¦åç§°å’Œæè¿°
        
        Args:
            raw_reviews: è‹±æ–‡åŸæ–‡è¯„è®ºåˆ—è¡¨ï¼ˆæ¥è‡ª get_scientific_samplesï¼‰
            product_title: äº§å“è‹±æ–‡æ ‡é¢˜
            bullet_points: äº§å“è‹±æ–‡äº”ç‚¹æè¿°
            
        Returns:
            3ç±»ç»´åº¦å­—å…¸ï¼ˆä¸­æ–‡ï¼‰ï¼Œæ ¼å¼ï¼š
            {
                "product": [{"name": "åŠŸèƒ½è¡¨ç°", "description": "..."}, ...],
                "scenario": [{"name": "å®¶å±…æ—¥å¸¸", "description": "..."}, ...],
                "emotion": [{"name": "æƒŠå–œå¥½è¯„", "description": "..."}, ...]
            }
            
            å‘åå…¼å®¹ï¼šå¦‚æœè°ƒç”¨æ–¹æœŸæœ› List[dict]ï¼Œå¯ä»¥ä½¿ç”¨ result.get("product", [])
        """
        if not self._check_client():
            logger.error("Translation service not configured for raw dimension learning")
            return {}
        
        # [UPDATED 2026-01-19] é™ä½æœ€ä½æ ·æœ¬è¦æ±‚ï¼Œåªè¦æœ‰è¯„è®ºå°±å°è¯•å­¦ä¹ 
        if not raw_reviews or len(raw_reviews) < 1:
            logger.warning("æ²¡æœ‰å¯ç”¨æ ·æœ¬ï¼Œæ— æ³•å­¦ä¹ ç»´åº¦")
            return None
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… token
        sample_texts = raw_reviews[:50]
        combined_text = "\n---\n".join([f"Review {i+1}: {text}" for i, text in enumerate(sample_texts)])
        
        # å¤„ç†äº§å“ä¿¡æ¯
        title_text = product_title.strip() if product_title else "(Not provided)"
        bullet_text = bullet_points.strip() if bullet_points else "(Not provided)"
        
        try:
            prompt = DIMENSION_DISCOVERY_RAW_PROMPT.format(
                product_title=title_text,
                bullet_points=bullet_text,
                count=len(sample_texts),
                reviews_text=combined_text
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000,  # å¢åŠ  token é™åˆ¶ä»¥æ”¯æŒ3ç±»ç»´åº¦
                timeout=120.0,   # å¢åŠ è¶…æ—¶æ—¶é—´
            )
            
            result = response.choices[0].message.content.strip()
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict):
                logger.warning(f"è·¨è¯­è¨€ç»´åº¦å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                # [FIX] è¿”å› None è€Œä¸æ˜¯ç©ºå­—å…¸ï¼Œè®©è°ƒç”¨æ–¹çŸ¥é“æ˜¯è§£æå¤±è´¥
                return None
            
            # [UPDATED] è§£æ3ç±»ç»´åº¦
            valid_result = {}
            
            # 1. äº§å“ç»´åº¦
            product_dims = parsed.get("product_dimensions", [])
            valid_product = []
            for dim in product_dims:
                if isinstance(dim, dict) and dim.get("name"):
                    valid_product.append({
                        "name": dim["name"].strip(),
                        "description": (dim.get("description") or "").strip()
                    })
            if valid_product:
                valid_result["product"] = valid_product
            
            # 2. åœºæ™¯ç»´åº¦
            scenario_dims = parsed.get("scenario_dimensions", [])
            valid_scenario = []
            for dim in scenario_dims:
                if isinstance(dim, dict) and dim.get("name"):
                    valid_scenario.append({
                        "name": dim["name"].strip(),
                        "description": (dim.get("description") or "").strip()
                    })
            if valid_scenario:
                valid_result["scenario"] = valid_scenario
            
            # 3. æƒ…ç»ªç»´åº¦
            emotion_dims = parsed.get("emotion_dimensions", [])
            valid_emotion = []
            for dim in emotion_dims:
                if isinstance(dim, dict) and dim.get("name"):
                    valid_emotion.append({
                        "name": dim["name"].strip(),
                        "description": (dim.get("description") or "").strip()
                    })
            if valid_emotion:
                valid_result["emotion"] = valid_emotion
            
            # å‘åå…¼å®¹ï¼šå¦‚æœAIè¿”å›æ—§æ ¼å¼ï¼ˆå•ä¸€ dimensions åˆ—è¡¨ï¼‰ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼
            if not valid_result and "dimensions" in parsed:
                old_dims = parsed.get("dimensions", [])
                valid_product = []
                for dim in old_dims:
                    if isinstance(dim, dict) and dim.get("name"):
                        valid_product.append({
                            "name": dim["name"].strip(),
                            "description": (dim.get("description") or "").strip()
                        })
                if valid_product:
                    valid_result["product"] = valid_product
                    # æ·»åŠ é»˜è®¤çš„åœºæ™¯å’Œæƒ…ç»ªç»´åº¦
                    valid_result["scenario"] = [
                        {"name": "å®¶å±…æ—¥å¸¸", "description": "åœ¨å®¶ä¸­æ—¥å¸¸ç”Ÿæ´»åœºæ™¯"},
                        {"name": "å·¥ä½œåŠå…¬", "description": "åŠå…¬å®¤æˆ–å·¥ä½œåœºæ™¯"},
                        {"name": "æˆ·å¤–å‡ºè¡Œ", "description": "æˆ·å¤–æ´»åŠ¨æˆ–å‡ºè¡Œåœºæ™¯"}
                    ]
                    valid_result["emotion"] = [
                        {"name": "æƒŠå–œå¥½è¯„", "description": "è¶…å‡ºé¢„æœŸçš„æ­£é¢æƒ…ç»ª"},
                        {"name": "å¤±æœ›ä¸æ»¡", "description": "æœŸæœ›è½ç©ºçš„è´Ÿé¢æƒ…ç»ª"},
                        {"name": "æ„Ÿæ¿€æ¨è", "description": "æ„Ÿè°¢å¹¶æ„¿æ„æ¨èçš„æƒ…ç»ª"}
                    ]
                    logger.warning("[è·¨è¯­è¨€å­¦ä¹ ] AIè¿”å›æ—§æ ¼å¼ï¼Œå·²è‡ªåŠ¨è¡¥å……åœºæ™¯å’Œæƒ…ç»ªç»´åº¦")
            
            total_dims = sum(len(v) for v in valid_result.values())
            
            # [FIX 2026-01-19] ç»“æœæ ¡éªŒ - ç¡®ä¿æ¯ç±»ç»´åº¦è‡³å°‘æœ‰ 2 ä¸ª
            product_count = len(valid_result.get('product', []))
            scenario_count = len(valid_result.get('scenario', []))
            emotion_count = len(valid_result.get('emotion', []))
            
            if product_count < 2 or scenario_count < 2 or emotion_count < 2:
                logger.warning(f"[è·¨è¯­è¨€å­¦ä¹ ] ç»´åº¦æ•°é‡ä¸è¶³: äº§å“={product_count}, åœºæ™¯={scenario_count}, æƒ…ç»ª={emotion_count}ï¼Œéœ€è¦æ¯ç±»è‡³å°‘2ä¸ª")
                return None  # è¿”å› None è¡¨ç¤ºå­¦ä¹ å¤±è´¥ï¼Œè§¦å‘é‡è¯•
            
            logger.info(f"[è·¨è¯­è¨€å­¦ä¹ ] ä» {len(sample_texts)} æ¡è‹±æ–‡è¯„è®ºå­¦ä¹ åˆ° {total_dims} ä¸ªä¸­æ–‡ç»´åº¦ "
                       f"(äº§å“:{product_count}, åœºæ™¯:{scenario_count}, æƒ…ç»ª:{emotion_count})")
            return valid_result
            
        except Exception as e:
            logger.error(f"è·¨è¯­è¨€ç»´åº¦å­¦ä¹ å¤±è´¥: {e}")
            # [FIX] è¿”å› None è€Œä¸æ˜¯ç©ºå­—å…¸ï¼Œè§¦å‘é‡è¯•
            return None

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_context_labels_from_raw(
        self, 
        raw_reviews: List[str],
        product_title: str = "",
        bullet_points: List[str] = None
    ) -> dict:
        """
        è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹ ï¼šä»è‹±æ–‡åŸæ–‡è¯„è®ºç›´æ¥å­¦ä¹  5W æ ‡ç­¾åº“ï¼ˆè¾“å‡ºä¸­æ–‡ï¼‰ã€‚
        
        è¿™æ˜¯æµå¼å¤„ç†æ¶æ„çš„æ ¸å¿ƒæ–¹æ³•ï¼š
        - ä¸éœ€è¦ç­‰å¾…ç¿»è¯‘å®Œæˆ
        - ç›´æ¥ä½¿ç”¨è‹±æ–‡åŸæ–‡è¿›è¡Œå­¦ä¹ 
        - AI è¾“å‡ºä¸­æ–‡æ ‡ç­¾åç§°å’Œæè¿°
        
        Args:
            raw_reviews: è‹±æ–‡åŸæ–‡è¯„è®ºåˆ—è¡¨ï¼ˆæ¥è‡ª get_scientific_samplesï¼‰
            product_title: äº§å“è‹±æ–‡æ ‡é¢˜
            bullet_points: äº§å“è‹±æ–‡äº”ç‚¹æè¿°åˆ—è¡¨
            
        Returns:
            5W æ ‡ç­¾å­—å…¸ï¼ˆä¸­æ–‡ï¼‰ï¼Œæ ¼å¼ï¼š
            {
                "who": [{"name": "è€å¹´äºº", "description": "..."}, ...],
                "where": [...],
                "when": [...],
                "why": [...],
                "what": [...]
            }
        """
        if not self._check_client():
            logger.error("Translation service not configured for raw context learning")
            return {}
        
        # [UPDATED 2026-01-19] é™ä½æœ€ä½æ ·æœ¬è¦æ±‚ï¼Œåªè¦æœ‰è¯„è®ºå°±å°è¯•å­¦ä¹ 
        if not raw_reviews or len(raw_reviews) < 1:
            logger.warning("æ²¡æœ‰å¯ç”¨æ ·æœ¬ï¼Œæ— æ³•å­¦ä¹  5W æ ‡ç­¾")
            return {}
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… token
        sample_texts = raw_reviews[:50]
        combined_reviews = "\n---\n".join([f"Review {i+1}: {text}" for i, text in enumerate(sample_texts)])
        
        # æ ¼å¼åŒ–äº§å“å®˜æ–¹ä¿¡æ¯
        formatted_title = product_title.strip() if product_title else "(Not provided)"
        formatted_bullets = "(Not provided)"
        if bullet_points and len(bullet_points) > 0:
            formatted_bullets = "\n".join([f"  - {bp}" for bp in bullet_points if bp and bp.strip()])
        
        logger.info(f"[è·¨è¯­è¨€å­¦ä¹ ] 5Wæ ‡ç­¾å­¦ä¹ ï¼š{len(sample_texts)} æ¡è‹±æ–‡è¯„è®º + äº§å“ä¿¡æ¯")
        
        try:
            prompt = CONTEXT_DISCOVERY_RAW_PROMPT.format(
                product_title=formatted_title,
                bullet_points=formatted_bullets,
                count=len(sample_texts),
                reviews_text=combined_reviews
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=120.0,
            )
            
            result = response.choices[0].message.content.strip()
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict):
                logger.warning(f"è·¨è¯­è¨€ 5W æ ‡ç­¾å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return {}
            
            # [UPDATED 2026-01-14] æ‰©å±• valid_types: buyer/user æ›¿ä»£ whoï¼ŒåŒæ—¶å…¼å®¹æ—§çš„ who
            valid_types = {"buyer", "user", "who", "where", "when", "why", "what"}
            valid_result = {}
            
            for context_type in valid_types:
                labels = parsed.get(context_type, [])
                valid_labels = []
                
                for label in labels:
                    if isinstance(label, dict) and label.get("name"):
                        valid_labels.append({
                            "name": label["name"].strip(),
                            "description": (label.get("description") or "").strip()
                        })
                
                if valid_labels:
                    valid_result[context_type] = valid_labels
            
            total_labels = sum(len(v) for v in valid_result.values())
            logger.info(f"[è·¨è¯­è¨€å­¦ä¹ ] ä»è‹±æ–‡è¯„è®ºå­¦ä¹ åˆ° {total_labels} ä¸ªä¸­æ–‡ 5W æ ‡ç­¾ï¼ˆ{len(valid_result)} ä¸ªç±»å‹ï¼‰")
            return valid_result
            
        except Exception as e:
            logger.error(f"è·¨è¯­è¨€ 5W æ ‡ç­¾å­¦ä¹ å¤±è´¥: {e}")
            return {}

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_context_labels(
        self, 
        reviews_text: List[str],
        product_title: str = "",
        bullet_points: List[str] = None
    ) -> dict:
        """
        è®© AI ç»“åˆäº§å“å®˜æ–¹ä¿¡æ¯å’Œè¯„è®ºæ ·æœ¬å­¦ä¹  5W æ ‡å‡†æ ‡ç­¾åº“ï¼ˆDefinition é˜¶æ®µï¼‰ã€‚
        
        è¿™æ˜¯ AI-Native æ¶æ„çš„æ ¸å¿ƒï¼š"å…ˆå­¦ä¹ æ ‡å‡†ï¼Œåå¼ºåˆ¶å½’ç±»"ã€‚
        AI ä¼šåˆ†æäº§å“æ ‡é¢˜ã€äº”ç‚¹å–ç‚¹å’Œè¯„è®ºæ ·æœ¬ï¼Œä¸ºæ¯ä¸ª 5W ç±»å‹ç”Ÿæˆæ ‡å‡†æ ‡ç­¾ã€‚
        
        **[UPDATED] åŠ å…¥äº§å“å®˜æ–¹ä¿¡æ¯ï¼š**
        - æ ‡é¢˜å’Œäº”ç‚¹æ˜¯å•†å®¶çš„"å–å®¶ç§€"ï¼Œå¾€å¾€æ¯”ç”¨æˆ·è¯„è®ºæ›´ç²¾å‡†
        - ç‰¹åˆ«å¯¹ Whoï¼ˆäººç¾¤ï¼‰ã€Whereï¼ˆåœºæ™¯ï¼‰ã€Whatï¼ˆä»»åŠ¡ï¼‰æå‡æ˜¾è‘—
        
        Args:
            reviews_text: è¯„è®ºæ–‡æœ¬åˆ—è¡¨ï¼ˆå»ºè®®30-50æ¡ï¼Œæ··åˆå¥½è¯„å·®è¯„ï¼‰
            product_title: äº§å“æ ‡é¢˜ï¼ˆè‹±æ–‡åŸæ–‡ï¼‰
            bullet_points: äº§å“äº”ç‚¹å–ç‚¹åˆ—è¡¨ï¼ˆè‹±æ–‡åŸæ–‡ï¼‰
            
        Returns:
            5W æ ‡ç­¾å­—å…¸ï¼Œæ ¼å¼ï¼š
            {
                "who": [{"name": "è€å¹´äºº", "description": "..."}, ...],
                "where": [...],
                "when": [...],
                "why": [...],
                "what": [...]
            }
            
        Example:
            >>> labels = service.learn_context_labels(
            ...     reviews[:50],
            ...     product_title="LED Light for Seniors",
            ...     bullet_points=["Perfect for elderly", "Home Office use"]
            ... )
        """
        if not self._check_client():
            logger.error("Translation service not configured for context learning")
            return {}
        
        # [UPDATED 2026-01-19] é™ä½æœ€ä½æ ·æœ¬è¦æ±‚
        if not reviews_text or len(reviews_text) < 1:
            logger.warning("æ²¡æœ‰å¯ç”¨æ ·æœ¬ï¼Œæ— æ³•å­¦ä¹  5W æ ‡ç­¾")
            return {}
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… tokenï¼ˆ50æ¡è¯„è®ºçº¦ 4000-6000 tokensï¼‰
        sample_texts = reviews_text[:50]
        combined_reviews = "\n---\n".join([f"è¯„è®º{i+1}: {text}" for i, text in enumerate(sample_texts)])
        
        # [NEW] æ ¼å¼åŒ–äº§å“å®˜æ–¹ä¿¡æ¯
        formatted_title = product_title.strip() if product_title else "ï¼ˆæ— ï¼‰"
        formatted_bullets = "ï¼ˆæ— ï¼‰"
        if bullet_points and len(bullet_points) > 0:
            formatted_bullets = "\n".join([f"  - {bp}" for bp in bullet_points if bp and bp.strip()])
        
        logger.info(f"5W æ ‡ç­¾å­¦ä¹ ï¼š{len(sample_texts)} æ¡è¯„è®º + äº§å“ä¿¡æ¯ï¼ˆæ ‡é¢˜: {len(formatted_title)}å­—, äº”ç‚¹: {len(bullet_points or [])}æ¡ï¼‰")
        
        try:
            prompt = CONTEXT_DISCOVERY_PROMPT.format(
                product_title=formatted_title,
                bullet_points=formatted_bullets,
                count=len(sample_texts),
                reviews_text=combined_reviews
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
                max_tokens=3000,
                timeout=120.0,  # ç¨é•¿çš„è¶…æ—¶æ—¶é—´
            )
            
            result = response.choices[0].message.content.strip()
            
            # ä½¿ç”¨å¥å£®çš„ JSON è§£æå™¨
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict):
                logger.warning(f"5W æ ‡ç­¾å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return {}
            
            # [UPDATED 2026-01-14] éªŒè¯å’Œæ¸…ç†æ¯ä¸ª 5W ç±»å‹çš„æ ‡ç­¾ï¼ˆæ‰©å±•ç‰ˆï¼šbuyer/user æ›¿ä»£ whoï¼‰
            valid_types = {"buyer", "user", "who", "where", "when", "why", "what"}
            valid_result = {}
            
            for context_type in valid_types:
                labels = parsed.get(context_type, [])
                valid_labels = []
                
                for label in labels:
                    if isinstance(label, dict) and label.get("name"):
                        valid_labels.append({
                            "name": label["name"].strip(),
                            "description": (label.get("description") or "").strip()
                        })
                
                if valid_labels:
                    valid_result[context_type] = valid_labels
                    logger.debug(f"  {context_type}: {len(valid_labels)} ä¸ªæ ‡ç­¾")
            
            total_labels = sum(len(v) for v in valid_result.values())
            logger.info(f"AI æˆåŠŸå­¦ä¹ åˆ° {total_labels} ä¸ª 5W æ ‡ç­¾ï¼ˆ{len(valid_result)} ä¸ªç±»å‹ï¼‰")
            return valid_result
            
        except Exception as e:
            logger.error(f"5W æ ‡ç­¾å­¦ä¹ å¤±è´¥: {e}")
            return {}

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def extract_insights(
        self,
        original_text: str,
        translated_text: str = None,  # [UPDATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å‚æ•°ä»…ä¸ºå‘åå…¼å®¹
        dimension_schema = None  # [UPDATED 2026-01-16] æ”¯æŒ List[dict] æˆ– dict (3ç±»ç»´åº¦)
    ) -> List[dict]:
        """
        Extract insights from a review using cross-language analysis.
        
        [UPDATED] è·¨è¯­è¨€æ´å¯Ÿæå– - ç›´æ¥ä»è‹±æ–‡åŸæ–‡æå–æ´å¯Ÿï¼Œè¾“å‡ºä¸­æ–‡ç»“æœã€‚
        ä¸å†ä¾èµ–ç¿»è¯‘åçš„æ–‡æœ¬ï¼Œå®ç°ä¸ç¿»è¯‘ä»»åŠ¡çš„å®Œå…¨è§£è€¦ã€‚
        
        [UPDATED 2026-01-16] æ”¯æŒ3ç±»ç»´åº¦ä½“ç³»ï¼š
        - äº§å“ç»´åº¦ (product): ç”¨äº strength/weakness/suggestion
        - åœºæ™¯ç»´åº¦ (scenario): ç”¨äº scenario ç±»å‹æ´å¯Ÿ
        - æƒ…ç»ªç»´åº¦ (emotion): ç”¨äº emotion ç±»å‹æ´å¯Ÿ
        
        Args:
            original_text: åŸå§‹è¯„è®ºæ–‡æœ¬ï¼ˆè‹±æ–‡ï¼‰
            translated_text: [DEPRECATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™ä»…ä¸ºå‘åå…¼å®¹
            dimension_schema: ç»´åº¦æ¨¡å¼ï¼Œæ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                - æ—§æ ¼å¼ List[dict]: [{"name": "ç»´åº¦å", "description": "..."}, ...]
                - æ–°æ ¼å¼ dict: {
                    "product": [{"name": "åŠŸèƒ½è¡¨ç°", "description": "..."}],
                    "scenario": [{"name": "å®¶å±…æ—¥å¸¸", "description": "..."}],
                    "emotion": [{"name": "æƒŠå–œå¥½è¯„", "description": "..."}]
                  }
        
        Returns:
            æ´å¯Ÿåˆ—è¡¨ï¼Œæ¯ä¸ªæ´å¯ŸåŒ…å« type, dimension, quote(è‹±æ–‡), quote_translated(ä¸­æ–‡), analysis(ä¸­æ–‡) ç­‰å­—æ®µ
        """
        if not self._check_client():
            return []
        
        # [ä¼˜åŒ–] ç§»é™¤é•¿åº¦é™åˆ¶ - ç¡®ä¿æ¯æ¡è¯„è®ºéƒ½èƒ½æå–æ´å¯Ÿ
        # å³ä½¿æ˜¯çŸ­è¯„è®ºä¹Ÿå¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯
        if not original_text or not original_text.strip():
            return []
        
        try:
            # [UPDATED 2026-01-16] æ£€æµ‹ç»´åº¦æ ¼å¼å¹¶æ„å»ºå¯¹åº”çš„ prompt
            if dimension_schema:
                # æ£€æµ‹æ˜¯æ–°æ ¼å¼ï¼ˆdict with product/scenario/emotionï¼‰è¿˜æ˜¯æ—§æ ¼å¼ï¼ˆlistï¼‰
                is_new_format = (
                    isinstance(dimension_schema, dict) and 
                    any(k in dimension_schema for k in ["product", "scenario", "emotion"])
                )
                
                if is_new_format:
                    # æ–°æ ¼å¼ï¼š3ç±»ç»´åº¦ä½“ç³»
                    product_dims = dimension_schema.get("product", [])
                    scenario_dims = dimension_schema.get("scenario", [])
                    emotion_dims = dimension_schema.get("emotion", [])
                    
                    # æ„å»º3ç±»ç»´åº¦çš„ schema å­—ç¬¦ä¸²
                    product_schema_str = "\n".join([
                        f"- {d['name']}: {d.get('description', 'æ— å…·ä½“å®šä¹‰')}" 
                        for d in product_dims
                    ]) if product_dims else "- æ•´ä½“æ»¡æ„åº¦: é€šç”¨äº§å“ç»´åº¦"
                    
                    scenario_schema_str = "\n".join([
                        f"- {d['name']}: {d.get('description', 'æ— å…·ä½“å®šä¹‰')}" 
                        for d in scenario_dims
                    ]) if scenario_dims else "- æ—¥å¸¸ä½¿ç”¨: é€šç”¨åœºæ™¯ç»´åº¦"
                    
                    emotion_schema_str = "\n".join([
                        f"- {d['name']}: {d.get('description', 'æ— å…·ä½“å®šä¹‰')}" 
                        for d in emotion_dims
                    ]) if emotion_dims else "- æ­£é¢æƒ…ç»ª: ç§¯ææƒ…æ„Ÿ\n- è´Ÿé¢æƒ…ç»ª: æ¶ˆææƒ…æ„Ÿ"
                    
                    prompt = INSIGHT_EXTRACTION_PROMPT_DYNAMIC.format(
                        original_text=original_text,
                        product_schema_str=product_schema_str,
                        scenario_schema_str=scenario_schema_str,
                        emotion_schema_str=emotion_schema_str
                    )
                    logger.debug(f"[è·¨è¯­è¨€æ´å¯Ÿ] ä½¿ç”¨3ç±»ç»´åº¦ Prompt "
                               f"(äº§å“:{len(product_dims)}, åœºæ™¯:{len(scenario_dims)}, æƒ…ç»ª:{len(emotion_dims)})")
                else:
                    # æ—§æ ¼å¼ï¼šå•ä¸€ç»´åº¦åˆ—è¡¨ï¼Œå‘åå…¼å®¹
                    # å°†æ—§æ ¼å¼è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼ˆå…¨éƒ¨ä½œä¸ºäº§å“ç»´åº¦ï¼Œä½¿ç”¨é»˜è®¤åœºæ™¯å’Œæƒ…ç»ªç»´åº¦ï¼‰
                    if isinstance(dimension_schema, list) and len(dimension_schema) > 0:
                        product_schema_str = "\n".join([
                    f"- {d['name']}: {d.get('description', 'æ— å…·ä½“å®šä¹‰')}" 
                    for d in dimension_schema
                ])
                        scenario_schema_str = "- æ—¥å¸¸ä½¿ç”¨: é€šç”¨åœºæ™¯ç»´åº¦\n- å·¥ä½œåŠå…¬: åŠå…¬åœºæ™¯\n- æˆ·å¤–å‡ºè¡Œ: æˆ·å¤–åœºæ™¯"
                        emotion_schema_str = "- æƒŠå–œå¥½è¯„: è¶…å‡ºé¢„æœŸçš„æ­£é¢æƒ…ç»ª\n- å¤±æœ›ä¸æ»¡: æœŸæœ›è½ç©ºçš„è´Ÿé¢æƒ…ç»ª\n- æ„Ÿæ¿€æ¨è: æ„Ÿè°¢å¹¶æ¨è"
                        
                prompt = INSIGHT_EXTRACTION_PROMPT_DYNAMIC.format(
                    original_text=original_text,
                            product_schema_str=product_schema_str,
                            scenario_schema_str=scenario_schema_str,
                            emotion_schema_str=emotion_schema_str
                )
                        logger.debug(f"[è·¨è¯­è¨€æ´å¯Ÿ] æ—§æ ¼å¼ç»´åº¦å·²è½¬æ¢ï¼Œå…± {len(dimension_schema)} ä¸ªäº§å“ç»´åº¦")
            else:
                        # ç»´åº¦åˆ—è¡¨ä¸ºç©ºï¼Œä½¿ç”¨æ— ç»´åº¦ Prompt
                prompt = INSIGHT_EXTRACTION_PROMPT.format(
                            original_text=original_text
                        )
            else:
                # ä½¿ç”¨æ— ç»´åº¦ Prompt - è‡ªåŠ¨æ£€æµ‹ç»´åº¦
                prompt = INSIGHT_EXTRACTION_PROMPT.format(
                    original_text=original_text
                )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2, # Lower temperature for structural extraction
                max_tokens=1500,
                timeout=60.0,
            )
            
            result = response.choices[0].message.content.strip()
            
            # [UPDATED] Use robust JSON parser
            insights = parse_json_safely(result)
            
            if not isinstance(insights, list):
                logger.warning(f"Parsed insights is not a list: {type(insights)}")
                return []
            
            # Validate insights
            valid_insights = []
            valid_types = {"strength", "weakness", "suggestion", "scenario", "emotion"}
            
            for insight in insights:
                if not isinstance(insight, dict):
                    continue
                if insight.get("type") not in valid_types:
                    continue
                if not insight.get("quote") or not insight.get("analysis"):
                    continue
                
                # [UPDATED 2026-01-15] æ·»åŠ  confidence å­—æ®µæ”¯æŒ
                confidence = insight.get("confidence", "high")
                if confidence not in ("high", "medium", "low"):
                    confidence = "high"
                
                valid_insights.append({
                    "type": insight["type"],
                    "quote": insight["quote"],
                    "quote_translated": insight.get("quote_translated"),
                    "analysis": insight["analysis"],
                    "dimension": insight.get("dimension"),
                    "confidence": confidence  # [NEW] ç½®ä¿¡åº¦
                })
            
            logger.debug(f"Extracted {len(valid_insights)} insights from review")
            return valid_insights
            
        except Exception as e:
            logger.warning(f"Insight extraction failed: {e}")
            return []
    
    def translate_review(
        self,
        title: Optional[str],
        body: str,
        extract_insights: bool = True
    ) -> Tuple[Optional[str], str, Sentiment, List[dict]]:
        """
        Translate a complete review (title and body), analyze sentiment, and extract insights.
        """
        # Translate title if present
        translated_title = None
        if title and title.strip():
            try:
                translated_title = self.translate_text(title)
            except Exception as e:
                logger.error(f"Failed to translate title: {e}")
                translated_title = None
        
        # Translate body (required)
        try:
            translated_body = self.translate_text(body)
        except Exception as e:
            logger.error(f"Failed to translate body: {e}")
            translated_body = ""
        
        # Analyze sentiment from original text (more accurate)
        sentiment = self.analyze_sentiment(body)
        
        # Extract insights
        insights = []
        if extract_insights and translated_body:
            try:
                insights = self.extract_insights(body, translated_body)
            except Exception as e:
                logger.warning(f"Failed to extract insights: {e}")
                insights = []
        
        return translated_title, translated_body, sentiment, insights
    
    def process_review_parallel(
        self, 
        title: Optional[str], 
        body: str,
        dimension_schema: List[dict] = None,  # [NEW] æ¥æ”¶ä¸“å±ç»´åº¦ï¼ˆç”¨äºæ´å¯Ÿæå–ï¼‰
        context_schema: dict = None           # [NEW] æ¥æ”¶ä¸“å±5Wæ ‡ç­¾ï¼ˆç”¨äºä¸»é¢˜æå–ï¼‰
    ) -> Optional[dict]:
        """
        [High Performance] Execute distinct prompts in parallel to maintain quality while boosting speed.
        
        This method orchestrates parallel execution of translation and analysis tasks:
        - Phase 1: Translate Title, Translate Body, Analyze Sentiment (Parallel - no dependencies)
        - Phase 2: Extract Insights, Extract Themes (Parallel - dependent on Phase 1 translation results)
        
        [UPDATED] Now supports dynamic schemas for personalized analysis:
        - dimension_schema: Product-specific dimensions for insight categorization
        - context_schema: Product-specific 5W labels for theme categorization
        
        Expected speedup: ~50% (from ~6s to ~3.5s per review) while maintaining 100% quality.
        
        Args:
            title: Review title (optional)
            body: Review body (required)
            dimension_schema: Optional list of dimension dicts for insight extraction
                             [{"name": "ç»´åº¦å", "description": "ç»´åº¦å®šä¹‰"}, ...]
            context_schema: Optional 5W label dict for theme extraction
                           {"who": [{"name": "...", "description": "..."}], ...}
            
        Returns:
            Dict with all analysis results, or None if processing fails
            
        Example:
            {
                "title_original": "Great product",
                "body_original": "Love it!",
                "title_translated": "å¾ˆæ£’çš„äº§å“",
                "body_translated": "å¤ªå–œæ¬¢äº†ï¼",
                "sentiment": "positive",
                "insights": [...],
                "themes": {...}
            }
        """
        if not self._check_client() or not body:
            return None

        result = {
            "title_original": title or None,
            "body_original": body,
            "title_translated": None,
            "body_translated": None,
            "sentiment": Sentiment.NEUTRAL.value,
            "insights": [],
            "themes": {}
        }

        # Create thread pool (max_workers=5 balances concurrency with API rate limits)
        with ThreadPoolExecutor(max_workers=5) as executor:
            # --- Phase 1: åŸºç¡€ä»»åŠ¡ (æ— ä¾èµ–ï¼Œå¯ä»¥å¹¶è¡Œ) ---
            future_title = executor.submit(self.translate_text, title) if title and title.strip() else None
            future_body = executor.submit(self.translate_text, body)
            future_sentiment = executor.submit(self.analyze_sentiment, body)

            # Wait for Phase 1 results (blocks until all complete)
            try:
                if future_title:
                    result["title_translated"] = future_title.result()
                
                # Critical: must get body translation before Phase 2 analysis
                result["body_translated"] = future_body.result()
                
                result["sentiment"] = future_sentiment.result().value
                
                logger.debug(f"Phase 1 completed: translation and sentiment analysis done")
            except Exception as e:
                logger.error(f"Phase 1 (translation) failed: {e}")
                # If body translation fails, cannot proceed to Phase 2
                if not result["body_translated"]:
                    logger.warning("Body translation failed, skipping Phase 2 analysis")
                    return result

            # --- Phase 2: é«˜çº§åˆ†æä»»åŠ¡ (ä¾èµ–ç¿»è¯‘ç»“æœï¼Œå¹¶è¡Œæ‰§è¡Œ) ---
            # Now we have both original_text and translated_text
            # We can launch insight extraction and theme extraction in parallel
            
            # [FIXED] å°†ä¸“å±ç»´åº¦ (dimension_schema) é€ä¼ ç»™æå–æ–¹æ³•
            future_insights = executor.submit(
                self.extract_insights, 
                result["body_original"], 
                result["body_translated"],
                dimension_schema  # <--- æ³¨å…¥ç»´åº¦è¡¨
            )
            
            # [FIXED] å°†ä¸“å±æ ‡ç­¾ (context_schema) é€ä¼ ç»™æå–æ–¹æ³•
            future_themes = executor.submit(
                self.extract_themes, 
                result["body_original"], 
                result["body_translated"],
                context_schema  # <--- æ³¨å…¥5Wæ ‡ç­¾åº“
            )

            # Wait for Phase 2 results (both can fail independently)
            try:
                result["insights"] = future_insights.result() or []
                logger.debug(f"Extracted {len(result['insights'])} insights")
            except Exception as e:
                logger.warning(f"Insight extraction failed: {e}")
                result["insights"] = []

            try:
                result["themes"] = future_themes.result() or {}
                logger.debug(f"Extracted {len(result['themes'])} theme categories")
            except Exception as e:
                logger.warning(f"Theme extraction failed: {e}")
                result["themes"] = {}

        logger.info(
            f"Parallel processing completed: "
            f"translation={bool(result['body_translated'])}, "
            f"sentiment={result['sentiment']}, "
            f"insights={len(result['insights'])}, "
            f"themes={len(result['themes'])}"
        )
        return result
    
    def batch_translate(
        self,
        reviews: list[dict]
    ) -> list[dict]:
        """
        Translate a batch of reviews.
        """
        results = []
        
        for review in reviews:
            title = review.get("title") or review.get("title_original")
            body = review.get("body") or review.get("body_original", "")
            
            try:
                translated_title, translated_body, sentiment, insights = self.translate_review(
                    title=title,
                    body=body,
                    extract_insights=True 
                )
                results.append({
                    "title_translated": translated_title,
                    "body_translated": translated_body,
                    "sentiment": sentiment.value,
                    "insights": insights,
                    "success": True
                })
            except Exception as e:
                logger.error(f"Batch translation failed for review: {e}")
                results.append({
                    "title_translated": None,
                    "body_translated": None,
                    "sentiment": Sentiment.NEUTRAL.value,
                    "insights": [],
                    "success": False,
                    "error": str(e)
                })
        
        return results
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def translate_bullet_points(self, bullet_points: List[str]) -> List[str]:
        """
        Translate product bullet points from English to Chinese.
        """
        if not self._check_client():
            raise RuntimeError("Translation service not configured")
        
        if not bullet_points or len(bullet_points) == 0:
            return []
        
        # Combine bullet points for batch translation
        combined_text = "\n".join(bullet_points)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": BULLET_POINTS_SYSTEM_PROMPT},
                    {"role": "user", "content": combined_text}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=60.0,
            )
            
            translated_text = response.choices[0].message.content.strip()
            
            # Split back into individual bullet points
            translated_points = [p.strip() for p in translated_text.split("\n") if p.strip()]
            
            # Ensure we have the same number of translations
            if len(translated_points) != len(bullet_points):
                logger.warning(
                    f"Bullet point count mismatch: original {len(bullet_points)}, "
                    f"translated {len(translated_points)}"
                )
                # Pad with empty strings or truncate
                while len(translated_points) < len(bullet_points):
                    translated_points.append("")
                translated_points = translated_points[:len(bullet_points)]
            
            logger.info(f"Translated {len(bullet_points)} bullet points")
            return translated_points
            
        except Exception as e:
            logger.error(f"Bullet points translation failed: {e}")
            raise
    
    def translate_product_title(self, title: str) -> str:
        """
        Translate product title from English to Chinese.
        """
        if not title or not title.strip():
            return ""
        
        try:
            return self.translate_text(title)
        except Exception as e:
            logger.error(f"Product title translation failed: {e}")
            raise

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def extract_themes(
        self, 
        original_text: str, 
        translated_text: str = None,  # [UPDATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å‚æ•°ä»…ä¸ºå‘åå…¼å®¹
        context_schema: dict = None
    ) -> dict:
        """
        Extract 5W theme content from a review using cross-language analysis.
        
        [UPDATED] è·¨è¯­è¨€5Wä¸»é¢˜æå– - ç›´æ¥ä»è‹±æ–‡åŸæ–‡æå–5Wè¦ç´ ï¼Œè¾“å‡ºä¸­æ–‡ç»“æœã€‚
        ä¸å†ä¾èµ–ç¿»è¯‘åçš„æ–‡æœ¬ï¼Œå®ç°ä¸ç¿»è¯‘ä»»åŠ¡çš„å®Œå…¨è§£è€¦ã€‚
        
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. å¼€æ”¾æå–æ¨¡å¼ï¼ˆæ—  context_schemaï¼‰ï¼šAI è‡ªç”±æå– 5W è¦ç´ 
        2. å¼ºåˆ¶å½’ç±»æ¨¡å¼ï¼ˆæœ‰ context_schemaï¼‰ï¼šAI åªèƒ½è¾“å‡ºæ ‡ç­¾åº“ä¸­å·²æœ‰çš„æ ‡ç­¾
        
        Args:
            original_text: è¯„è®ºåŸæ–‡ï¼ˆè‹±æ–‡ï¼‰
            translated_text: [DEPRECATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™ä»…ä¸ºå‘åå…¼å®¹
            context_schema: å¯é€‰çš„ 5W æ ‡ç­¾åº“ï¼Œæ ¼å¼ï¼š
                {
                    "who": [{"name": "è€å¹´äºº", "description": "..."}, ...],
                    "where": [...],
                    ...
                }
                
        Returns:
            æå–çš„ä¸»é¢˜å†…å®¹ï¼Œæ ¼å¼ï¼š
            - å¼€æ”¾æ¨¡å¼ï¼š{"who": [{"content": "ä¸­æ–‡å†…å®¹", "content_original": "English quote", ...}], ...}
            - å½’ç±»æ¨¡å¼ï¼š{"who": [{"content": "è€å¹´äºº", "quote": "English quote", ...}], ...}
        """
        if not self._check_client():
            return {}
        
        # [UPDATED] ä½¿ç”¨åŸæ–‡æ£€æŸ¥é•¿åº¦ï¼Œè·³è¿‡è¿‡çŸ­çš„è¯„è®º
        if not original_text or len(original_text.strip()) < 10:
            return {}
        
        # [UPDATED] Valid theme types for 5W model (2026-01-14: æ·»åŠ  buyer/user æ‹†åˆ†)
        valid_themes = {"buyer", "user", "who", "where", "when", "why", "what"}
        
        try:
            # æ ¹æ®æ˜¯å¦æœ‰æ ‡ç­¾åº“é€‰æ‹©ä¸åŒçš„ Prompt
            # [UPDATED] è·¨è¯­è¨€æ¨¡å¼ï¼šåªä¼ å…¥è‹±æ–‡åŸæ–‡ï¼ŒAI è¾“å‡ºä¸­æ–‡åˆ†æ
            if context_schema and any(context_schema.get(t) for t in valid_themes):
                # å¼ºåˆ¶å½’ç±»æ¨¡å¼ - ä½¿ç”¨æ ‡ç­¾åº“
                schema_lines = []
                for theme_type in valid_themes:
                    labels = context_schema.get(theme_type, [])
                    if labels:
                        label_names = [l["name"] for l in labels if isinstance(l, dict) and l.get("name")]
                        if label_names:
                            schema_lines.append(f"- **{theme_type}**: {', '.join(label_names)}")
                
                schema_str = "\n".join(schema_lines) if schema_lines else "ï¼ˆæ— æ ‡ç­¾åº“ï¼‰"
                
                prompt = THEME_EXTRACTION_PROMPT_WITH_SCHEMA.format(
                    original_text=original_text or "",
                    schema_str=schema_str
                )
                logger.debug(f"[è·¨è¯­è¨€5W] ä½¿ç”¨å¼ºåˆ¶å½’ç±»æ¨¡å¼ï¼Œæ ‡ç­¾åº“åŒ…å« {len(schema_lines)} ä¸ªç±»å‹")
            else:
                # å¼€æ”¾æå–æ¨¡å¼ - è‡ªç”±æå–
                prompt = THEME_EXTRACTION_PROMPT.format(
                    original_text=original_text or ""
                )
                logger.debug("[è·¨è¯­è¨€5W] ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=2000,
                timeout=60.0,
            )
            
            result = response.choices[0].message.content.strip()
            
            # [UPDATED] Use robust JSON parser
            themes = parse_json_safely(result)
            
            if not isinstance(themes, dict):
                logger.warning(f"Parsed themes is not a dict: {type(themes)}")
                return {}
            
            # æ ¹æ®æ¨¡å¼å¤„ç†è¿”å›ç»“æœ
            valid_result = {}
            
            if context_schema and any(context_schema.get(t) for t in valid_themes):
                # [UPDATED] å¼ºåˆ¶å½’ç±»æ¨¡å¼ - æ”¯æŒå¸¦è¯æ®çš„å¯è§£é‡Šå½’ç±»
                # æ–°æ ¼å¼: {"tag": "è€å¹´äºº", "quote": "...", "explanation": "..."}
                for theme_type in valid_themes:
                    items = themes.get(theme_type, [])
                    if not isinstance(items, list):
                        continue
                    
                    # è·å–è¯¥ç±»å‹å…è®¸çš„æ ‡ç­¾
                    allowed_labels = {
                        l["name"] for l in context_schema.get(theme_type, []) 
                        if isinstance(l, dict) and l.get("name")
                    }
                    
                    valid_items = []
                    for item in items:
                        if isinstance(item, dict):
                            # æ–°æ ¼å¼: å¸¦ tag/quote/quote_translated/confidence/explanation çš„å¯¹è±¡
                            tag = item.get("tag") or item.get("content")
                            if tag and tag.strip() in allowed_labels:
                                # [UPDATED 2026-01-15] æ·»åŠ  confidence å­—æ®µæ”¯æŒ
                                confidence = item.get("confidence", "high")
                                # éªŒè¯ confidence å€¼
                                if confidence not in ("high", "medium", "low"):
                                    confidence = "high"
                                valid_items.append({
                                    "content": tag.strip(),  # æ ‡å‡†æ ‡ç­¾å
                                    "content_original": item.get("quote") or item.get("content_original"),  # åŸæ–‡è¯æ®
                                    "quote_translated": item.get("quote_translated"),  # [NEW] ä¸­æ–‡ç¿»è¯‘è¯æ®
                                    "content_translated": item.get("content_translated"),  # ç¿»è¯‘ï¼ˆå¯é€‰ï¼Œå‘åå…¼å®¹ï¼‰
                                    "explanation": item.get("explanation"),  # å½’ç±»ç†ç”±
                                    "confidence": confidence  # [NEW] ç½®ä¿¡åº¦
                                })
                        elif isinstance(item, str):
                            # å…¼å®¹æ—§æ ¼å¼: çº¯å­—ç¬¦ä¸²
                            if item.strip() in allowed_labels:
                                valid_items.append({
                                    "content": item.strip(),
                                    "content_original": None,
                                    "content_translated": None,
                                    "explanation": f"å‘½ä¸­æ ‡ç­¾åº“: {item.strip()}",
                                    "confidence": "high"  # æ—§æ ¼å¼é»˜è®¤é«˜ç½®ä¿¡åº¦
                                })
                    
                    if valid_items:
                        valid_result[theme_type] = valid_items
                        logger.debug(f"  {theme_type}: {len(valid_items)} ä¸ªæ ‡ç­¾ (å¸¦è¯æ®)")
            else:
                # å¼€æ”¾æå–æ¨¡å¼ - è¿”å›çš„æ˜¯å®Œæ•´å†…å®¹é¡¹
                for theme_type, items in themes.items():
                    if theme_type not in valid_themes:
                        continue
                    if not isinstance(items, list):
                        continue
                    
                    # Validate each item
                    valid_items = []
                    for item in items:
                        if isinstance(item, dict) and "content" in item:
                            # Ensure content is a non-empty string
                            content = item.get("content", "").strip()
                            if content:
                                # [UPDATED 2026-01-15] æ·»åŠ  confidence å­—æ®µæ”¯æŒ
                                confidence = item.get("confidence", "high")
                                if confidence not in ("high", "medium", "low"):
                                    confidence = "high"
                                # Build valid item
                                valid_item = {
                                    "content": content,
                                    "content_original": item.get("content_original") or None,
                                    "content_translated": item.get("content_translated") or None,
                                    "explanation": item.get("explanation") or None,
                                    "confidence": confidence  # [NEW] ç½®ä¿¡åº¦
                                }
                                valid_items.append(valid_item)
                        elif isinstance(item, str):
                            # Backward compatibility: if item is a string, convert to new format
                            if item.strip():
                                valid_items.append({
                                    "content": item.strip(),
                                    "content_original": None,
                                    "content_translated": None,
                                    "explanation": None,
                                    "confidence": "high"  # æ—§æ ¼å¼é»˜è®¤é«˜ç½®ä¿¡åº¦
                                })
                    
                    if valid_items:
                        valid_result[theme_type] = valid_items
            
            logger.debug(f"Extracted themes: {list(valid_result.keys())}")
            return valid_result
            
        except Exception as e:
            logger.warning(f"Theme extraction failed: {e}")
            return {}
    
    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_project_level(
        self,
        reviews_text: str,
        products_data: str,
        product_count: int
    ) -> dict:
        """
        é¡¹ç›®çº§ç»´åº¦/æ ‡ç­¾å­¦ä¹ ä¸æ˜ å°„ - ç”¨äºå¸‚åœºæ´å¯ŸåŠŸèƒ½ã€‚
        
        ä¸€æ¬¡ AI è°ƒç”¨å®Œæˆï¼š
        1. å­¦ä¹ é¡¹ç›®çº§ç»Ÿä¸€ç»´åº¦ï¼ˆèšåˆè‡ªå¤šä¸ªäº§å“ï¼‰
        2. å­¦ä¹ é¡¹ç›®çº§ç»Ÿä¸€5Wæ ‡ç­¾ï¼ˆèšåˆè‡ªå¤šä¸ªäº§å“ï¼‰
        3. å»ºç«‹é¡¹ç›®çº§ -> äº§å“çº§çš„æ˜ å°„å…³ç³»
        
        Args:
            reviews_text: é‡‡æ ·çš„è¯„è®ºæ–‡æœ¬ï¼ˆå·²æ ¼å¼åŒ–ï¼‰
            products_data: æ‰€æœ‰äº§å“çš„ç»´åº¦å’Œæ ‡ç­¾æ•°æ®ï¼ˆå·²æ ¼å¼åŒ–ï¼‰
            product_count: äº§å“æ•°é‡
            
        Returns:
            å­¦ä¹ ç»“æœå­—å…¸ï¼Œæ ¼å¼ï¼š
            {
                "project_dimensions": {
                    "product": [{"name": "...", "description": "...", "mapped_from": [...]}],
                    "scenario": [...],
                    "emotion": [...]
                },
                "project_labels": {
                    "buyer": [{"name": "...", "description": "...", "mapped_from": [...]}],
                    "user": [...],
                    "where": [...],
                    "when": [...],
                    "why": [...],
                    "what": [...]
                }
            }
        """
        if not self._check_client():
            logger.error("Translation service not configured for project level learning")
            return {}
        
        if not reviews_text or not products_data:
            logger.warning("è¯„è®ºæ ·æœ¬æˆ–äº§å“æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œé¡¹ç›®çº§å­¦ä¹ ")
            return {}
        
        try:
            # æ„å»º Prompt
            prompt = PROJECT_LEVEL_LEARNING_PROMPT.format(
                reviews_text=reviews_text,
                products_data=products_data,
                product_count=product_count
            )
            
            logger.info(f"ğŸ“ å¼€å§‹é¡¹ç›®çº§å­¦ä¹ ï¼Œäº§å“æ•°é‡: {product_count}ï¼ŒPrompté•¿åº¦: {len(prompt)}")
            
            # è°ƒç”¨ AIï¼ˆä½¿ç”¨æ›´é•¿è¶…æ—¶ï¼‰
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¸‚åœºç ”ç©¶ä¸“å®¶ã€‚è¯·æŒ‰ç…§æŒ‡å®šçš„ JSON æ ¼å¼è¾“å‡ºç»“æœï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # è¾ƒä½çš„æ¸©åº¦ï¼Œç¡®ä¿è¾“å‡ºç¨³å®š
                max_tokens=4000,  # æ§åˆ¶è¾“å‡ºé•¿åº¦
                timeout=180.0,  # 3åˆ†é’Ÿè¶…æ—¶ï¼Œé¡¹ç›®çº§å­¦ä¹ éœ€è¦æ›´é•¿æ—¶é—´
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # æ¸…ç† markdown ä»£ç å—
            if result_text.startswith("```json"):
                result_text = result_text[7:]
            if result_text.startswith("```"):
                result_text = result_text[3:]
            if result_text.endswith("```"):
                result_text = result_text[:-3]
            result_text = result_text.strip()
            
            # è§£æ JSON
            parsed = json.loads(result_text)
            
            # éªŒè¯ç»“æ„
            valid_result = {
                "project_dimensions": {},
                "project_labels": {}
            }
            
            # éªŒè¯ç»´åº¦
            project_dimensions = parsed.get("project_dimensions", {})
            for dim_type in ["product", "scenario", "emotion"]:
                dims = project_dimensions.get(dim_type, [])
                valid_dims = []
                for dim in dims:
                    if isinstance(dim, dict) and dim.get("name"):
                        valid_dims.append({
                            "name": dim["name"].strip(),
                            "description": (dim.get("description") or "").strip(),
                            "mapped_from": dim.get("mapped_from", [])
                        })
                if valid_dims:
                    valid_result["project_dimensions"][dim_type] = valid_dims
            
            # éªŒè¯æ ‡ç­¾
            project_labels = parsed.get("project_labels", {})
            for label_type in ["buyer", "user", "where", "when", "why", "what"]:
                labels = project_labels.get(label_type, [])
                valid_labels = []
                for label in labels:
                    if isinstance(label, dict) and label.get("name"):
                        valid_labels.append({
                            "name": label["name"].strip(),
                            "description": (label.get("description") or "").strip(),
                            "mapped_from": label.get("mapped_from", [])
                        })
                if valid_labels:
                    valid_result["project_labels"][label_type] = valid_labels
            
            # ç»Ÿè®¡
            dim_count = sum(len(v) for v in valid_result["project_dimensions"].values())
            label_count = sum(len(v) for v in valid_result["project_labels"].values())
            logger.info(f"âœ… é¡¹ç›®çº§å­¦ä¹ å®Œæˆï¼š{dim_count} ä¸ªç»´åº¦ï¼Œ{label_count} ä¸ªæ ‡ç­¾")
            
            return valid_result
            
        except json.JSONDecodeError as e:
            logger.error(f"é¡¹ç›®çº§å­¦ä¹  JSON è§£æå¤±è´¥: {e}")
            logger.debug(f"åŸå§‹å“åº”: {result_text[:500]}...")
            return {}
        except Exception as e:
            logger.error(f"é¡¹ç›®çº§å­¦ä¹ å¤±è´¥: {e}")
            return {}


# Singleton instance
translation_service = TranslationService()
