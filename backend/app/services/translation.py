"""
Translation Service - Qwen API Integration for Amazon Review Translation
[Optimized Version]
Features:
1. Few-Shot System Prompt for natural, e-commerce style translation
2. CoT (Chain of Thought) Prompt for insight extraction
3. Robust JSON parsing to handle LLM output errors
"""
import logging
import json
import re
from typing import Optional, Tuple, List
from enum import Enum
from concurrent.futures import ThreadPoolExecutor

from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

from app.core.config import settings

logger = logging.getLogger(__name__)


class Sentiment(str, Enum):
    """Sentiment analysis result"""
    POSITIVE = "positive"
    NEUTRAL = "neutral"
    NEGATIVE = "negative"


# [UPDATED] System prompt with Few-Shot examples
TRANSLATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­ç¾æ–‡åŒ–å·®å¼‚çš„èµ„æ·±äºšé©¬é€Šè·¨å¢ƒç”µå•†ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ç›®æ ‡æ˜¯æä¾›"ä¿¡ã€è¾¾ã€é›…"çš„ä¸­æ–‡è¯‘æ–‡ã€‚

### æ ¸å¿ƒè§„åˆ™
1. **æ‹’ç»ç¿»è¯‘è…”**: ä¸è¦é€å­—ç¿»è¯‘ã€‚
   - âŒ é”™è¯¯: "è¿™ä¸ªäº§å“å·¥ä½œå¾—å¾ˆå¥½" (The product works great)
   - âœ… æ­£ç¡®: "è¿™ä¸œè¥¿å¤ªå¥½ç”¨äº†" / "æ•ˆæœç»äº†"
2. **æœ¯è¯­ç²¾å‡†**: 
   - "DOA (Dead on Arrival)" -> "åˆ°æ‰‹å³å"
   - "Return window" -> "é€€è´§æœŸ"
   - "Steal" -> "æ¡æ¼/è¶…å€¼"
3. **æƒ…æ„Ÿå¯¹é½**: 
   - 1æ˜Ÿè¯„è®ºé€šå¸¸å¸¦æœ‰æ„¤æ€’ï¼Œè¯‘æ–‡è¦ç”¨æ„Ÿå¹å·ã€åé—®å¥ä½“ç°æƒ…ç»ªã€‚
   - 5æ˜Ÿè¯„è®ºé€šå¸¸å¸¦æœ‰å…´å¥‹ï¼Œè¯‘æ–‡è¦ä½“ç°"ç§è‰"æ„Ÿã€‚

### å‚è€ƒèŒƒä¾‹ (Few-Shot)
Input: "Total lemon. Stopped working after 2 days. Don't waste your money."
Output: "ç®€ç›´æ˜¯ä¸ªæ¬¡å“ï¼ç”¨äº†ä¸¤å¤©å°±åäº†ã€‚åƒä¸‡åˆ«æµªè´¹é’±ï¼"

Input: "I was skeptical at first, but this thing is a game changer for my morning routine."
Output: "èµ·åˆæˆ‘è¿˜æœ‰ç‚¹æ€€ç–‘ï¼Œä½†è¿™ä¸œè¥¿å½»åº•æ”¹å˜äº†æˆ‘æ¯å¤©æ—©ä¸Šçš„ä¹ æƒ¯ï¼ŒçœŸé¦™ï¼"

Input: "It fits a bit snug, suggest sizing up."
Output: "ç©¿èµ·æ¥æœ‰ç‚¹ç´§ï¼Œå»ºè®®ä¹°å¤§ä¸€ç ã€‚"

Input: "The battery life is a joke."
Output: "ç”µæ± ç»­èˆªç®€ç›´å°±æ˜¯ä¸ªç¬‘è¯ã€‚"

è¯·ç¿»è¯‘ä»¥ä¸‹å†…å®¹ï¼Œç›´æ¥è¾“å‡ºè¯‘æ–‡ï¼š"""


SENTIMENT_ANALYSIS_PROMPT = """åˆ†æä»¥ä¸‹äºšé©¬é€Šå•†å“è¯„è®ºçš„æƒ…æ„Ÿå€¾å‘ã€‚

è¯„è®ºå†…å®¹ï¼š
{review_text}

è¯·åªè¿”å›ä»¥ä¸‹ä¸‰ä¸ªè¯ä¹‹ä¸€ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–å†…å®¹ï¼š
- positiveï¼ˆæ­£é¢ï¼šæ»¡æ„ã€æ¨èã€å–œæ¬¢ï¼‰
- neutralï¼ˆä¸­æ€§ï¼šå®¢è§‚æè¿°ã€ä¸€èˆ¬è¯„ä»·ï¼‰
- negativeï¼ˆè´Ÿé¢ï¼šä¸æ»¡ã€æ‰¹è¯„ã€é€€è´§ï¼‰

æƒ…æ„Ÿåˆ¤æ–­ï¼š"""


# System prompt for bullet points translation
BULLET_POINTS_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„äºšé©¬é€Šäº§å“æè¿°ç¿»è¯‘ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†äº§å“çš„äº”ç‚¹æè¿°ï¼ˆBullet Pointsï¼‰ä»è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ã€‚

ç¿»è¯‘åŸåˆ™ï¼š
1. **å‡†ç¡®ä¼ è¾¾å–ç‚¹**: ä¿ç•™åŸæ–‡çš„æ ¸å¿ƒå–ç‚¹å’Œäº§å“ä¼˜åŠ¿
2. **ç”µå•†æ–‡æ¡ˆé£æ ¼**: ä½¿ç”¨ç¬¦åˆä¸­å›½ç”µå•†çš„æ–‡æ¡ˆé£æ ¼ï¼Œæœ‰å¸å¼•åŠ›
3. **ç®€æ´æœ‰åŠ›**: æ¯æ¡æè¿°ç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹
4. **ä¸“ä¸šæœ¯è¯­**: æ­£ç¡®ç¿»è¯‘äº§å“ç›¸å…³çš„ä¸“ä¸šæœ¯è¯­
5. **ä¿æŒæ ¼å¼**: ä¿æŒåŸæ–‡çš„æ ¼å¼ç»“æ„ï¼Œæ¯æ¡æè¿°ç‹¬ç«‹æˆè¡Œ

è¾“å‡ºæ ¼å¼ï¼š
- ç›´æ¥è¾“å‡ºç¿»è¯‘åçš„ä¸­æ–‡äº”ç‚¹æè¿°
- æ¯æ¡æè¿°ç‹¬ç«‹æˆè¡Œ
- ä¸è¦æ·»åŠ åºå·æˆ–ç¬¦å·
- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Š"""


# [NEW] è·¨è¯­è¨€ç»´åº¦å‘ç° Prompt (è‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡ç»´åº¦è¾“å‡º)
DIMENSION_DISCOVERY_RAW_PROMPT = """You are a senior product manager and user research expert. 
Based on the following **English product information** and **English user review samples**, 
build a core evaluation dimension model for this product.

# Product Official Information (English)
- **Product Title**: {product_title}
- **Bullet Points**: 
{bullet_points}

# User Review Samples ({count} reviews, English Original)
{reviews_text}

# Task
Extract 5-8 core evaluation dimensions. **Output dimension names and descriptions in Chinese**.

# Requirements
1. **Combine official positioning with user perspective**: Dimension names should use official terms when possible (from bullet points), but must cover actual user feedback.
2. **Dimension names**: Use concise Chinese (e.g.: å¤–è§‚è®¾è®¡ã€ç»“æ„åšå·¥ã€ææ–™è´¨æ„Ÿã€åŠŸèƒ½è¡¨ç°ã€ç©æ³•å¤šæ ·æ€§ã€å®‰å…¨æ€§ã€æ€§ä»·æ¯”).
3. **Dimension definition**: One sentence describing what the dimension covers, to guide subsequent classification.
4. **Mutual exclusivity**: Dimensions should not overlap, clear boundaries.
5. **Coverage**: 
   - Must cover major pain points and benefits from reviews
   - Include dimensions emphasized in bullet points even if users are "silently satisfied"
6. **Quantity control**: Extract 5-8 most core dimensions, no more.

# Output Format (JSON Only, Chinese output)
{{
  "dimensions": [
    {{ "name": "ç»´åº¦åç§°(ä¸­æ–‡)", "description": "è¯¥ç»´åº¦çš„å…·ä½“å®šä¹‰(ä¸­æ–‡)" }},
    ...
  ]
}}

Output JSON only, no other text."""


# [NEW] è·¨è¯­è¨€5Wæ ‡ç­¾å‘ç° Prompt (è‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡æ ‡ç­¾è¾“å‡º)
# [UPDATED 2026-01-14] Who æ‹†åˆ†ä¸º Buyer + User
CONTEXT_DISCOVERY_RAW_PROMPT = """You are a senior marketing expert and user researcher.
Based on the following **English product information** and **English user review samples**,
build a "5W User & Market Model" for this product.

# Product Official Information (English)
- **Product Title**: {product_title}
- **Bullet Points**:
{bullet_points}

# User Review Samples ({count} buyer reviews, English Original)
{reviews_text}

# Task
Synthesize official positioning and user feedback to identify 6 categories of core elements.
Extract **Top 5-8 typical labels per category**. **Output all labels in Chinese**.

**CRITICAL: Distinguish Buyer vs User**
- **Buyer**: The person who PAYS for the product (e.g., mom buying for child, gift giver)
- **User**: The person who actually USES the product (e.g., child, gift recipient)
- If Buyer and User are the same person, put in **User** category only.

1. **Buyer (è´­ä¹°è€…)**: Who pays for the product?
   - Look for phrases: "I bought this for...", "Gift for...", "Ordered for my..."
   - Examples: å¦ˆå¦ˆã€é€ç¤¼è€…ã€ä¸ˆå¤«ã€ä¼ä¸šé‡‡è´­ã€å¥³å„¿(ä¸ºçˆ¶æ¯ä¹°)
   - Focus on the purchasing decision maker

2. **User (ä½¿ç”¨è€…)**: Who actually uses the product?
   - Look for phrases: "My son loves it", "Works great for my elderly mom", "I use it daily"
   - Examples: 3å²å¹¼å„¿ã€è€äººã€å‘˜å·¥ã€æ•æ„Ÿè‚Œäººç¾¤ã€æ¸¸æˆç©å®¶
   - If buyer = user (e.g., "I bought this for myself"), put here

3. **Where (åœ°ç‚¹)**: Where is it used?
   - Reference official positioning (e.g.: "for Home Office, Garage")
   - Physical spaces: å§å®¤ã€åŠå…¬å®¤ã€å¨æˆ¿ã€è½¦ä¸Šã€æˆ¿è½¦(RV)ã€æˆ·å¤–éœ²è¥

4. **When (æ—¶åˆ»)**: When is it used?
   - Time points: æ—©ä¸Šã€ç¡å‰ã€æ·±å¤œ
   - Triggers: åœç”µæ—¶ã€æ—…è¡Œæ—¶ã€è¿åŠ¨åã€èŠ‚å‡æ—¥

5. **Why (åŠ¨æœº)**: What triggers the purchase? (Purchase Driver)
   - Replacement: æ—§çš„åäº†ã€å‡çº§æ¢ä»£
   - Gift: ç”Ÿæ—¥ç¤¼ç‰©ã€åœ£è¯ç¤¼ç‰©ã€ä¹”è¿é€ç¤¼
   - External: è¢«ç§è‰ã€çœ‹äº†è¯„æµ‹ã€æœ‹å‹æ¨è

6. **What (ä»»åŠ¡)**: What specific task does the user try to accomplish? (Jobs to be Done)
   - Focus on core uses from official promotion
   - Note: Specific tasks, not product features
   - Examples: æ¸…ç†åœ°æ¯¯ä¸Šçš„å® ç‰©æ¯›ã€ç¼“è§£èƒŒç—›ã€å“„å­©å­ç¡è§‰ã€å»é™¤å¼‚å‘³

# Requirements
1. **Label names in concise Chinese** (2-6 characters ideal).
2. **Merge synonyms**: e.g., "å¦ˆå¦ˆ", "è€å¦ˆ", "æ¯äº²" should be unified.
3. **Consistent granularity**: Not too coarse ("å®¶äºº") or too fine ("62å²çš„ç‹¬å±…æ¯äº²").
4. **Official info priority**: Include labels from official positioning even if not mentioned in reviews.
5. **Provide brief description**: One sentence explaining the label for classification.

# Output Format (JSON Only, Chinese output)
{{
  "buyer": [
    {{ "name": "å®å¦ˆ", "description": "ä¸ºå­©å­è´­ä¹°äº§å“çš„æ¯äº²" }},
    {{ "name": "é€ç¤¼è€…", "description": "è´­ä¹°äº§å“ä½œä¸ºç¤¼ç‰©é€äººçš„ç”¨æˆ·" }}
  ],
  "user": [
    {{ "name": "3å²å¹¼å„¿", "description": "å®é™…ä½¿ç”¨äº§å“çš„ä½é¾„å„¿ç«¥" }},
    {{ "name": "è€å¹´äºº", "description": "å®é™…ä½¿ç”¨äº§å“çš„è€å¹´äººç¾¤" }}
  ],
  "where": [
    {{ "name": "å§å®¤", "description": "å§å®¤/ç¡çœ åœºæ™¯ä¸‹ä½¿ç”¨" }}
  ],
  "when": [
    {{ "name": "ç¡å‰", "description": "ç¡è§‰å‰ä½¿ç”¨" }}
  ],
  "why": [
    {{ "name": "æ›¿ä»£æ—§å“", "description": "åŸæœ‰äº§å“æŸåéœ€è¦æ›´æ¢" }}
  ],
  "what": [
    {{ "name": "æ¸…ç†å® ç‰©æ¯›", "description": "å®˜æ–¹æ ¸å¿ƒç”¨é€”ï¼šæ¸…ç†å®¶ä¸­çš„çŒ«æ¯›ç‹—æ¯›" }}
  ]
}}

Output JSON only, no other text."""


# [UPDATED] ç»´åº¦å‘ç° Prompt (åŠ å…¥äº§å“ä¿¡æ¯ç‰ˆ)
DIMENSION_DISCOVERY_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„äº§å“ç»ç†å’Œç”¨æˆ·ç ”ç©¶ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹**äº§å“å®˜æ–¹ä¿¡æ¯**å’Œ**ç”¨æˆ·è¯„è®ºæ ·æœ¬**ï¼Œæ„å»ºè¯¥äº§å“çš„æ ¸å¿ƒè¯„ä»·ç»´åº¦æ¨¡å‹ã€‚

# äº§å“å®˜æ–¹ä¿¡æ¯
- **äº§å“æ ‡é¢˜**: {product_title}
- **æ ¸å¿ƒå–ç‚¹ (Bullet Points)**: 
{bullet_points}

# ç”¨æˆ·è¯„è®ºæ ·æœ¬ ({count}æ¡)
{reviews_text}

# ä»»åŠ¡
æç‚¼å‡º 5-8 ä¸ªæ ¸å¿ƒè¯„ä»·ç»´åº¦ã€‚

# è¦æ±‚
1. **ç»“åˆå®˜æ–¹å®šä¹‰ä¸ç”¨æˆ·è§†è§’**: ç»´åº¦åç§°åº”å°½é‡ä½¿ç”¨å®˜æ–¹æœ¯è¯­ï¼ˆå¦‚æ¥è‡ªå–ç‚¹ï¼‰ï¼Œä½†å¿…é¡»èƒ½è¦†ç›–ç”¨æˆ·çš„å®é™…åé¦ˆã€‚
2. **ç»´åº¦åç§°**: ä½¿ç”¨ç®€ç»ƒçš„ä¸­æ–‡ï¼ˆå¦‚ï¼šå¤–è§‚è®¾è®¡ã€ç»“æ„åšå·¥ã€ææ–™è´¨æ„Ÿã€åŠŸèƒ½è¡¨ç°ã€å®‰å…¨æ€§ã€æ€§ä»·æ¯”ï¼‰ã€‚
3. **ç»´åº¦å®šä¹‰**: ç”¨ä¸€å¥è¯æè¿°è¯¥ç»´åº¦åŒ…å«çš„å…·ä½“å†…å®¹ï¼Œç”¨äºæŒ‡å¯¼åç»­åˆ†ç±»ã€‚
4. **äº’æ–¥æ€§**: ç»´åº¦ä¹‹é—´ä¸è¦é‡å ï¼Œå„ç»´åº¦å®šä¹‰è¾¹ç•Œæ¸…æ™°ã€‚
5. **è¦†ç›–ç‡**: 
   - å¿…é¡»è¦†ç›–è¯„è®ºä¸­å‡ºç°çš„ä¸»è¦ç—›ç‚¹å’Œçˆ½ç‚¹
   - ä¹Ÿè¦åŒ…å«äº§å“å–ç‚¹ä¸­å¼ºè°ƒä½†ç”¨æˆ·å¯èƒ½"æ²‰é»˜æ»¡æ„"çš„ç»´åº¦ï¼ˆä¾¿äºåç»­ç›‘æ§ï¼‰
6. **æ•°é‡æ§åˆ¶**: æç‚¼ 5-8 ä¸ªæœ€æ ¸å¿ƒçš„ç»´åº¦ï¼Œä¸è¦è¿‡å¤šã€‚

# è¾“å‡ºæ ¼å¼ (JSON Only)
{{
  "dimensions": [
    {{ "name": "ç»´åº¦åç§°", "description": "è¯¥ç»´åº¦çš„å…·ä½“å®šä¹‰ï¼Œæè¿°å®ƒåŒ…å«å“ªäº›å†…å®¹" }},
    ...
  ]
}}

è¯·åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šæ–‡å­—ã€‚"""


# [UPDATED] è·¨è¯­è¨€æ´å¯Ÿæå– Prompt - 5ç±»æ´å¯Ÿç³»ç»Ÿ (è‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡è¾“å‡º)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µ
INSIGHT_EXTRACTION_PROMPT_DYNAMIC = """# Role
Amazon Review Analyst (Cross-language Expert) with STRICT evidence standards

# Task
Analyze the following **English review** and extract key insights. Categorize each insight into the specified product dimensions.

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: All `analysis` and `quote_translated` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **Quote**: Keep the `quote` field in **Original English** (for evidence tracing).

# Input (English Review)
{original_text}

# Dimension Schema (Must Use)
Only categorize insights into the following dimensions. If content doesn't fit any dimension, use "å…¶ä»–".
{schema_str}

# âš ï¸ CONFIDENCE LEVELS (Must include in output)
- **high**: Insight is explicitly stated in the review with clear evidence
  - âœ… "The battery lasts only 2 hours" â†’ weakness about ç»­èˆª (high)
  - âœ… "I love the compact design" â†’ strength about å¤–è§‚è®¾è®¡ (high)
  
- **medium**: Insight can be reasonably inferred from context
  - âœ… "Works as expected" â†’ general satisfaction (medium)
  
- **low**: Use for fallback when review is too vague
  - âš ï¸ Only use for very short reviews like "Good" or "OK"
  - For specific claims, always use high or medium

# 5 Insight Types (CRITICAL - Distinguish Carefully)
Break down the review into specific insights and categorize into one of these 5 types:

1. **strength (Product Advantage)**: Features or experiences explicitly praised by the user.
   - Example insights: "å¸åŠ›éå¸¸å¼ºåŠ²", "ç»­èˆªè¶…å‡ºé¢„æœŸ", "å¤–è§‚ç²¾ç¾"
   - Use: Extract for Listing selling points

2. **weakness (Pain Point)**: Defects, bugs, or complaints mentioned by the user.
   - Example insights: "ç”µæ± ç»­èˆªå¤ªçŸ­", "å¡‘æ–™æ„Ÿå¼º", "å™ªéŸ³è¿‡å¤§"
   - Use: Product improvement basis

3. **suggestion (Feature Request)**: Improvement suggestions or desired features.
   - Example insights: "å¦‚æœèƒ½åŠ LEDç¯å°±å¥½äº†", "å¸Œæœ›å¢åŠ å®šæ—¶åŠŸèƒ½"
   - Use: Direct PM requirements

4. **scenario (Usage Scenario)**: **Specific** usage processes or behavioral stories.
   - Example insights: "å°è¯•æ¸…ç†è½¦åº“é”¯æœ«æ—¶å¸å˜´è¢«å µ", "æ™šä¸Šå–‚å¥¶æ—¶ä¸€é”®å¼€å¯å¾ˆæ–¹ä¾¿"
   - âš ï¸ Important: Different from 5W tags!
     - 5W tags are **simple nouns**: "å§å®¤", "å¨æˆ¿"
     - Scenario is **dynamic behavior**: "åœ¨å¨æˆ¿åšé¥­æ—¶æ¸…ç†é¢ç²‰"
   - If it's just a simple place/time noun, do NOT extract as scenario

5. **emotion (Emotional Insight)**: Strong emotions expressed (anger/surprise/disappointment/gratitude).
   - Example insights: "å¯¹æ­¤æå…¶å¤±æœ›", "è¿™æ˜¯æˆ‘ä¹°è¿‡æœ€å¥½çš„ä¸œè¥¿", "åæ‚”æ²¡æ—©ç‚¹ä¹°"
   - Use: Operations team sentiment alerts

# Output Format (JSON Array)
[
  {{
    "type": "weakness", 
    "dimension": "é€‰æ‹©ä¸Šè¿°ç»´åº¦ä¹‹ä¸€", 
    "quote": "Original English quote from the review",
    "quote_translated": "å¼•ç”¨çš„ä¸­æ–‡ç¿»è¯‘",
    "analysis": "ç®€è¦åˆ†æï¼ˆä¸­æ–‡ï¼‰",
    "sentiment": "positive/negative/neutral",
    "confidence": "high"
  }}
]

# Critical Rules
1. **æ¯æ¡è¯„è®ºå¿…é¡»è‡³å°‘æå–1ä¸ªæ´å¯Ÿ**, even for very short reviews.
2. **dimension must be from the schema**, do not invent new dimensions.
3. For short positive reviews (e.g., "Amazing!"), extract as emotion type with dimension "æ•´ä½“æ»¡æ„åº¦".
4. For short negative reviews (e.g., "Terrible"), extract as weakness type with dimension "æ•´ä½“æ»¡æ„åº¦".
5. Be specific: not "è´¨é‡ä¸å¥½" but "å¡‘æ–™æ„Ÿå¼º" or "æŒ‰é”®æ¾åŠ¨".
6. NEVER return empty array []. At least 1 insight required.
7. Scenario must be **dynamic behavior**, not simple place/time nouns.
8. **All Chinese output must be natural, fluent Simplified Chinese.**
9. **Always include confidence field** (high/medium/low) for each insight.
"""


# [UPDATED] è·¨è¯­è¨€æ´å¯Ÿæå– Prompt - 5ç±»æ´å¯Ÿç³»ç»Ÿ (æ— ç»´åº¦ Schema ç‰ˆæœ¬ï¼Œè‹±æ–‡è¾“å…¥ â†’ ä¸­æ–‡è¾“å‡º)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µ
INSIGHT_EXTRACTION_PROMPT = """# Role
Amazon Review Analyst (Cross-language Expert) with STRICT evidence standards

# Task
Analyze the following **English review** and extract key user insights. **At least 1 insight must be extracted per review.**

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: All `analysis` and `quote_translated` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **Quote**: Keep the `quote` field in **Original English** (for evidence tracing).

# Input (English Review)
{original_text}

# âš ï¸ CONFIDENCE LEVELS (Must include in output)
- **high**: Insight is explicitly stated with clear evidence
  - âœ… "Battery dies after 2 hours" â†’ weakness (high)
  
- **medium**: Reasonably inferred from context
  - âœ… "Works as expected" â†’ satisfaction (medium)
  
- **low**: Fallback for very vague reviews
  - âš ï¸ Only for "Good", "OK", "Nice" with no details

# 5 Insight Types (CRITICAL - Distinguish Carefully)
Break down the review into specific insights and categorize into one of these 5 types:

1. **strength (Product Advantage)**: Features or experiences explicitly praised.
   - Example insights: "å¸åŠ›å¼ºåŠ²", "ç»­èˆªè¶…å‡ºé¢„æœŸ"
   - Use: Listing selling points

2. **weakness (Pain Point)**: Defects, bugs, or complaints.
   - Example insights: "ç”µæ± ç»­èˆªå¤ªçŸ­", "å¡‘æ–™æ„Ÿå¼º"
   - Use: Product improvement

3. **suggestion (Feature Request)**: Improvement suggestions.
   - Example insights: "å¦‚æœèƒ½åŠ LEDç¯å°±å¥½äº†"
   - Use: PM requirements

4. **scenario (Usage Scenario)**: **Specific** usage processes.
   - Example insights: "æ¸…ç†è½¦åº“é”¯æœ«æ—¶å¸å˜´è¢«å µ"
   - âš ï¸ Must be dynamic behavior, not simple nouns!

5. **emotion (Emotional Insight)**: Strong emotions expressed.
   - Example insights: "æå…¶å¤±æœ›", "è¿™æ˜¯ä¹°è¿‡æœ€å¥½çš„ä¸œè¥¿"
   - Use: Sentiment alerts

# Dimension Detection
Auto-detect dimension based on review content (e.g.: æ•´ä½“æ»¡æ„åº¦, äº§å“è´¨é‡, ä½¿ç”¨ä½“éªŒ, ç‰©æµæœåŠ¡, æ€§ä»·æ¯”).

# Output Format (JSON Array)
[
  {{
    "type": "strength", 
    "dimension": "æ•´ä½“æ»¡æ„åº¦",
    "quote": "Amazing toy", 
    "quote_translated": "å¤ªæ£’çš„ç©å…·äº†",
    "analysis": "ç”¨æˆ·å¯¹äº§å“é«˜åº¦è®¤å¯ï¼Œè¡¨è¾¾å¼ºçƒˆæ­£é¢æƒ…æ„Ÿ",
    "sentiment": "positive",
    "confidence": "high"
  }},
  {{
    "type": "emotion",
    "dimension": "è´­ä¹°ä½“éªŒ",
    "quote": "Great buy",
    "quote_translated": "ä¹°å¾—å¤ªå€¼äº†",
    "analysis": "ç”¨æˆ·è®¤ä¸ºè¿™æ¬¡è´­ä¹°ç‰©è¶…æ‰€å€¼",
    "sentiment": "positive",
    "confidence": "high"
  }}
]

# Critical Rules
1. **æ¯æ¡è¯„è®ºå¿…é¡»è‡³å°‘æå–1ä¸ªæ´å¯Ÿ**, even for very short reviews.
2. For short positive reviews (e.g., "Amazing!", "Love it!"), extract as emotion type with dimension "æ•´ä½“æ»¡æ„åº¦".
3. For short negative reviews (e.g., "Terrible"), extract as weakness type with dimension "æ•´ä½“æ»¡æ„åº¦".
4. Be specific: not "è´¨é‡ä¸å¥½" but "å¡‘æ–™æ„Ÿå¼º" or "æŒ‰é”®æ¾åŠ¨".
5. NEVER return empty array []. At least 1 insight required.
6. Scenario must be **dynamic behavior**, not simple place/time nouns.
7. **All Chinese output must be natural, fluent Simplified Chinese.**
8. **Always include confidence field** (high/medium/low) for each insight.
"""


class InsightType(str, Enum):
    """Insight type enumeration"""
    STRENGTH = "strength"
    WEAKNESS = "weakness"
    SUGGESTION = "suggestion"
    SCENARIO = "scenario"
    EMOTION = "emotion"





# [UPDATED 2026-01-14] è·¨è¯­è¨€5W Model Extraction Prompt (Who æ‹†åˆ†ä¸º Buyer + User)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µå’Œä¸¥æ ¼è¯æ®è¦æ±‚
THEME_EXTRACTION_PROMPT = """You are a professional marketing analyst with STRICT evidence standards.
Analyze the following **English review** using the "5W Analysis Framework" and extract key market elements.

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: All `content`, `content_translated`, and `explanation` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **content_original**: Keep in **Original English** (for evidence tracing).

# Input (English Review)
{original_text}

# âš ï¸ EVIDENCE STANDARDS (MOST CRITICAL)

**The "Courage to Say Nothing" Rule:**
It is FAR BETTER to return an empty array than to make a weak or speculative extraction!

## Confidence Levels (MUST include in output)
- **high**: Reviewer EXPLICITLY states the information
  - âœ… "I bought this for my mom" â†’ buyer with confidence: "high"
  - âœ… "I'm a heavy sleeper" â†’ user with confidence: "high"
  
- **medium**: Information can be REASONABLY INFERRED from clear context
  - âœ… "Works great for my morning routine" â†’ when: "æ—©æ™¨" with confidence: "medium"
  
- **low**: DO NOT OUTPUT! If evidence is weak, do not extract at all.
  - âŒ Product is an alarm clock â†’ assuming user is "æ·±ç¡äººç¾¤" (WRONG!)
  - âŒ General praise like "Great product!" â†’ extracting any 5W (WRONG!)

## When NOT to Extract (Return Empty Array Instead)
1. Review only talks about product quality (e.g., "Great product!", "Love it!")
2. No direct evidence in the review text for that category
3. Extraction would be based on product type assumptions, not review content
4. The connection requires more than one logical leap

**Remember: An empty array [] is a VALID and often CORRECT answer!**

# Extract the following 6 core elements (leave empty array if not mentioned):

**CRITICAL: Distinguish Buyer vs User**
- **Buyer**: The person who PAYS (e.g., "I bought this for my son" â†’ Buyer is "å¦ˆå¦ˆ/çˆ¸çˆ¸")
- **User**: The person who USES (e.g., "my son loves it" â†’ User is "å­©å­")
- If same person, put in **User** only

1. **buyer (Purchaser/Gift Giver)**: 
   - Definition: Who is paying for the product?
   - Look for: "I bought this for...", "Gift for...", "Ordered for my..."
   - Output examples (Chinese): å¦ˆå¦ˆ, é€ç¤¼è€…, ä¸ˆå¤«, ä¼ä¸šé‡‡è´­

2. **user (Actual User)**: 
   - Definition: Who is actually using the product?
   - Look for: "My son uses it", "Works great for my elderly mom", "I use it daily"
   - Output examples (Chinese): 3å²å¹¼å„¿, è€å¹´äºº, å‘˜å·¥, æ¸¸æˆç©å®¶

3. **where (Location)**: 
   - Definition: In what physical space is it used?
   - Output examples (Chinese): å§å®¤, åŠå…¬å®¤, æˆ¿è½¦, è½¦åº“, æˆ·å¤–éœ²è¥

4. **when (Timing)**: 
   - Definition: At what time or specific situation is it used?
   - Output examples (Chinese): ç¡å‰, åœç”µæ—¶, åœ£è¯èŠ‚æ—©æ™¨, è¿åŠ¨å

5. **why (Purchase Motivation)**: 
   - Definition: What triggered the purchase decision? (Purchase Driver)
   - Output examples (Chinese): æ—§çš„åäº†, ä½œä¸ºç”Ÿæ—¥ç¤¼ç‰©, ä¸ºäº†çœé’±, æ¬æ–°å®¶

6. **what (Jobs to be Done)**: 
   - Definition: What specific task is the user trying to accomplish?
   - Note: Focus on tasks, not product features.
   - Output examples (Chinese): æ¸…ç†çŒ«æ¯›, ç¼“è§£èƒŒç—›, å“„å­©å­ç¡è§‰

# Output Format (JSON)
{{
  "buyer": [
    {{
      "content": "å®å¦ˆ",
      "content_original": "I bought this for my son",
      "content_translated": "æˆ‘ç»™å„¿å­ä¹°çš„",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®è¯´'ç»™å„¿å­ä¹°çš„'ï¼Œè¯æ˜è´­ä¹°è€…æ˜¯æ¯äº²"
    }}
  ],
  "user": [
    {{
      "content": "3å²ç”·ç«¥",
      "content_original": "my 3 year old loves it",
      "content_translated": "æˆ‘3å²çš„å­©å­å¾ˆå–œæ¬¢",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®æåˆ°'3å²çš„å­©å­'æ˜¯ä½¿ç”¨è€…"
    }}
  ],
  "what": [],
  "why": [],
  "where": [],
  "when": []
}}

# Example of CORRECT Behavior for Short Reviews
Input: "Amazing alarm clock! Works perfectly!"
Output: {{ "buyer": [], "user": [], "where": [], "when": [], "why": [], "what": [] }}
Reason: Review only praises product quality, no 5W elements mentioned.
"""


# [UPDATED 2026-01-14] 5W æ ‡ç­¾å‘ç° Prompt (å­¦ä¹ é˜¶æ®µ - Who æ‹†åˆ†ä¸º Buyer + User)
CONTEXT_DISCOVERY_PROMPT = """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¸‚åœºè¥é”€ä¸“å®¶å’Œç”¨æˆ·ç ”ç©¶å‘˜ã€‚è¯·åŸºäºä»¥ä¸‹**äº§å“å®˜æ–¹ä¿¡æ¯**å’Œ**ç”¨æˆ·è¯„è®ºæ ·æœ¬**ï¼Œæ„å»ºè¯¥äº§å“çš„"5W ç”¨æˆ·ä¸å¸‚åœºæ¨¡å‹"ã€‚

# äº§å“å®˜æ–¹ä¿¡æ¯ï¼ˆå–å®¶å®šä¹‰ï¼‰
- **äº§å“æ ‡é¢˜**: {product_title}
- **æ ¸å¿ƒå–ç‚¹ (Bullet Points)**:
{bullet_points}

# ç”¨æˆ·è¯„è®ºæ ·æœ¬ï¼ˆ{count}æ¡ä¹°å®¶åé¦ˆï¼‰
{reviews_text}

# ä»»åŠ¡
è¯·ç»¼åˆå®˜æ–¹å®šä½ä¸ç”¨æˆ·åé¦ˆï¼Œè¯†åˆ«å¹¶å½’çº³å‡ºä»¥ä¸‹ **6 ç±»æ ¸å¿ƒè¦ç´ **ï¼Œæ¯ç±»æå– **Top 5-8 ä¸ªå…¸å‹æ ‡ç­¾**ï¼š

**é‡è¦ï¼šå¿…é¡»åŒºåˆ†è´­ä¹°è€…å’Œä½¿ç”¨è€…**
- **è´­ä¹°è€…(Buyer)**: ä»˜é’±ä¹°äº§å“çš„äººï¼ˆå¦‚ï¼šå¦ˆå¦ˆç»™å­©å­ä¹°ã€é€ç¤¼è€…ï¼‰
- **ä½¿ç”¨è€…(User)**: å®é™…ä½¿ç”¨äº§å“çš„äººï¼ˆå¦‚ï¼šå­©å­ã€æ”¶ç¤¼è€…ã€è€äººï¼‰
- å¦‚æœè´­ä¹°è€…å’Œä½¿ç”¨è€…æ˜¯åŒä¸€äººï¼Œåªå¡«å…¥**ä½¿ç”¨è€…**ç±»åˆ«

1. **Buyer (è´­ä¹°è€…)**: è°æ˜¯è´­ä¹°å†³ç­–è€…ï¼Ÿè°ä»˜é’±ï¼Ÿ
   - å…³æ³¨è¡¨è¿°å¦‚ï¼š"I bought this for..."ã€"Gift for..."ã€"Ordered for my..."
   - ç¤ºä¾‹æ ‡ç­¾ï¼šå¦ˆå¦ˆã€é€ç¤¼è€…ã€ä¸ˆå¤«ã€ä¼ä¸šé‡‡è´­ã€å¥³å„¿(ä¸ºçˆ¶æ¯ä¹°)
   - é‡ç‚¹è¯†åˆ«è´­ä¹°å†³ç­–è€…çš„èº«ä»½

2. **User (ä½¿ç”¨è€…)**: è°å®é™…ä½¿ç”¨äº§å“ï¼Ÿ
   - å…³æ³¨è¡¨è¿°å¦‚ï¼š"My son loves it"ã€"Works great for my elderly mom"ã€"I use it daily"
   - ç¤ºä¾‹æ ‡ç­¾ï¼š3å²å¹¼å„¿ã€è€å¹´äººã€å‘˜å·¥ã€æ•æ„Ÿè‚Œäººç¾¤ã€æ¸¸æˆç©å®¶
   - å¦‚æœä¹°å®¶è‡ªç”¨ï¼ˆå¦‚"I bought this for myself"ï¼‰ï¼Œæ”¾å…¥æ­¤ç±»åˆ«

3. **Where (åœ°ç‚¹)**: åœ¨å“ªé‡Œä½¿ç”¨ï¼Ÿ
   - ä¼˜å…ˆå‚è€ƒå®˜æ–¹å®šä½ï¼ˆå¦‚: "for Home Office, Garage"ï¼‰
   - ç»“åˆç”¨æˆ·å®é™…ä½¿ç”¨åœºæ™¯
   - ç‰©ç†ç©ºé—´ï¼Œå¦‚: å§å®¤ã€åŠå…¬å®¤ã€å¨æˆ¿ã€è½¦ä¸Šã€æˆ¿è½¦(RV)ã€æˆ·å¤–éœ²è¥

4. **When (æ—¶åˆ»)**: ä»€ä¹ˆæ—¶å€™ä½¿ç”¨ï¼Ÿ
   - æ—¶é—´ç‚¹ï¼Œå¦‚: æ—©ä¸Šã€ç¡å‰ã€æ·±å¤œ
   - è§¦å‘æ—¶æœºï¼Œå¦‚: åœç”µæ—¶ã€æ—…è¡Œæ—¶ã€è¿åŠ¨åã€èŠ‚å‡æ—¥

5. **Why (åŠ¨æœº)**: è´­ä¹°çš„è§¦å‘ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ(Purchase Driver)
   - æ›¿ä»£éœ€æ±‚ï¼Œå¦‚: æ—§çš„åäº†ã€å‡çº§æ¢ä»£
   - é€ç¤¼éœ€æ±‚ï¼Œå¦‚: ç”Ÿæ—¥ç¤¼ç‰©ã€åœ£è¯ç¤¼ç‰©ã€ä¹”è¿é€ç¤¼
   - å¤–éƒ¨é©±åŠ¨ï¼Œå¦‚: è¢«ç§è‰ã€çœ‹äº†è¯„æµ‹ã€æœ‹å‹æ¨è

6. **What (ä»»åŠ¡)**: ç”¨æˆ·è¯•å›¾ç”¨å®ƒå®Œæˆä»€ä¹ˆå…·ä½“ä»»åŠ¡ï¼Ÿ(Jobs to be Done)
   - **é‡ç‚¹å…³æ³¨å®˜æ–¹å®£ä¼ çš„æ ¸å¿ƒç”¨é€”**ï¼ˆå¦‚: "remove pet hair", "eliminate odors"ï¼‰
   - æ³¨æ„: æ˜¯å…·ä½“ä»»åŠ¡ï¼Œä¸æ˜¯äº§å“åŠŸèƒ½
   - å¦‚: æ¸…ç†åœ°æ¯¯ä¸Šçš„å® ç‰©æ¯›ã€ç¼“è§£èƒŒç—›ã€å“„å­©å­ç¡è§‰ã€å»é™¤å¼‚å‘³

# è¦æ±‚
1. **æ ‡ç­¾åç§°ä½¿ç”¨ç®€ç»ƒçš„ä¸­æ–‡**ï¼ˆ2-6ä¸ªå­—æœ€ä½³ï¼‰ã€‚
2. **åˆå¹¶åŒä¹‰è¯**ï¼šå¦‚"å¦ˆå¦ˆ"ã€"è€å¦ˆ"ã€"æ¯äº²"åº”ç»Ÿä¸€ä¸ºä¸€ä¸ªæ ‡ç­¾ã€‚
3. **ä¿æŒé¢—ç²’åº¦ä¸€è‡´**ï¼šä¸è¦å¤ªç²—ï¼ˆå¦‚"å®¶äºº"ï¼‰ä¹Ÿä¸è¦å¤ªç»†ï¼ˆå¦‚"62å²çš„ç‹¬å±…æ¯äº²"ï¼‰ã€‚
4. **å®˜æ–¹ä¿¡æ¯ä¼˜å…ˆ**ï¼šå¦‚æœå®˜æ–¹æ˜ç¡®æåˆ°çš„äººç¾¤/åœºæ™¯/ç”¨é€”ï¼Œå³ä½¿è¯„è®ºä¸­æ²¡æåŠä¹Ÿåº”åˆ—å…¥ã€‚
5. **æä¾›ç®€çŸ­æè¿°**ï¼šç”¨ä¸€å¥è¯è§£é‡Šè¯¥æ ‡ç­¾çš„å«ä¹‰ï¼Œä¾¿äºåç»­å½’ç±»åˆ¤æ–­ã€‚

# è¾“å‡ºæ ¼å¼ (JSON Only)
{{
  "buyer": [
    {{ "name": "å®å¦ˆ", "description": "ä¸ºå­©å­è´­ä¹°äº§å“çš„æ¯äº²" }},
    {{ "name": "é€ç¤¼è€…", "description": "è´­ä¹°äº§å“ä½œä¸ºç¤¼ç‰©é€äººçš„ç”¨æˆ·" }}
  ],
  "user": [
    {{ "name": "3å²å¹¼å„¿", "description": "å®é™…ä½¿ç”¨äº§å“çš„ä½é¾„å„¿ç«¥" }},
    {{ "name": "è€å¹´äºº", "description": "å®é™…ä½¿ç”¨äº§å“çš„è€å¹´äººç¾¤" }}
  ],
  "where": [
    {{ "name": "å§å®¤", "description": "å§å®¤/ç¡çœ åœºæ™¯ä¸‹ä½¿ç”¨" }},
    {{ "name": "è½¦åº“", "description": "å®˜æ–¹æ¨èçš„ä½¿ç”¨åœºæ™¯ä¹‹ä¸€" }}
  ],
  "when": [
    {{ "name": "ç¡å‰", "description": "ç¡è§‰å‰ä½¿ç”¨" }}
  ],
  "why": [
    {{ "name": "æ›¿ä»£æ—§å“", "description": "åŸæœ‰äº§å“æŸåéœ€è¦æ›´æ¢" }},
    {{ "name": "é€ç¤¼", "description": "ä½œä¸ºç¤¼ç‰©é€ç»™ä»–äºº" }}
  ],
  "what": [
    {{ "name": "æ¸…ç†å® ç‰©æ¯›", "description": "å®˜æ–¹æ ¸å¿ƒç”¨é€”ï¼šæ¸…ç†å®¶ä¸­çš„çŒ«æ¯›ç‹—æ¯›" }},
    {{ "name": "å»é™¤å¼‚å‘³", "description": "å®˜æ–¹æ ¸å¿ƒç”¨é€”ï¼šæ¶ˆé™¤å® ç‰©æˆ–å…¶ä»–å¼‚å‘³" }}
  ]
}}

è¯·åªè¾“å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–è§£é‡Šæ–‡å­—ã€‚"""


# [UPDATED 2026-01-14] è·¨è¯­è¨€5W å®šå‘æå– Prompt (æ‰§è¡Œé˜¶æ®µ - Who æ‹†åˆ†ä¸º Buyer + User)
# [UPDATED 2026-01-15] æ·»åŠ ç½®ä¿¡åº¦å­—æ®µå’Œä¸¥æ ¼è¯æ®è¦æ±‚
THEME_EXTRACTION_PROMPT_WITH_SCHEMA = """You are a professional marketing analyst with STRICT evidence standards.
Analyze the following **English review** and identify the 5W elements it contains.

**CRITICAL Language Rules:**
- **Input**: The review text is in **English**.
- **Output**: `quote_translated` and `explanation` fields must be in **Simplified Chinese (ç®€ä½“ä¸­æ–‡)**.
- **quote**: Keep in **Original English** (for evidence tracing).
- **tag**: Must match exactly with the provided Schema labels (Chinese).

# Input (English Review)
{original_text}

# Label Schema (MUST use these labels only)
{schema_str}

# âš ï¸ EVIDENCE STANDARDS (MOST CRITICAL)

**The "Courage to Say Nothing" Rule:**
It is FAR BETTER to return an empty array than to make a weak or speculative categorization!

## Confidence Levels (MUST include in output)
- **high**: Reviewer EXPLICITLY states the information in the review text
  - âœ… "I bought this for my mom" â†’ buyer: å­å¥³ (high)
  - âœ… "I'm a heavy sleeper" â†’ user: æ·±ç¡äººç¾¤ (high)
  
- **medium**: Information can be REASONABLY INFERRED from clear context
  - âœ… "Works great for my morning routine" â†’ when: æ—©æ™¨ (medium)
  - âœ… "Perfect for the nursery" â†’ where: å„¿ç«¥æˆ¿ (medium)
  
- **low**: DO NOT OUTPUT! If evidence is weak, do not categorize at all.
  - âŒ Product is an alarm clock â†’ assuming user is "æ·±ç¡äººç¾¤" (WRONG!)
  - âŒ Product is a toy â†’ assuming buyer is "å®¶é•¿" without evidence (WRONG!)

## When NOT to Categorize (Return Empty Array Instead)
1. Review only talks about product quality (e.g., "Great product!", "Love it!")
2. No direct evidence in the review text for that category
3. Categorization would be based on product type assumptions, not review content
4. You're relying on stereotypes or common associations
5. The connection requires more than one logical leap

**Remember: An empty array [] is a VALID and often CORRECT answer!**

# Task Rules
1. **Evidence-First**: Only categorize when there is CLEAR evidence in the review text
2. **Forced Labels**: The `tag` field must exactly match a label from the schema
3. **Quote Required**: Must include the exact English quote that supports categorization
4. **Confidence Required**: Must include confidence level (high/medium only, never low)
5. **Explanation Required**: Explain WHY this quote supports this categorization

**CRITICAL: Distinguish Buyer vs User**
- **buyer**: The person who PAYS/purchases (e.g., "I bought this for my son" â†’ Buyer is the parent)
- **user**: The person who USES the product (e.g., "my son loves it" â†’ User is the child)
- If same person, put in **user** only
- If unclear who pays vs uses, put in **user** only

# Output Format (JSON Only)
{{
  "buyer": [
    {{
      "tag": "å®å¦ˆ", 
      "quote": "I bought this for my son",
      "quote_translated": "æˆ‘ç»™å„¿å­ä¹°çš„",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®è¯´'ç»™å„¿å­ä¹°çš„'ï¼Œè¯æ˜è´­ä¹°è€…æ˜¯æ¯äº²"
    }}
  ],
  "user": [
    {{
      "tag": "3å²ç”·ç«¥", 
      "quote": "my 3 year old loves it",
      "quote_translated": "æˆ‘3å²çš„å­©å­å¾ˆå–œæ¬¢",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®æåˆ°'3å²çš„å­©å­'æ˜¯ä½¿ç”¨è€…"
    }}
  ],
  "where": [],
  "when": [],
  "why": [
    {{
      "tag": "é€ç¤¼",
      "quote": "as a gift for my mom",
      "quote_translated": "ä½œä¸ºç¤¼ç‰©é€ç»™å¦ˆå¦ˆ",
      "confidence": "high",
      "explanation": "è¯„è®ºæ˜ç¡®è¯´'ä½œä¸ºç¤¼ç‰©'ï¼Œè´­ä¹°åŠ¨æœºæ˜¯é€ç¤¼"
    }}
  ],
  "what": []
}}

# Examples of CORRECT Behavior

Example 1 - Short positive review with no 5W info:
Input: "Amazing alarm clock! Works perfectly!"
Output: {{ "buyer": [], "user": [], "where": [], "when": [], "why": [], "what": [] }}
Reason: Review only praises product quality, no 5W elements mentioned.

Example 2 - Review with clear evidence:
Input: "Bought this for my elderly mother who has trouble hearing. The loud alarm helps her wake up in the morning."
Output: {{
  "buyer": [{{"tag": "å­å¥³", "quote": "Bought this for my elderly mother", "quote_translated": "ç»™å¹´è¿ˆçš„æ¯äº²ä¹°çš„", "confidence": "high", "explanation": "æ˜ç¡®è¯´æ˜¯ç»™æ¯äº²è´­ä¹°"}}],
  "user": [{{"tag": "è€å¹´äºº", "quote": "my elderly mother who has trouble hearing", "quote_translated": "å¹´è¿ˆçš„æ¯äº²å¬åŠ›ä¸å¥½", "confidence": "high", "explanation": "æ˜ç¡®è¯´ä½¿ç”¨è€…æ˜¯å¹´è¿ˆçš„æ¯äº²"}}],
  "where": [],
  "when": [{{"tag": "æ—©æ™¨", "quote": "wake up in the morning", "quote_translated": "æ—©ä¸Šèµ·åºŠ", "confidence": "high", "explanation": "æ˜ç¡®è¯´æ—©ä¸Šä½¿ç”¨"}}],
  "why": [],
  "what": [{{"tag": "èµ·åºŠ", "quote": "helps her wake up", "quote_translated": "å¸®åŠ©å¥¹èµ·åºŠ", "confidence": "high", "explanation": "æ˜ç¡®è¯´ç”¨é€”æ˜¯å¸®åŠ©èµ·åºŠ"}}]
}}

Output JSON only, no other text."""


# [NEW] Helper function for robust JSON parsing
def parse_json_safely(text: str):
    """
    Safely parse JSON from LLM output, handling markdown blocks and extra characters.
    """
    if not text:
        return None
        
    # 1. Try direct parsing
    try:
        return json.loads(text)
    except:
        pass
    
    # 2. Try to extract from ```json ... ``` blocks
    match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
    if match:
        try:
            return json.loads(match.group(1))
        except:
            pass
            
    # 3. Try to find the first [ or { and last ] or }
    try:
        text = text.strip()
        if '}' in text: # Likely an object
            start = text.find('{')
            end = text.rfind('}') + 1
            if start != -1 and end != -1:
                return json.loads(text[start:end])
        if ']' in text: # Likely an array
            start = text.find('[')
            end = text.rfind(']') + 1
            if start != -1 and end != -1:
                return json.loads(text[start:end])
    except:
        pass
        
    return None


class TranslationService:
    """
    Service for translating Amazon reviews using Qwen API.
    
    Features:
    - Context-aware e-commerce translation
    - Sentiment analysis
    - Automatic retry with exponential backoff
    - Rate limiting awareness
    """
    
    def __init__(self):
        """Initialize the translation service with Qwen API client."""
        if not settings.QWEN_API_KEY:
            logger.warning("QWEN_API_KEY not configured, translation will fail")
            self.client = None
        else:
            self.client = OpenAI(
                api_key=settings.QWEN_API_KEY,
                base_url=settings.QWEN_API_BASE,
            )
        self.model = settings.QWEN_MODEL
    
    def _check_client(self) -> bool:
        """Check if API client is properly configured."""
        if self.client is None:
            logger.error("Translation service not configured: missing API key")
            return False
        return True
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def translate_text(self, text: str) -> str:
        """
        Translate English text to Chinese with e-commerce context.
        """
        if not self._check_client():
            raise RuntimeError("Translation service not configured")
        
        if not text or not text.strip():
            return ""
        
        # Clean text: remove extra whitespace and normalize
        text = " ".join(text.split())
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": TRANSLATION_SYSTEM_PROMPT},
                    {"role": "user", "content": text}
                ],
                temperature=0.3,  # Lower temperature for more consistent translations
                max_tokens=2000,
                timeout=60.0,
            )
            
            translated = response.choices[0].message.content.strip()
            
            # Validate translation result
            if not translated or len(translated.strip()) == 0:
                logger.warning(f"Translation returned empty for text: {text[:100]}")
                # Retry with a more explicit prompt for short text
                if len(text) < 50:
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–‡æœ¬ç¿»è¯‘æˆä¸­æ–‡ï¼Œå³ä½¿æ–‡æœ¬å¾ˆçŸ­ä¹Ÿè¦ç¿»è¯‘ã€‚"},
                            {"role": "user", "content": f"è¯·ç¿»è¯‘ï¼š{text}"}
                        ],
                        temperature=0.3,
                        max_tokens=500,
                    )
                    translated = response.choices[0].message.content.strip()
            
            if not translated or len(translated.strip()) == 0:
                # Fallback: return a note if translation truly fails
                logger.error(f"Translation failed to produce result for: {text[:100]}")
                raise ValueError(f"Translation returned empty for text: {text[:50]}")
            
            logger.debug(f"Translated: {text[:50]}... -> {translated[:50]}...")
            return translated
            
        except Exception as e:
            logger.error(f"Translation failed for text: {text[:100]}... Error: {e}")
            raise
    
    # ==========================================================================
    # ğŸ”¥ æ‰¹é‡ç¿»è¯‘æ–¹æ³•ï¼ˆ10 æ¡ä¸€æ‰¹ï¼Œæå‡ 10 å€æ•ˆç‡ï¼‰
    # ==========================================================================
    
    # æ‰¹é‡ç¿»è¯‘ç³»ç»Ÿæç¤º
    BATCH_TRANSLATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ç²¾é€šä¸­ç¾æ–‡åŒ–å·®å¼‚çš„èµ„æ·±äºšé©¬é€Šè·¨å¢ƒç”µå•†ç¿»è¯‘ä¸“å®¶ã€‚

## ä»»åŠ¡
å°†å¤šæ¡äºšé©¬é€Šè‹±æ–‡è¯„è®ºæ‰¹é‡ç¿»è¯‘æˆä¸­æ–‡ã€‚

## ç¿»è¯‘åŸåˆ™
1. **æ‹’ç»ç¿»è¯‘è…”**: ä½¿ç”¨è‡ªç„¶æµç•…çš„ä¸­æ–‡è¡¨è¾¾
2. **æƒ…æ„Ÿå¯¹é½**: ä¿æŒåŸæ–‡çš„è¯­æ°”å’Œæƒ…ç»ª
3. **ç”µå•†é£æ ¼**: ä½¿ç”¨ç¬¦åˆä¸­å›½ç”µå•†çš„æ–‡æ¡ˆé£æ ¼

## è¾“å…¥/è¾“å‡ºæ ¼å¼
- è¾“å…¥: JSON å­—å…¸ï¼Œé”®ä¸ºè¯„è®º IDï¼Œå€¼ä¸ºè‹±æ–‡åŸæ–‡
- è¾“å‡º: JSON å­—å…¸ï¼Œé”®ä¸è¾“å…¥ä¸€è‡´ï¼Œå€¼ä¸ºä¸­æ–‡è¯‘æ–‡
- **ä¸¥æ ¼è¦æ±‚**: åªè¿”å› JSONï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€Markdown æ ‡è®°æˆ–å…¶ä»–æ–‡å­—

## ç¤ºä¾‹
è¾“å…¥: {"r1": "Total lemon. Don't waste your money.", "r2": "Game changer for my morning routine."}
è¾“å‡º: {"r1": "ç®€ç›´æ˜¯ä¸ªæ¬¡å“ï¼åˆ«æµªè´¹é’±äº†ã€‚", "r2": "å½»åº•æ”¹å˜äº†æˆ‘æ¯å¤©æ—©ä¸Šçš„ä¹ æƒ¯ï¼ŒçœŸé¦™ï¼"}"""

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=15),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def translate_batch(self, reviews: List[dict]) -> dict:
        """
        æ‰¹é‡ç¿»è¯‘å¤šæ¡è¯„è®ºï¼ˆ10 æ¡ä¸€æ‰¹ï¼‰
        
        ğŸ”¥ æ ¸å¿ƒä¼˜åŒ–ï¼šä¸€æ¬¡ API è°ƒç”¨ç¿»è¯‘ 10 æ¡è¯„è®º
        - QPS æ¶ˆè€—é™ä½ 10 å€
        - æ€»ä½“æ•ˆç‡æå‡ 8-10 å€
        
        Args:
            reviews: è¯„è®ºåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« {"id": "xxx", "text": "original text"}
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸ï¼Œæ ¼å¼: {"id1": "translated1", "id2": "translated2", ...}
            
        Example:
            results = translation_service.translate_batch([
                {"id": "r1", "text": "Great product!"},
                {"id": "r2", "text": "Not worth the money."}
            ])
            # è¿”å›: {"r1": "å¾ˆæ£’çš„äº§å“ï¼", "r2": "ä¸å€¼è¿™ä¸ªä»·ã€‚"}
        """
        if not self._check_client():
            raise RuntimeError("Translation service not configured")
        
        if not reviews or len(reviews) == 0:
            return {}
        
        # æ„å»ºè¾“å…¥ JSON
        input_dict = {}
        for review in reviews:
            review_id = str(review.get("id", ""))
            text = review.get("text", "")
            if review_id and text and text.strip():
                # æˆªæ–­è¶…é•¿æ–‡æœ¬ï¼ˆé˜²æ­¢è¶…å‡º token é™åˆ¶ï¼‰
                text = " ".join(text.split())  # æ¸…ç†ç©ºç™½
                if len(text) > 2000:
                    text = text[:2000] + "..."
                input_dict[review_id] = text
        
        if not input_dict:
            return {}
        
        input_json = json.dumps(input_dict, ensure_ascii=False)
        
        logger.info(f"[æ‰¹é‡ç¿»è¯‘] å¼€å§‹ç¿»è¯‘ {len(input_dict)} æ¡è¯„è®º")
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.BATCH_TRANSLATION_SYSTEM_PROMPT},
                    {"role": "user", "content": input_json}
                ],
                temperature=0.3,
                max_tokens=8000,  # æ‰¹é‡ç¿»è¯‘éœ€è¦æ›´å¤š token
                timeout=120.0,   # æ‰¹é‡ç¿»è¯‘éœ€è¦æ›´é•¿è¶…æ—¶
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # è§£æ JSON ç»“æœ
            result_dict = self._parse_batch_translation_result(result_text, input_dict)
            
            logger.info(f"[æ‰¹é‡ç¿»è¯‘] å®Œæˆ: è¾“å…¥ {len(input_dict)} æ¡, æˆåŠŸ {len(result_dict)} æ¡")
            
            return result_dict
            
        except Exception as e:
            logger.error(f"[æ‰¹é‡ç¿»è¯‘] API è°ƒç”¨å¤±è´¥: {e}")
            raise
    
    def _parse_batch_translation_result(self, result_text: str, input_dict: dict) -> dict:
        """
        è§£ææ‰¹é‡ç¿»è¯‘ç»“æœï¼Œå¸¦å®¹é”™å¤„ç†
        
        å¤„ç†å¸¸è§çš„ LLM è¾“å‡ºé—®é¢˜ï¼š
        1. å¤šä½™çš„ Markdown ä»£ç å—æ ‡è®°
        2. å‰åæœ‰è§£é‡Šæ–‡å­—
        3. JSON æ ¼å¼é”™è¯¯
        """
        result_dict = {}
        
        # 1. å°è¯•æ¸…ç† Markdown ä»£ç å—
        clean_text = result_text
        if "```json" in clean_text:
            match = re.search(r'```json\s*(.*?)\s*```', clean_text, re.DOTALL)
            if match:
                clean_text = match.group(1)
        elif "```" in clean_text:
            match = re.search(r'```\s*(.*?)\s*```', clean_text, re.DOTALL)
            if match:
                clean_text = match.group(1)
        
        # 2. å°è¯•æå– JSON å¯¹è±¡
        json_match = re.search(r'\{[^{}]*\}', clean_text, re.DOTALL)
        if json_match:
            clean_text = json_match.group(0)
        
        # 3. å°è¯•è§£æ JSON
        try:
            result_dict = json.loads(clean_text)
            if isinstance(result_dict, dict):
                # éªŒè¯é”®ä¸è¾“å…¥ä¸€è‡´
                valid_result = {}
                for key in input_dict.keys():
                    if key in result_dict and result_dict[key]:
                        valid_result[key] = str(result_dict[key]).strip()
                return valid_result
        except json.JSONDecodeError as e:
            logger.warning(f"[æ‰¹é‡ç¿»è¯‘] JSON è§£æå¤±è´¥: {e}")
        
        # 4. è§£æå¤±è´¥ï¼Œå°è¯• json_repairï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import json_repair
            repaired = json_repair.loads(clean_text)
            if isinstance(repaired, dict):
                valid_result = {}
                for key in input_dict.keys():
                    if key in repaired and repaired[key]:
                        valid_result[key] = str(repaired[key]).strip()
                return valid_result
        except ImportError:
            pass
        except Exception as e:
            logger.warning(f"[æ‰¹é‡ç¿»è¯‘] json_repair å¤±è´¥: {e}")
        
        # 5. æœ€ç»ˆå›é€€ï¼šè¿”å›ç©ºï¼Œè®©è°ƒç”¨æ–¹é™çº§ä¸ºå•æ¡ç¿»è¯‘
        logger.error(f"[æ‰¹é‡ç¿»è¯‘] æ— æ³•è§£æç»“æœï¼ŒåŸå§‹è¾“å‡º: {result_text[:500]}")
        return {}
    
    def translate_batch_with_fallback(self, reviews: List[dict]) -> dict:
        """
        æ‰¹é‡ç¿»è¯‘ï¼Œå¸¦å•æ¡å›é€€æœºåˆ¶
        
        å¦‚æœæ‰¹é‡ç¿»è¯‘å¤±è´¥æˆ–éƒ¨åˆ†å¤±è´¥ï¼Œè‡ªåŠ¨é™çº§ä¸ºå•æ¡ç¿»è¯‘
        
        Args:
            reviews: è¯„è®ºåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« {"id": "xxx", "text": "original text"}
            
        Returns:
            ç¿»è¯‘ç»“æœå­—å…¸ï¼Œæ ¼å¼: {"id1": "translated1", "id2": "translated2", ...}
        """
        result = {}
        
        # 1. å°è¯•æ‰¹é‡ç¿»è¯‘
        try:
            batch_result = self.translate_batch(reviews)
            result.update(batch_result)
        except Exception as e:
            logger.warning(f"[æ‰¹é‡ç¿»è¯‘] æ‰¹é‡æ¨¡å¼å¤±è´¥ï¼Œé™çº§ä¸ºå•æ¡: {e}")
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æœªç¿»è¯‘çš„è¯„è®ºï¼Œå•æ¡å›é€€
        for review in reviews:
            review_id = str(review.get("id", ""))
            text = review.get("text", "")
            
            if review_id and text and review_id not in result:
                try:
                    translated = self.translate_text(text)
                    if translated:
                        result[review_id] = translated
                        logger.debug(f"[æ‰¹é‡ç¿»è¯‘] å•æ¡å›é€€æˆåŠŸ: {review_id}")
                except Exception as e:
                    logger.warning(f"[æ‰¹é‡ç¿»è¯‘] å•æ¡å›é€€å¤±è´¥ {review_id}: {e}")
        
        return result
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def analyze_sentiment(self, text: str) -> Sentiment:
        """
        Analyze the sentiment of a review.
        """
        if not self._check_client():
            return Sentiment.NEUTRAL
        
        if not text or not text.strip():
            return Sentiment.NEUTRAL
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": SENTIMENT_ANALYSIS_PROMPT.format(review_text=text)}
                ],
                temperature=0.1,
                max_tokens=20,
                timeout=30.0,
            )
            
            result = response.choices[0].message.content.strip().lower()
            
            if "positive" in result:
                return Sentiment.POSITIVE
            elif "negative" in result:
                return Sentiment.NEGATIVE
            else:
                return Sentiment.NEUTRAL
                
        except Exception as e:
            logger.warning(f"Sentiment analysis failed: {e}, defaulting to neutral")
            return Sentiment.NEUTRAL
    
    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_dimensions(
        self, 
        reviews_text: List[str],
        product_title: str = "",
        bullet_points: str = ""
    ) -> List[dict]:
        """
        è®© AI ä»äº§å“ä¿¡æ¯å’Œè¯„è®ºæ ·æœ¬ä¸­å­¦ä¹ å¹¶æ€»ç»“äº§å“è¯„ä»·ç»´åº¦ã€‚
        
        Args:
            reviews_text: è¯„è®ºæ–‡æœ¬åˆ—è¡¨ï¼ˆå»ºè®®30-50æ¡ï¼‰
            product_title: äº§å“æ ‡é¢˜ï¼ˆå¯é€‰ï¼Œç”¨äºæä¾›äº§å“ä¸Šä¸‹æ–‡ï¼‰
            bullet_points: äº§å“äº”ç‚¹æè¿°ï¼ˆå¯é€‰ï¼Œç”¨äºè¡¥å……äº§å“å–ç‚¹ï¼‰
            
        Returns:
            ç»´åº¦åˆ—è¡¨ï¼Œæ¯ä¸ªç»´åº¦åŒ…å« name å’Œ description
            
        Example:
            [
                {"name": "ç”µæ± ç»­èˆª", "description": "ä¸å……ç”µé€Ÿåº¦å’Œä½¿ç”¨æ—¶é•¿ç›¸å…³çš„é—®é¢˜"},
                {"name": "å¤–è§‚è®¾è®¡", "description": "äº§å“çš„å¤–è§‚ã€é¢œè‰²ã€æè´¨ç­‰è§†è§‰ç›¸å…³è¯„ä»·"}
            ]
        """
        if not self._check_client():
            logger.error("Translation service not configured for dimension learning")
            return []
        
        if not reviews_text or len(reviews_text) < 5:
            logger.warning("æ ·æœ¬æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦5æ¡è¯„è®ºï¼‰ï¼Œæ— æ³•æœ‰æ•ˆå­¦ä¹ ç»´åº¦")
            return []
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… token
        sample_texts = reviews_text[:50]
        combined_text = "\n---\n".join(sample_texts)
        
        # å¤„ç†äº§å“ä¿¡æ¯
        title_text = product_title.strip() if product_title else "ï¼ˆæœªæä¾›ï¼‰"
        bullet_text = bullet_points.strip() if bullet_points else "ï¼ˆæœªæä¾›ï¼‰"
        
        try:
            prompt = DIMENSION_DISCOVERY_PROMPT.format(
                product_title=title_text,
                bullet_points=bullet_text,
                count=len(sample_texts),
                reviews_text=combined_text
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
                max_tokens=2000,
                timeout=90.0,
            )
            
            result = response.choices[0].message.content.strip()
            
            # ä½¿ç”¨å¥å£®çš„ JSON è§£æå™¨
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict) or "dimensions" not in parsed:
                logger.warning(f"ç»´åº¦å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return []
            
            dimensions = parsed.get("dimensions", [])
            
            # éªŒè¯ç»´åº¦æ ¼å¼
            valid_dimensions = []
            for dim in dimensions:
                if isinstance(dim, dict) and dim.get("name"):
                    valid_dimensions.append({
                        "name": dim["name"].strip(),
                        "description": (dim.get("description") or "").strip()
                    })
            
            logger.info(f"AI æˆåŠŸå­¦ä¹ åˆ° {len(valid_dimensions)} ä¸ªäº§å“ç»´åº¦")
            return valid_dimensions
            
        except Exception as e:
            logger.error(f"ç»´åº¦å­¦ä¹ å¤±è´¥: {e}")
            return []

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_dimensions_from_raw(
        self, 
        raw_reviews: List[str],
        product_title: str = "",
        bullet_points: str = ""
    ) -> List[dict]:
        """
        è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹ ï¼šä»è‹±æ–‡åŸæ–‡è¯„è®ºç›´æ¥å­¦ä¹ äº§å“ç»´åº¦ï¼ˆè¾“å‡ºä¸­æ–‡ï¼‰ã€‚
        
        è¿™æ˜¯æµå¼å¤„ç†æ¶æ„çš„æ ¸å¿ƒæ–¹æ³•ï¼š
        - ä¸éœ€è¦ç­‰å¾…ç¿»è¯‘å®Œæˆ
        - ç›´æ¥ä½¿ç”¨è‹±æ–‡åŸæ–‡è¿›è¡Œå­¦ä¹ 
        - AI è¾“å‡ºä¸­æ–‡ç»´åº¦åç§°å’Œæè¿°
        
        Args:
            raw_reviews: è‹±æ–‡åŸæ–‡è¯„è®ºåˆ—è¡¨ï¼ˆæ¥è‡ª get_scientific_samplesï¼‰
            product_title: äº§å“è‹±æ–‡æ ‡é¢˜
            bullet_points: äº§å“è‹±æ–‡äº”ç‚¹æè¿°
            
        Returns:
            ç»´åº¦åˆ—è¡¨ï¼ˆä¸­æ–‡ï¼‰ï¼Œæ¯ä¸ªç»´åº¦åŒ…å« name å’Œ description
        """
        if not self._check_client():
            logger.error("Translation service not configured for raw dimension learning")
            return []
        
        if not raw_reviews or len(raw_reviews) < 5:
            logger.warning("æ ·æœ¬æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦5æ¡è‹±æ–‡è¯„è®ºï¼‰ï¼Œæ— æ³•æœ‰æ•ˆå­¦ä¹ ç»´åº¦")
            return []
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… token
        sample_texts = raw_reviews[:50]
        combined_text = "\n---\n".join([f"Review {i+1}: {text}" for i, text in enumerate(sample_texts)])
        
        # å¤„ç†äº§å“ä¿¡æ¯
        title_text = product_title.strip() if product_title else "(Not provided)"
        bullet_text = bullet_points.strip() if bullet_points else "(Not provided)"
        
        try:
            prompt = DIMENSION_DISCOVERY_RAW_PROMPT.format(
                product_title=title_text,
                bullet_points=bullet_text,
                count=len(sample_texts),
                reviews_text=combined_text
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=2000,
                timeout=90.0,
            )
            
            result = response.choices[0].message.content.strip()
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict) or "dimensions" not in parsed:
                logger.warning(f"è·¨è¯­è¨€ç»´åº¦å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return []
            
            dimensions = parsed.get("dimensions", [])
            
            valid_dimensions = []
            for dim in dimensions:
                if isinstance(dim, dict) and dim.get("name"):
                    valid_dimensions.append({
                        "name": dim["name"].strip(),
                        "description": (dim.get("description") or "").strip()
                    })
            
            logger.info(f"[è·¨è¯­è¨€å­¦ä¹ ] ä» {len(sample_texts)} æ¡è‹±æ–‡è¯„è®ºå­¦ä¹ åˆ° {len(valid_dimensions)} ä¸ªä¸­æ–‡ç»´åº¦")
            return valid_dimensions
            
        except Exception as e:
            logger.error(f"è·¨è¯­è¨€ç»´åº¦å­¦ä¹ å¤±è´¥: {e}")
            return []

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_context_labels_from_raw(
        self, 
        raw_reviews: List[str],
        product_title: str = "",
        bullet_points: List[str] = None
    ) -> dict:
        """
        è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹ ï¼šä»è‹±æ–‡åŸæ–‡è¯„è®ºç›´æ¥å­¦ä¹  5W æ ‡ç­¾åº“ï¼ˆè¾“å‡ºä¸­æ–‡ï¼‰ã€‚
        
        è¿™æ˜¯æµå¼å¤„ç†æ¶æ„çš„æ ¸å¿ƒæ–¹æ³•ï¼š
        - ä¸éœ€è¦ç­‰å¾…ç¿»è¯‘å®Œæˆ
        - ç›´æ¥ä½¿ç”¨è‹±æ–‡åŸæ–‡è¿›è¡Œå­¦ä¹ 
        - AI è¾“å‡ºä¸­æ–‡æ ‡ç­¾åç§°å’Œæè¿°
        
        Args:
            raw_reviews: è‹±æ–‡åŸæ–‡è¯„è®ºåˆ—è¡¨ï¼ˆæ¥è‡ª get_scientific_samplesï¼‰
            product_title: äº§å“è‹±æ–‡æ ‡é¢˜
            bullet_points: äº§å“è‹±æ–‡äº”ç‚¹æè¿°åˆ—è¡¨
            
        Returns:
            5W æ ‡ç­¾å­—å…¸ï¼ˆä¸­æ–‡ï¼‰ï¼Œæ ¼å¼ï¼š
            {
                "who": [{"name": "è€å¹´äºº", "description": "..."}, ...],
                "where": [...],
                "when": [...],
                "why": [...],
                "what": [...]
            }
        """
        if not self._check_client():
            logger.error("Translation service not configured for raw context learning")
            return {}
        
        if not raw_reviews or len(raw_reviews) < 10:
            logger.warning("æ ·æœ¬æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦10æ¡è‹±æ–‡è¯„è®ºï¼‰ï¼Œæ— æ³•æœ‰æ•ˆå­¦ä¹  5W æ ‡ç­¾")
            return {}
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… token
        sample_texts = raw_reviews[:50]
        combined_reviews = "\n---\n".join([f"Review {i+1}: {text}" for i, text in enumerate(sample_texts)])
        
        # æ ¼å¼åŒ–äº§å“å®˜æ–¹ä¿¡æ¯
        formatted_title = product_title.strip() if product_title else "(Not provided)"
        formatted_bullets = "(Not provided)"
        if bullet_points and len(bullet_points) > 0:
            formatted_bullets = "\n".join([f"  - {bp}" for bp in bullet_points if bp and bp.strip()])
        
        logger.info(f"[è·¨è¯­è¨€å­¦ä¹ ] 5Wæ ‡ç­¾å­¦ä¹ ï¼š{len(sample_texts)} æ¡è‹±æ–‡è¯„è®º + äº§å“ä¿¡æ¯")
        
        try:
            prompt = CONTEXT_DISCOVERY_RAW_PROMPT.format(
                product_title=formatted_title,
                bullet_points=formatted_bullets,
                count=len(sample_texts),
                reviews_text=combined_reviews
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=120.0,
            )
            
            result = response.choices[0].message.content.strip()
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict):
                logger.warning(f"è·¨è¯­è¨€ 5W æ ‡ç­¾å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return {}
            
            # [UPDATED 2026-01-14] æ‰©å±• valid_types: buyer/user æ›¿ä»£ whoï¼ŒåŒæ—¶å…¼å®¹æ—§çš„ who
            valid_types = {"buyer", "user", "who", "where", "when", "why", "what"}
            valid_result = {}
            
            for context_type in valid_types:
                labels = parsed.get(context_type, [])
                valid_labels = []
                
                for label in labels:
                    if isinstance(label, dict) and label.get("name"):
                        valid_labels.append({
                            "name": label["name"].strip(),
                            "description": (label.get("description") or "").strip()
                        })
                
                if valid_labels:
                    valid_result[context_type] = valid_labels
            
            total_labels = sum(len(v) for v in valid_result.values())
            logger.info(f"[è·¨è¯­è¨€å­¦ä¹ ] ä»è‹±æ–‡è¯„è®ºå­¦ä¹ åˆ° {total_labels} ä¸ªä¸­æ–‡ 5W æ ‡ç­¾ï¼ˆ{len(valid_result)} ä¸ªç±»å‹ï¼‰")
            return valid_result
            
        except Exception as e:
            logger.error(f"è·¨è¯­è¨€ 5W æ ‡ç­¾å­¦ä¹ å¤±è´¥: {e}")
            return {}

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def learn_context_labels(
        self, 
        reviews_text: List[str],
        product_title: str = "",
        bullet_points: List[str] = None
    ) -> dict:
        """
        è®© AI ç»“åˆäº§å“å®˜æ–¹ä¿¡æ¯å’Œè¯„è®ºæ ·æœ¬å­¦ä¹  5W æ ‡å‡†æ ‡ç­¾åº“ï¼ˆDefinition é˜¶æ®µï¼‰ã€‚
        
        è¿™æ˜¯ AI-Native æ¶æ„çš„æ ¸å¿ƒï¼š"å…ˆå­¦ä¹ æ ‡å‡†ï¼Œåå¼ºåˆ¶å½’ç±»"ã€‚
        AI ä¼šåˆ†æäº§å“æ ‡é¢˜ã€äº”ç‚¹å–ç‚¹å’Œè¯„è®ºæ ·æœ¬ï¼Œä¸ºæ¯ä¸ª 5W ç±»å‹ç”Ÿæˆæ ‡å‡†æ ‡ç­¾ã€‚
        
        **[UPDATED] åŠ å…¥äº§å“å®˜æ–¹ä¿¡æ¯ï¼š**
        - æ ‡é¢˜å’Œäº”ç‚¹æ˜¯å•†å®¶çš„"å–å®¶ç§€"ï¼Œå¾€å¾€æ¯”ç”¨æˆ·è¯„è®ºæ›´ç²¾å‡†
        - ç‰¹åˆ«å¯¹ Whoï¼ˆäººç¾¤ï¼‰ã€Whereï¼ˆåœºæ™¯ï¼‰ã€Whatï¼ˆä»»åŠ¡ï¼‰æå‡æ˜¾è‘—
        
        Args:
            reviews_text: è¯„è®ºæ–‡æœ¬åˆ—è¡¨ï¼ˆå»ºè®®30-50æ¡ï¼Œæ··åˆå¥½è¯„å·®è¯„ï¼‰
            product_title: äº§å“æ ‡é¢˜ï¼ˆè‹±æ–‡åŸæ–‡ï¼‰
            bullet_points: äº§å“äº”ç‚¹å–ç‚¹åˆ—è¡¨ï¼ˆè‹±æ–‡åŸæ–‡ï¼‰
            
        Returns:
            5W æ ‡ç­¾å­—å…¸ï¼Œæ ¼å¼ï¼š
            {
                "who": [{"name": "è€å¹´äºº", "description": "..."}, ...],
                "where": [...],
                "when": [...],
                "why": [...],
                "what": [...]
            }
            
        Example:
            >>> labels = service.learn_context_labels(
            ...     reviews[:50],
            ...     product_title="LED Light for Seniors",
            ...     bullet_points=["Perfect for elderly", "Home Office use"]
            ... )
        """
        if not self._check_client():
            logger.error("Translation service not configured for context learning")
            return {}
        
        if not reviews_text or len(reviews_text) < 30:
            logger.warning("æ ·æœ¬æ•°é‡ä¸è¶³ï¼ˆè‡³å°‘éœ€è¦30æ¡è¯„è®ºï¼‰ï¼Œæ— æ³•æœ‰æ•ˆå­¦ä¹  5W æ ‡ç­¾")
            return {}
        
        # é™åˆ¶æ ·æœ¬é‡é˜²æ­¢è¶… tokenï¼ˆ50æ¡è¯„è®ºçº¦ 4000-6000 tokensï¼‰
        sample_texts = reviews_text[:50]
        combined_reviews = "\n---\n".join([f"è¯„è®º{i+1}: {text}" for i, text in enumerate(sample_texts)])
        
        # [NEW] æ ¼å¼åŒ–äº§å“å®˜æ–¹ä¿¡æ¯
        formatted_title = product_title.strip() if product_title else "ï¼ˆæ— ï¼‰"
        formatted_bullets = "ï¼ˆæ— ï¼‰"
        if bullet_points and len(bullet_points) > 0:
            formatted_bullets = "\n".join([f"  - {bp}" for bp in bullet_points if bp and bp.strip()])
        
        logger.info(f"5W æ ‡ç­¾å­¦ä¹ ï¼š{len(sample_texts)} æ¡è¯„è®º + äº§å“ä¿¡æ¯ï¼ˆæ ‡é¢˜: {len(formatted_title)}å­—, äº”ç‚¹: {len(bullet_points or [])}æ¡ï¼‰")
        
        try:
            prompt = CONTEXT_DISCOVERY_PROMPT.format(
                product_title=formatted_title,
                bullet_points=formatted_bullets,
                count=len(sample_texts),
                reviews_text=combined_reviews
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,  # è¾ƒä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
                max_tokens=3000,
                timeout=120.0,  # ç¨é•¿çš„è¶…æ—¶æ—¶é—´
            )
            
            result = response.choices[0].message.content.strip()
            
            # ä½¿ç”¨å¥å£®çš„ JSON è§£æå™¨
            parsed = parse_json_safely(result)
            
            if not isinstance(parsed, dict):
                logger.warning(f"5W æ ‡ç­¾å‘ç°è¿”å›æ ¼å¼ä¸æ­£ç¡®: {type(parsed)}")
                return {}
            
            # [UPDATED 2026-01-14] éªŒè¯å’Œæ¸…ç†æ¯ä¸ª 5W ç±»å‹çš„æ ‡ç­¾ï¼ˆæ‰©å±•ç‰ˆï¼šbuyer/user æ›¿ä»£ whoï¼‰
            valid_types = {"buyer", "user", "who", "where", "when", "why", "what"}
            valid_result = {}
            
            for context_type in valid_types:
                labels = parsed.get(context_type, [])
                valid_labels = []
                
                for label in labels:
                    if isinstance(label, dict) and label.get("name"):
                        valid_labels.append({
                            "name": label["name"].strip(),
                            "description": (label.get("description") or "").strip()
                        })
                
                if valid_labels:
                    valid_result[context_type] = valid_labels
                    logger.debug(f"  {context_type}: {len(valid_labels)} ä¸ªæ ‡ç­¾")
            
            total_labels = sum(len(v) for v in valid_result.values())
            logger.info(f"AI æˆåŠŸå­¦ä¹ åˆ° {total_labels} ä¸ª 5W æ ‡ç­¾ï¼ˆ{len(valid_result)} ä¸ªç±»å‹ï¼‰")
            return valid_result
            
        except Exception as e:
            logger.error(f"5W æ ‡ç­¾å­¦ä¹ å¤±è´¥: {e}")
            return {}

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def extract_insights(
        self,
        original_text: str,
        translated_text: str = None,  # [UPDATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å‚æ•°ä»…ä¸ºå‘åå…¼å®¹
        dimension_schema: List[dict] = None
    ) -> List[dict]:
        """
        Extract insights from a review using cross-language analysis.
        
        [UPDATED] è·¨è¯­è¨€æ´å¯Ÿæå– - ç›´æ¥ä»è‹±æ–‡åŸæ–‡æå–æ´å¯Ÿï¼Œè¾“å‡ºä¸­æ–‡ç»“æœã€‚
        ä¸å†ä¾èµ–ç¿»è¯‘åçš„æ–‡æœ¬ï¼Œå®ç°ä¸ç¿»è¯‘ä»»åŠ¡çš„å®Œå…¨è§£è€¦ã€‚
        
        Args:
            original_text: åŸå§‹è¯„è®ºæ–‡æœ¬ï¼ˆè‹±æ–‡ï¼‰
            translated_text: [DEPRECATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™ä»…ä¸ºå‘åå…¼å®¹
            dimension_schema: å¯é€‰çš„ç»´åº¦æ¨¡å¼åˆ—è¡¨ï¼Œç”¨äºé™å®š AI åªä½¿ç”¨è¿™äº›ç»´åº¦è¿›è¡Œå½’ç±»
                             æ ¼å¼: [{"name": "ç»´åº¦å", "description": "ç»´åº¦å®šä¹‰"}, ...]
        
        Returns:
            æ´å¯Ÿåˆ—è¡¨ï¼Œæ¯ä¸ªæ´å¯ŸåŒ…å« type, dimension, quote(è‹±æ–‡), quote_translated(ä¸­æ–‡), analysis(ä¸­æ–‡) ç­‰å­—æ®µ
        """
        if not self._check_client():
            return []
        
        # [ä¼˜åŒ–] ç§»é™¤é•¿åº¦é™åˆ¶ - ç¡®ä¿æ¯æ¡è¯„è®ºéƒ½èƒ½æå–æ´å¯Ÿ
        # å³ä½¿æ˜¯çŸ­è¯„è®ºä¹Ÿå¯èƒ½åŒ…å«é‡è¦ä¿¡æ¯
        if not original_text or not original_text.strip():
            return []
        
        try:
            # æ ¹æ®æ˜¯å¦æœ‰ç»´åº¦æ¨¡å¼é€‰æ‹©ä¸åŒçš„ Prompt
            # [UPDATED] è·¨è¯­è¨€æ¨¡å¼ï¼šåªä¼ å…¥è‹±æ–‡åŸæ–‡ï¼ŒAI è¾“å‡ºä¸­æ–‡åˆ†æ
            if dimension_schema and len(dimension_schema) > 0:
                # ä½¿ç”¨åŠ¨æ€ç»´åº¦ Prompt - å¼ºåˆ¶ AI æŒ‰æŒ‡å®šç»´åº¦å½’ç±»
                schema_str = "\n".join([
                    f"- {d['name']}: {d.get('description', 'æ— å…·ä½“å®šä¹‰')}" 
                    for d in dimension_schema
                ])
                prompt = INSIGHT_EXTRACTION_PROMPT_DYNAMIC.format(
                    original_text=original_text,
                    schema_str=schema_str
                )
                logger.debug(f"[è·¨è¯­è¨€æ´å¯Ÿ] ä½¿ç”¨åŠ¨æ€ç»´åº¦ Promptï¼Œå…± {len(dimension_schema)} ä¸ªç»´åº¦")
            else:
                # ä½¿ç”¨æ— ç»´åº¦ Prompt - è‡ªåŠ¨æ£€æµ‹ç»´åº¦
                prompt = INSIGHT_EXTRACTION_PROMPT.format(
                    original_text=original_text
                )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2, # Lower temperature for structural extraction
                max_tokens=1500,
                timeout=60.0,
            )
            
            result = response.choices[0].message.content.strip()
            
            # [UPDATED] Use robust JSON parser
            insights = parse_json_safely(result)
            
            if not isinstance(insights, list):
                logger.warning(f"Parsed insights is not a list: {type(insights)}")
                return []
            
            # Validate insights
            valid_insights = []
            valid_types = {"strength", "weakness", "suggestion", "scenario", "emotion"}
            
            for insight in insights:
                if not isinstance(insight, dict):
                    continue
                if insight.get("type") not in valid_types:
                    continue
                if not insight.get("quote") or not insight.get("analysis"):
                    continue
                
                # [UPDATED 2026-01-15] æ·»åŠ  confidence å­—æ®µæ”¯æŒ
                confidence = insight.get("confidence", "high")
                if confidence not in ("high", "medium", "low"):
                    confidence = "high"
                
                valid_insights.append({
                    "type": insight["type"],
                    "quote": insight["quote"],
                    "quote_translated": insight.get("quote_translated"),
                    "analysis": insight["analysis"],
                    "dimension": insight.get("dimension"),
                    "confidence": confidence  # [NEW] ç½®ä¿¡åº¦
                })
            
            logger.debug(f"Extracted {len(valid_insights)} insights from review")
            return valid_insights
            
        except Exception as e:
            logger.warning(f"Insight extraction failed: {e}")
            return []
    
    def translate_review(
        self,
        title: Optional[str],
        body: str,
        extract_insights: bool = True
    ) -> Tuple[Optional[str], str, Sentiment, List[dict]]:
        """
        Translate a complete review (title and body), analyze sentiment, and extract insights.
        """
        # Translate title if present
        translated_title = None
        if title and title.strip():
            try:
                translated_title = self.translate_text(title)
            except Exception as e:
                logger.error(f"Failed to translate title: {e}")
                translated_title = None
        
        # Translate body (required)
        try:
            translated_body = self.translate_text(body)
        except Exception as e:
            logger.error(f"Failed to translate body: {e}")
            translated_body = ""
        
        # Analyze sentiment from original text (more accurate)
        sentiment = self.analyze_sentiment(body)
        
        # Extract insights
        insights = []
        if extract_insights and translated_body:
            try:
                insights = self.extract_insights(body, translated_body)
            except Exception as e:
                logger.warning(f"Failed to extract insights: {e}")
                insights = []
        
        return translated_title, translated_body, sentiment, insights
    
    def process_review_parallel(
        self, 
        title: Optional[str], 
        body: str,
        dimension_schema: List[dict] = None,  # [NEW] æ¥æ”¶ä¸“å±ç»´åº¦ï¼ˆç”¨äºæ´å¯Ÿæå–ï¼‰
        context_schema: dict = None           # [NEW] æ¥æ”¶ä¸“å±5Wæ ‡ç­¾ï¼ˆç”¨äºä¸»é¢˜æå–ï¼‰
    ) -> Optional[dict]:
        """
        [High Performance] Execute distinct prompts in parallel to maintain quality while boosting speed.
        
        This method orchestrates parallel execution of translation and analysis tasks:
        - Phase 1: Translate Title, Translate Body, Analyze Sentiment (Parallel - no dependencies)
        - Phase 2: Extract Insights, Extract Themes (Parallel - dependent on Phase 1 translation results)
        
        [UPDATED] Now supports dynamic schemas for personalized analysis:
        - dimension_schema: Product-specific dimensions for insight categorization
        - context_schema: Product-specific 5W labels for theme categorization
        
        Expected speedup: ~50% (from ~6s to ~3.5s per review) while maintaining 100% quality.
        
        Args:
            title: Review title (optional)
            body: Review body (required)
            dimension_schema: Optional list of dimension dicts for insight extraction
                             [{"name": "ç»´åº¦å", "description": "ç»´åº¦å®šä¹‰"}, ...]
            context_schema: Optional 5W label dict for theme extraction
                           {"who": [{"name": "...", "description": "..."}], ...}
            
        Returns:
            Dict with all analysis results, or None if processing fails
            
        Example:
            {
                "title_original": "Great product",
                "body_original": "Love it!",
                "title_translated": "å¾ˆæ£’çš„äº§å“",
                "body_translated": "å¤ªå–œæ¬¢äº†ï¼",
                "sentiment": "positive",
                "insights": [...],
                "themes": {...}
            }
        """
        if not self._check_client() or not body:
            return None

        result = {
            "title_original": title or None,
            "body_original": body,
            "title_translated": None,
            "body_translated": None,
            "sentiment": Sentiment.NEUTRAL.value,
            "insights": [],
            "themes": {}
        }

        # Create thread pool (max_workers=5 balances concurrency with API rate limits)
        with ThreadPoolExecutor(max_workers=5) as executor:
            # --- Phase 1: åŸºç¡€ä»»åŠ¡ (æ— ä¾èµ–ï¼Œå¯ä»¥å¹¶è¡Œ) ---
            future_title = executor.submit(self.translate_text, title) if title and title.strip() else None
            future_body = executor.submit(self.translate_text, body)
            future_sentiment = executor.submit(self.analyze_sentiment, body)

            # Wait for Phase 1 results (blocks until all complete)
            try:
                if future_title:
                    result["title_translated"] = future_title.result()
                
                # Critical: must get body translation before Phase 2 analysis
                result["body_translated"] = future_body.result()
                
                result["sentiment"] = future_sentiment.result().value
                
                logger.debug(f"Phase 1 completed: translation and sentiment analysis done")
            except Exception as e:
                logger.error(f"Phase 1 (translation) failed: {e}")
                # If body translation fails, cannot proceed to Phase 2
                if not result["body_translated"]:
                    logger.warning("Body translation failed, skipping Phase 2 analysis")
                    return result

            # --- Phase 2: é«˜çº§åˆ†æä»»åŠ¡ (ä¾èµ–ç¿»è¯‘ç»“æœï¼Œå¹¶è¡Œæ‰§è¡Œ) ---
            # Now we have both original_text and translated_text
            # We can launch insight extraction and theme extraction in parallel
            
            # [FIXED] å°†ä¸“å±ç»´åº¦ (dimension_schema) é€ä¼ ç»™æå–æ–¹æ³•
            future_insights = executor.submit(
                self.extract_insights, 
                result["body_original"], 
                result["body_translated"],
                dimension_schema  # <--- æ³¨å…¥ç»´åº¦è¡¨
            )
            
            # [FIXED] å°†ä¸“å±æ ‡ç­¾ (context_schema) é€ä¼ ç»™æå–æ–¹æ³•
            future_themes = executor.submit(
                self.extract_themes, 
                result["body_original"], 
                result["body_translated"],
                context_schema  # <--- æ³¨å…¥5Wæ ‡ç­¾åº“
            )

            # Wait for Phase 2 results (both can fail independently)
            try:
                result["insights"] = future_insights.result() or []
                logger.debug(f"Extracted {len(result['insights'])} insights")
            except Exception as e:
                logger.warning(f"Insight extraction failed: {e}")
                result["insights"] = []

            try:
                result["themes"] = future_themes.result() or {}
                logger.debug(f"Extracted {len(result['themes'])} theme categories")
            except Exception as e:
                logger.warning(f"Theme extraction failed: {e}")
                result["themes"] = {}

        logger.info(
            f"Parallel processing completed: "
            f"translation={bool(result['body_translated'])}, "
            f"sentiment={result['sentiment']}, "
            f"insights={len(result['insights'])}, "
            f"themes={len(result['themes'])}"
        )
        return result
    
    def batch_translate(
        self,
        reviews: list[dict]
    ) -> list[dict]:
        """
        Translate a batch of reviews.
        """
        results = []
        
        for review in reviews:
            title = review.get("title") or review.get("title_original")
            body = review.get("body") or review.get("body_original", "")
            
            try:
                translated_title, translated_body, sentiment, insights = self.translate_review(
                    title=title,
                    body=body,
                    extract_insights=True 
                )
                results.append({
                    "title_translated": translated_title,
                    "body_translated": translated_body,
                    "sentiment": sentiment.value,
                    "insights": insights,
                    "success": True
                })
            except Exception as e:
                logger.error(f"Batch translation failed for review: {e}")
                results.append({
                    "title_translated": None,
                    "body_translated": None,
                    "sentiment": Sentiment.NEUTRAL.value,
                    "insights": [],
                    "success": False,
                    "error": str(e)
                })
        
        return results
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def translate_bullet_points(self, bullet_points: List[str]) -> List[str]:
        """
        Translate product bullet points from English to Chinese.
        """
        if not self._check_client():
            raise RuntimeError("Translation service not configured")
        
        if not bullet_points or len(bullet_points) == 0:
            return []
        
        # Combine bullet points for batch translation
        combined_text = "\n".join(bullet_points)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": BULLET_POINTS_SYSTEM_PROMPT},
                    {"role": "user", "content": combined_text}
                ],
                temperature=0.3,
                max_tokens=3000,
                timeout=60.0,
            )
            
            translated_text = response.choices[0].message.content.strip()
            
            # Split back into individual bullet points
            translated_points = [p.strip() for p in translated_text.split("\n") if p.strip()]
            
            # Ensure we have the same number of translations
            if len(translated_points) != len(bullet_points):
                logger.warning(
                    f"Bullet point count mismatch: original {len(bullet_points)}, "
                    f"translated {len(translated_points)}"
                )
                # Pad with empty strings or truncate
                while len(translated_points) < len(bullet_points):
                    translated_points.append("")
                translated_points = translated_points[:len(bullet_points)]
            
            logger.info(f"Translated {len(bullet_points)} bullet points")
            return translated_points
            
        except Exception as e:
            logger.error(f"Bullet points translation failed: {e}")
            raise
    
    def translate_product_title(self, title: str) -> str:
        """
        Translate product title from English to Chinese.
        """
        if not title or not title.strip():
            return ""
        
        try:
            return self.translate_text(title)
        except Exception as e:
            logger.error(f"Product title translation failed: {e}")
            raise

    @retry(
        stop=stop_after_attempt(2),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((Exception,)),
        reraise=True
    )
    def extract_themes(
        self, 
        original_text: str, 
        translated_text: str = None,  # [UPDATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™å‚æ•°ä»…ä¸ºå‘åå…¼å®¹
        context_schema: dict = None
    ) -> dict:
        """
        Extract 5W theme content from a review using cross-language analysis.
        
        [UPDATED] è·¨è¯­è¨€5Wä¸»é¢˜æå– - ç›´æ¥ä»è‹±æ–‡åŸæ–‡æå–5Wè¦ç´ ï¼Œè¾“å‡ºä¸­æ–‡ç»“æœã€‚
        ä¸å†ä¾èµ–ç¿»è¯‘åçš„æ–‡æœ¬ï¼Œå®ç°ä¸ç¿»è¯‘ä»»åŠ¡çš„å®Œå…¨è§£è€¦ã€‚
        
        æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
        1. å¼€æ”¾æå–æ¨¡å¼ï¼ˆæ—  context_schemaï¼‰ï¼šAI è‡ªç”±æå– 5W è¦ç´ 
        2. å¼ºåˆ¶å½’ç±»æ¨¡å¼ï¼ˆæœ‰ context_schemaï¼‰ï¼šAI åªèƒ½è¾“å‡ºæ ‡ç­¾åº“ä¸­å·²æœ‰çš„æ ‡ç­¾
        
        Args:
            original_text: è¯„è®ºåŸæ–‡ï¼ˆè‹±æ–‡ï¼‰
            translated_text: [DEPRECATED] ä¸å†ä½¿ç”¨ï¼Œä¿ç•™ä»…ä¸ºå‘åå…¼å®¹
            context_schema: å¯é€‰çš„ 5W æ ‡ç­¾åº“ï¼Œæ ¼å¼ï¼š
                {
                    "who": [{"name": "è€å¹´äºº", "description": "..."}, ...],
                    "where": [...],
                    ...
                }
                
        Returns:
            æå–çš„ä¸»é¢˜å†…å®¹ï¼Œæ ¼å¼ï¼š
            - å¼€æ”¾æ¨¡å¼ï¼š{"who": [{"content": "ä¸­æ–‡å†…å®¹", "content_original": "English quote", ...}], ...}
            - å½’ç±»æ¨¡å¼ï¼š{"who": [{"content": "è€å¹´äºº", "quote": "English quote", ...}], ...}
        """
        if not self._check_client():
            return {}
        
        # [UPDATED] ä½¿ç”¨åŸæ–‡æ£€æŸ¥é•¿åº¦ï¼Œè·³è¿‡è¿‡çŸ­çš„è¯„è®º
        if not original_text or len(original_text.strip()) < 10:
            return {}
        
        # [UPDATED] Valid theme types for 5W model (2026-01-14: æ·»åŠ  buyer/user æ‹†åˆ†)
        valid_themes = {"buyer", "user", "who", "where", "when", "why", "what"}
        
        try:
            # æ ¹æ®æ˜¯å¦æœ‰æ ‡ç­¾åº“é€‰æ‹©ä¸åŒçš„ Prompt
            # [UPDATED] è·¨è¯­è¨€æ¨¡å¼ï¼šåªä¼ å…¥è‹±æ–‡åŸæ–‡ï¼ŒAI è¾“å‡ºä¸­æ–‡åˆ†æ
            if context_schema and any(context_schema.get(t) for t in valid_themes):
                # å¼ºåˆ¶å½’ç±»æ¨¡å¼ - ä½¿ç”¨æ ‡ç­¾åº“
                schema_lines = []
                for theme_type in valid_themes:
                    labels = context_schema.get(theme_type, [])
                    if labels:
                        label_names = [l["name"] for l in labels if isinstance(l, dict) and l.get("name")]
                        if label_names:
                            schema_lines.append(f"- **{theme_type}**: {', '.join(label_names)}")
                
                schema_str = "\n".join(schema_lines) if schema_lines else "ï¼ˆæ— æ ‡ç­¾åº“ï¼‰"
                
                prompt = THEME_EXTRACTION_PROMPT_WITH_SCHEMA.format(
                    original_text=original_text or "",
                    schema_str=schema_str
                )
                logger.debug(f"[è·¨è¯­è¨€5W] ä½¿ç”¨å¼ºåˆ¶å½’ç±»æ¨¡å¼ï¼Œæ ‡ç­¾åº“åŒ…å« {len(schema_lines)} ä¸ªç±»å‹")
            else:
                # å¼€æ”¾æå–æ¨¡å¼ - è‡ªç”±æå–
                prompt = THEME_EXTRACTION_PROMPT.format(
                    original_text=original_text or ""
                )
                logger.debug("[è·¨è¯­è¨€5W] ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                max_tokens=2000,
                timeout=60.0,
            )
            
            result = response.choices[0].message.content.strip()
            
            # [UPDATED] Use robust JSON parser
            themes = parse_json_safely(result)
            
            if not isinstance(themes, dict):
                logger.warning(f"Parsed themes is not a dict: {type(themes)}")
                return {}
            
            # æ ¹æ®æ¨¡å¼å¤„ç†è¿”å›ç»“æœ
            valid_result = {}
            
            if context_schema and any(context_schema.get(t) for t in valid_themes):
                # [UPDATED] å¼ºåˆ¶å½’ç±»æ¨¡å¼ - æ”¯æŒå¸¦è¯æ®çš„å¯è§£é‡Šå½’ç±»
                # æ–°æ ¼å¼: {"tag": "è€å¹´äºº", "quote": "...", "explanation": "..."}
                for theme_type in valid_themes:
                    items = themes.get(theme_type, [])
                    if not isinstance(items, list):
                        continue
                    
                    # è·å–è¯¥ç±»å‹å…è®¸çš„æ ‡ç­¾
                    allowed_labels = {
                        l["name"] for l in context_schema.get(theme_type, []) 
                        if isinstance(l, dict) and l.get("name")
                    }
                    
                    valid_items = []
                    for item in items:
                        if isinstance(item, dict):
                            # æ–°æ ¼å¼: å¸¦ tag/quote/quote_translated/confidence/explanation çš„å¯¹è±¡
                            tag = item.get("tag") or item.get("content")
                            if tag and tag.strip() in allowed_labels:
                                # [UPDATED 2026-01-15] æ·»åŠ  confidence å­—æ®µæ”¯æŒ
                                confidence = item.get("confidence", "high")
                                # éªŒè¯ confidence å€¼
                                if confidence not in ("high", "medium", "low"):
                                    confidence = "high"
                                valid_items.append({
                                    "content": tag.strip(),  # æ ‡å‡†æ ‡ç­¾å
                                    "content_original": item.get("quote") or item.get("content_original"),  # åŸæ–‡è¯æ®
                                    "quote_translated": item.get("quote_translated"),  # [NEW] ä¸­æ–‡ç¿»è¯‘è¯æ®
                                    "content_translated": item.get("content_translated"),  # ç¿»è¯‘ï¼ˆå¯é€‰ï¼Œå‘åå…¼å®¹ï¼‰
                                    "explanation": item.get("explanation"),  # å½’ç±»ç†ç”±
                                    "confidence": confidence  # [NEW] ç½®ä¿¡åº¦
                                })
                        elif isinstance(item, str):
                            # å…¼å®¹æ—§æ ¼å¼: çº¯å­—ç¬¦ä¸²
                            if item.strip() in allowed_labels:
                                valid_items.append({
                                    "content": item.strip(),
                                    "content_original": None,
                                    "content_translated": None,
                                    "explanation": f"å‘½ä¸­æ ‡ç­¾åº“: {item.strip()}",
                                    "confidence": "high"  # æ—§æ ¼å¼é»˜è®¤é«˜ç½®ä¿¡åº¦
                                })
                    
                    if valid_items:
                        valid_result[theme_type] = valid_items
                        logger.debug(f"  {theme_type}: {len(valid_items)} ä¸ªæ ‡ç­¾ (å¸¦è¯æ®)")
            else:
                # å¼€æ”¾æå–æ¨¡å¼ - è¿”å›çš„æ˜¯å®Œæ•´å†…å®¹é¡¹
                for theme_type, items in themes.items():
                    if theme_type not in valid_themes:
                        continue
                    if not isinstance(items, list):
                        continue
                    
                    # Validate each item
                    valid_items = []
                    for item in items:
                        if isinstance(item, dict) and "content" in item:
                            # Ensure content is a non-empty string
                            content = item.get("content", "").strip()
                            if content:
                                # [UPDATED 2026-01-15] æ·»åŠ  confidence å­—æ®µæ”¯æŒ
                                confidence = item.get("confidence", "high")
                                if confidence not in ("high", "medium", "low"):
                                    confidence = "high"
                                # Build valid item
                                valid_item = {
                                    "content": content,
                                    "content_original": item.get("content_original") or None,
                                    "content_translated": item.get("content_translated") or None,
                                    "explanation": item.get("explanation") or None,
                                    "confidence": confidence  # [NEW] ç½®ä¿¡åº¦
                                }
                                valid_items.append(valid_item)
                        elif isinstance(item, str):
                            # Backward compatibility: if item is a string, convert to new format
                            if item.strip():
                                valid_items.append({
                                    "content": item.strip(),
                                    "content_original": None,
                                    "content_translated": None,
                                    "explanation": None,
                                    "confidence": "high"  # æ—§æ ¼å¼é»˜è®¤é«˜ç½®ä¿¡åº¦
                                })
                    
                    if valid_items:
                        valid_result[theme_type] = valid_items
            
            logger.debug(f"Extracted themes: {list(valid_result.keys())}")
            return valid_result
            
        except Exception as e:
            logger.warning(f"Theme extraction failed: {e}")
            return {}


# Singleton instance
translation_service = TranslationService()
