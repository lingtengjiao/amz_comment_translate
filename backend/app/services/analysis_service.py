"""
Analysis Service - VOC äº§å“å¯¹æ¯”åˆ†ææœåŠ¡ (Optimized Comparison)

æ¶æ„ä¼˜åŒ–ï¼š
1. ä½¿ç”¨ AsyncOpenAI å¼‚æ­¥å®¢æˆ·ç«¯ï¼Œéé˜»å¡
2. åˆ†æ­¥éª¤å¤„ç†ï¼šæ¯ä¸ªäº§å“å•ç‹¬åˆ†æ -> ç”Ÿæˆç»´åº¦æ´å¯Ÿ -> åˆå¹¶å¯¹æ¯”
3. ç²¾ç®€æ•°æ®ï¼šä¿ç•™ Top 20 æ ‡ç­¾ï¼ˆç¡®ä¿åˆ†ææ•°æ®å®Œæ•´æ€§ï¼‰
4. å¢å¼ºé‡è¯•ï¼štenacity è‡ªåŠ¨é‡è¯•
"""
import logging
import json
import asyncio
from uuid import UUID
from typing import List, Dict, Any, Optional

from sqlalchemy import select, desc
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from openai import AsyncOpenAI, APIConnectionError, APITimeoutError, RateLimitError

from app.models.analysis import (
    AnalysisProject, 
    AnalysisProjectItem, 
    AnalysisStatus, 
    AnalysisType
)
from app.models.product import Product
from app.services.summary_service import SummaryService
from app.core.config import settings

logger = logging.getLogger(__name__)

# åˆå§‹åŒ–å¼‚æ­¥ OpenAI å®¢æˆ·ç«¯
_async_client: Optional[AsyncOpenAI] = None

def get_async_client() -> AsyncOpenAI:
    """è·å–æˆ–åˆ›å»ºå¼‚æ­¥ OpenAI å®¢æˆ·ç«¯"""
    global _async_client
    if _async_client is None:
        if not settings.QWEN_API_KEY:
            raise ValueError("QWEN_API_KEY æœªé…ç½®")
        _async_client = AsyncOpenAI(
            api_key=settings.QWEN_API_KEY,
            base_url=settings.QWEN_API_BASE,
            timeout=60.0,  # å•ä¸ªè¯·æ±‚è¶…æ—¶
            max_retries=3   # å†…ç½®é‡è¯•
        )
    return _async_client


# ==============================================================================
# [PROMPT] VOC å¯¹æ¯”åˆ†æ Prompt
# ==============================================================================

SINGLE_PRODUCT_PROMPT = """åˆ†æäº§å“"{product_name}"çš„ç”¨æˆ·åé¦ˆæ•°æ®ï¼Œè¾“å‡ºç»“æ„åŒ–JSONã€‚

è¾“å…¥æ•°æ®ï¼š{stats_json}

é‡è¦è¯´æ˜ï¼š
- **label** å¿…é¡»æ˜¯æ•°æ®ä¸­çš„å…·ä½“æ ‡ç­¾åç§°ï¼ˆå¦‚"å„¿ç«¥"ã€"å®¶é•¿"ã€"ç„¦è™‘æ—¶"ã€"å®¶ä¸­"ã€"é€ç¤¼"ç­‰ï¼‰ï¼Œä¸è¦ç”¨"ç”¨æˆ·ç±»å‹"ã€"ä½¿ç”¨æ—¶æœº"è¿™ç§é€šç”¨è¯
- **desc** æ˜¯åŸºäºæ•°æ®å½’çº³çš„ä¸€å¥è¯æè¿°
- **count** å¿…é¡»ä»è¾“å…¥æ•°æ®çš„ count å­—æ®µè·å–

è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{{
  "product_name": "{product_name}",
  "asin": "{asin}",
  "five_w": {{
    "who": [
      {{"label": "å„¿ç«¥", "desc": "ä¸»è¦ä½¿ç”¨è€…ï¼Œç”¨äºæ„Ÿç»Ÿè®­ç»ƒ", "count": 42}},
      {{"label": "å®¶é•¿", "desc": "é‡è¦è´­ä¹°ç¾¤ä½“", "count": 30}}
    ],
    "when": [
      {{"label": "ç„¦è™‘æ—¶", "desc": "ä½¿ç”¨é¢‘ç‡æœ€é«˜", "count": 18}},
      {{"label": "å­¦ä¹ æ—¶", "desc": "ç”¨äºé›†ä¸­æ³¨æ„åŠ›", "count": 11}}
    ],
    "where": [
      {{"label": "å®¶åº­", "desc": "æœ€ä¸»è¦åœºæ™¯", "count": 37}},
      {{"label": "å­¦æ ¡", "desc": "ç”¨äºè¯¾å ‚ä¸“æ³¨åŠ›è¾…åŠ©", "count": 17}}
    ],
    "why": [
      {{"label": "æ”¹å–„è¡Œä¸º", "desc": "æ”¹å–„å¤šåŠ¨ã€å†²åŠ¨ç­‰é—®é¢˜", "count": 23}},
      {{"label": "ç¼“è§£ç„¦è™‘", "desc": "æ ¸å¿ƒéœ€æ±‚", "count": 15}}
    ],
    "what": [
      {{"label": "è§¦è§‰åˆºæ¿€", "desc": "é€šè¿‡çº¹ç†ä¿ƒè¿›æ„Ÿå®˜å‘å±•", "count": 38}},
      {{"label": "æƒ…ç»ªå®‰æŠš", "desc": "å¸®åŠ©å®‰æŠšæƒ…ç»ªæ³¢åŠ¨", "count": 19}}
    ]
  }},
  "dimensions": {{
    "pros": [
      {{"label": "ææ–™è´¨æ„Ÿ", "desc": "ç¡…èƒ¶æŸ”è½¯å®‰å…¨", "count": 31}},
      {{"label": "åŠŸèƒ½è¡¨ç°", "desc": "æœ‰æ•ˆç¼“è§£ç„¦è™‘", "count": 30}}
    ],
    "cons": [
      {{"label": "ç»“æ„ç‘•ç–µ", "desc": "è¿æ¥å¤„ä¸ç‰¢å›º", "count": 4}},
      {{"label": "ä½©æˆ´ä¸é€‚", "desc": "é•¿æ—¶é—´ä½¿ç”¨æœ‰å‹è¿«æ„Ÿ", "count": 3}}
    ],
    "suggestion": [
      {{"label": "å¢åŠ é¢œè‰²é€‰æ‹©", "desc": "ç”¨æˆ·å¸Œæœ›æœ‰æ›´å¤šé¢œè‰²æ¬¾å¼", "count": 8}},
      {{"label": "æ”¹è¿›åŒ…è£…", "desc": "å»ºè®®ä½¿ç”¨æ›´ç¯ä¿çš„åŒ…è£…", "count": 5}}
    ],
    "scenario": [
      {{"label": "è¯¾å ‚ä½¿ç”¨", "desc": "å­¦ç”Ÿåœ¨è¯¾å ‚ä¸Šä½¿ç”¨è¾…åŠ©ä¸“æ³¨", "count": 12}},
      {{"label": "é•¿é€”æ—…è¡Œ", "desc": "é£æœº/æ±½è½¦ä¸Šæ‰“å‘æ—¶é—´", "count": 7}}
    ],
    "emotion": [
      {{"label": "æƒŠå–œå¥½è¯„", "desc": "è¶…å‡ºé¢„æœŸï¼Œéå¸¸æ»¡æ„", "count": 15}},
      {{"label": "å¤±æœ›åæ§½", "desc": "è´¨é‡ä¸å¦‚é¢„æœŸï¼Œæœ‰è½å·®æ„Ÿ", "count": 6}}
    ]
  }}
}}

è¦æ±‚ï¼š
1. label å¿…é¡»ä»è¾“å…¥æ•°æ®çš„ "label" å­—æ®µä¸­æå–ï¼Œä¸è¦è‡ªå·±ç¼–é€ 
2. count å¿…é¡»ä»è¾“å…¥æ•°æ®çš„ "count" å­—æ®µè·å–ï¼Œä¿æŒåŸå§‹æ•°å€¼
3. dimensions åŒ…å«5ç±»å£ç¢‘æ´å¯Ÿï¼špros(ä¼˜åŠ¿)ã€cons(ç—›ç‚¹)ã€suggestion(ç”¨æˆ·å»ºè®®)ã€scenario(ä½¿ç”¨åœºæ™¯)ã€emotion(æƒ…ç»ªåé¦ˆ)
4. **æ•°æ®è¡¥å…¨ç­–ç•¥**ï¼šå¦‚æœæŸä¸ªç»´åº¦çš„åŸå§‹æ•°æ®ä¸ºç©ºæ•°ç»„ï¼Œè¯·æ ¹æ®ç›¸å…³ç»´åº¦æ¨æ–­å¹¶ç”Ÿæˆåˆç†å†…å®¹ï¼Œå¹¶æ ‡è®° is_inferred: trueï¼š
   - suggestion ä¸ºç©ºæ—¶ â†’ ä» cons/weakness åå‘æ¨æ–­ç”¨æˆ·æœŸæœ›çš„æ”¹è¿›å»ºè®®
   - scenario ä¸ºç©ºæ—¶ â†’ ä» where/when æ¨æ–­å…·ä½“ä½¿ç”¨åœºæ™¯æ•…äº‹
   - emotion ä¸ºç©ºæ—¶ â†’ ä» pros/cons æ¨æ–­ç”¨æˆ·æƒ…ç»ªå€¾å‘
   - æ¨æ–­ç”Ÿæˆçš„æ¡ç›®æ ¼å¼ï¼š{{"label": "xxx", "desc": "xxx", "count": 0, "is_inferred": true}}
5. éæ¨æ–­æ¡ç›®ä¸è¦æ·»åŠ  is_inferred å­—æ®µ
6. åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–æ–‡å­—
7. ç®€ä½“ä¸­æ–‡"""

DIMENSION_INSIGHT_PROMPT = """åŸºäºä»¥ä¸‹äº§å“çš„å¯¹æ¯”æ•°æ®ï¼Œä¸ºæ¯ä¸ªç»´åº¦ç”Ÿæˆæ´å¯Ÿåˆ†æã€‚

äº§å“æ•°é‡ï¼š{product_count}
äº§å“åˆ—è¡¨ï¼š
{product_summaries}

ä¸º10ä¸ªç»´åº¦ç”Ÿæˆæ´å¯Ÿï¼Œæ¯ä¸ªæ´å¯ŸåŒ…å«ï¼š
1. commonalityï¼šæ‰€æœ‰äº§å“çš„å…±æ€§ç‰¹å¾ï¼ˆ1å¥è¯ï¼‰
2. differencesï¼šæ¯ä¸ªäº§å“çš„å·®å¼‚ç‰¹ç‚¹ï¼ˆæ¯ä¸ªäº§å“1å¥è¯ï¼Œæ ‡æ³¨äº§å“åºå·ï¼‰
3. positioningï¼šæ¯ä¸ªäº§å“çš„å®šä½æ´å¯Ÿï¼ˆæ¯ä¸ªäº§å“1å¥è¯ï¼Œæ ‡æ³¨äº§å“åºå·ï¼‰

10ä¸ªç»´åº¦è¯´æ˜ï¼š
- 5Wç”¨æˆ·ç”»åƒï¼šwho(ç”¨æˆ·æ˜¯è°), when(ä½•æ—¶ä½¿ç”¨), where(åœ¨å“ªé‡Œç”¨), why(è´­ä¹°åŠ¨æœº), what(å…·ä½“ç”¨é€”)
- 5ç±»å£ç¢‘æ´å¯Ÿï¼špros(ä¼˜åŠ¿å–ç‚¹), cons(ç—›ç‚¹é—®é¢˜), suggestion(ç”¨æˆ·å»ºè®®), scenario(ä½¿ç”¨åœºæ™¯), emotion(æƒ…ç»ªåé¦ˆ)

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "dimension_insights": {{
    "who": {{
      "name": "ç”¨æˆ·æ˜¯è°",
      "commonality": "äº”æ¬¾äº§å“å‡å®šä½äºå‡å‹è§£å‹èµ›é“...",
      "differences": [
        {{"product": 1, "text": "å…¨å¹´é¾„è¦†ç›–ï¼Œå¤§ä¼—å¸‚åœºé€šç”¨å‹äº§å“"}},
        {{"product": 2, "text": "æ·±è€•ç‰¹æ®Šå„¿ç«¥å¸‚åœº"}}
      ],
      "positioning": [
        {{"product": 1, "text": "å¤§ä¼—å‡å‹å·¥å…·ï¼Œè¿½æ±‚å¸‚åœºè¦†ç›–æœ€å¤§åŒ–"}},
        {{"product": 2, "text": "åŒ»ç–—åº·å¤èµ›é“ï¼Œå»ºç«‹ä¸“ä¸šæŠ¤åŸæ²³"}}
      ]
    }},
    "when": {{ ... }},
    "where": {{ ... }},
    "why": {{ ... }},
    "what": {{ ... }},
    "pros": {{ ... }},
    "cons": {{ ... }},
    "suggestion": {{
      "name": "ç”¨æˆ·å»ºè®®",
      "commonality": "ç”¨æˆ·æ™®éæœŸæœ›äº§å“åœ¨é¢œè‰²ã€å°ºå¯¸æ–¹é¢æä¾›æ›´å¤šé€‰æ‹©...",
      "differences": [...],
      "positioning": [...]
    }},
    "scenario": {{
      "name": "ä½¿ç”¨åœºæ™¯",
      "commonality": "äº§å“åœ¨å®¶åº­å’ŒåŠå…¬åœºæ™¯å‡æœ‰è¾ƒé«˜ä½¿ç”¨é¢‘ç‡...",
      "differences": [...],
      "positioning": [...]
    }},
    "emotion": {{
      "name": "æƒ…ç»ªåé¦ˆ",
      "commonality": "æ•´ä½“ç”¨æˆ·æƒ…ç»ªåæ­£å‘ï¼Œä½†å¯¹è´¨é‡é—®é¢˜ååº”å¼ºçƒˆ...",
      "differences": [...],
      "positioning": [...]
    }}
  }}
}}

è¦æ±‚ï¼š
1. åŸºäºå®é™…æ•°æ®åˆ†æï¼Œä¸è¦ç¼–é€ 
2. å·®å¼‚å’Œå®šä½æ´å¯Ÿçš„äº§å“åºå·ä»1å¼€å§‹
3. æ´å¯Ÿè¦æœ‰å•†ä¸šä»·å€¼ï¼Œå¸®åŠ©ç†è§£ç«äº‰æ ¼å±€
4. åªè¾“å‡ºJSONï¼Œç®€ä½“ä¸­æ–‡"""

STRATEGY_SUMMARY_PROMPT = """åŸºäºä»¥ä¸‹äº§å“å¯¹æ¯”åˆ†æï¼Œç”Ÿæˆç«å“ç­–ç•¥æ€»ç»“ã€‚

äº§å“æ•°é‡ï¼š{product_count}
äº§å“åˆ—è¡¨ï¼š
{product_summaries}

è¾“å‡ºJSONæ ¼å¼ï¼š
{{
  "market_summary": "æ•´ä½“å¸‚åœºæ¦‚è¿°ï¼ˆ100å­—å†…ï¼‰",
  "strategy_summary": {{
    "market_positioning": {{
      "title": "å¸‚åœºå®šä½ç­–ç•¥",
      "emoji": "ğŸ¯",
      "content": "åˆ†æå„äº§å“çš„å¸‚åœºå®šä½å·®å¼‚å’Œç«äº‰ç­–ç•¥ï¼ˆ150å­—å†…ï¼‰"
    }},
    "scenario_deep_dive": {{
      "title": "åœºæ™¯åŒ–æ·±è€•",
      "emoji": "ğŸ’¼",
      "content": "åˆ†æå„äº§å“åœ¨ä½¿ç”¨åœºæ™¯å’Œæ—¶æœºä¸Šçš„å·®å¼‚åŒ–ç­–ç•¥ï¼ˆ150å­—å†…ï¼‰"
    }},
    "growth_opportunities": {{
      "title": "å¢é•¿æœºä¼šç‚¹",
      "emoji": "âš¡",
      "content": "åŸºäºåˆ†æè¯†åˆ«çš„å¸‚åœºæœºä¼šå’Œå¢é•¿å»ºè®®ï¼ˆ150å­—å†…ï¼‰"
    }}
  }}
}}

è¦æ±‚ï¼š
1. åŸºäº10ç»´åˆ†ææ•°æ®è¿›è¡Œå½’çº³ï¼ˆ5Wç”¨æˆ·ç”»åƒ + 5ç±»å£ç¢‘æ´å¯Ÿï¼‰
2. å†…å®¹è¦æœ‰å•†ä¸šæ´å¯Ÿä»·å€¼
3. ä½¿ç”¨äº§å“åºå·æ ‡æ³¨å…·ä½“å»ºè®®
4. åªè¾“å‡ºJSONï¼Œç®€ä½“ä¸­æ–‡"""


class AnalysisService:
    """
    VOC äº§å“å¯¹æ¯”åˆ†ææœåŠ¡
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
        self.summary_service = SummaryService(db)

    # ==========================================
    # é¡¹ç›®ç®¡ç†
    # ==========================================
    
    async def create_comparison_project(
        self, 
        title: str, 
        product_ids: List[UUID],
        description: Optional[str] = None,
        role_labels: Optional[List[str]] = None 
    ) -> AnalysisProject:
        """åˆ›å»ºåˆ†æé¡¹ç›®"""
        if len(product_ids) < 2:
            raise ValueError("è‡³å°‘éœ€è¦ 2 ä¸ªäº§å“")
        
        if len(product_ids) > 5:
            raise ValueError("æœ€å¤šæ”¯æŒ 5 ä¸ªäº§å“")

        stmt = select(Product).where(Product.id.in_(product_ids))
        result = await self.db.execute(stmt)
        products = result.scalars().all()
        
        if len(products) != len(product_ids):
            found_ids = {p.id for p in products}
            missing_ids = [pid for pid in product_ids if pid not in found_ids]
            raise ValueError(f"éƒ¨åˆ†äº§å“ä¸å­˜åœ¨: {missing_ids}")

        project = AnalysisProject(
            title=title,
            description=description,
            analysis_type=AnalysisType.COMPARISON.value,
            status=AnalysisStatus.PENDING.value
        )
        self.db.add(project)
        await self.db.flush()

        for i, pid in enumerate(product_ids):
            if role_labels and i < len(role_labels):
                label = role_labels[i]
            else:
                label = f"Product {i + 1}"
            
            item = AnalysisProjectItem(
                project_id=project.id,
                product_id=pid,
                role_label=label,
                display_order=i
            )
            self.db.add(item)
        
        await self.db.commit()
        await self.db.refresh(project)
        return project

    async def get_project(self, project_id: UUID) -> Optional[AnalysisProject]:
        """è·å–é¡¹ç›®è¯¦æƒ…"""
        stmt = (
            select(AnalysisProject)
            .options(selectinload(AnalysisProject.items).selectinload(AnalysisProjectItem.product))
            .where(AnalysisProject.id == project_id)
        )
        result = await self.db.execute(stmt)
        return result.scalar_one_or_none()

    async def list_projects(
        self, 
        limit: int = 20, 
        offset: int = 0,
        status: Optional[str] = None
    ) -> List[AnalysisProject]:
        """è·å–é¡¹ç›®åˆ—è¡¨"""
        stmt = (
            select(AnalysisProject)
            .options(selectinload(AnalysisProject.items).selectinload(AnalysisProjectItem.product))
            .order_by(desc(AnalysisProject.created_at))
            .limit(limit)
            .offset(offset)
        )
        
        if status:
            stmt = stmt.where(AnalysisProject.status == status)
        
        result = await self.db.execute(stmt)
        return list(result.scalars().all())

    async def delete_project(self, project_id: UUID) -> bool:
        """åˆ é™¤é¡¹ç›®"""
        project = await self.db.get(AnalysisProject, project_id)
        if not project:
            return False
        
        await self.db.delete(project)
        await self.db.commit()
        return True

    # ==========================================
    # æ ¸å¿ƒåˆ†æé€»è¾‘ (Full Structuring)
    # ==========================================
    
    async def run_analysis(self, project_id: UUID) -> AnalysisProject:
        """
        æ‰§è¡Œ VOC å¯¹æ¯”åˆ†æ
        
        ä¼˜åŒ–æ¶æ„ï¼š
        1. ä½¿ç”¨ AsyncOpenAI å¼‚æ­¥å®¢æˆ·ç«¯
        2. æ¯ä¸ªäº§å“ç‹¬ç«‹åˆ†æï¼ˆå°è¯·æ±‚ï¼Œç¨³å®šï¼‰
        3. å¹¶è¡Œè°ƒç”¨ AIï¼ˆå¤šäº§å“åŒæ—¶åˆ†æï¼‰
        4. ç”Ÿæˆç»´åº¦æ´å¯Ÿå’Œç­–ç•¥æ€»ç»“
        """
        project = await self.get_project(project_id)
        if not project or not project.items:
            raise ValueError("é¡¹ç›®æ— æ•ˆ")

        try:
            # æ›´æ–°çŠ¶æ€
            project.status = AnalysisStatus.PROCESSING.value
            await self.db.commit()

            # 1. æ”¶é›†äº§å“æ•°æ®ï¼ˆé¡ºåºï¼Œå› ä¸º SQLAlchemy é™åˆ¶ï¼‰
            products_info = []
            product_data_map = {}
            product_count = len(project.items)  # è·å–äº§å“æ€»æ•°ï¼Œç”¨äºåŠ¨æ€è°ƒæ•´æ ‡ç­¾æ•°é‡
            
            for item in project.items:
                res = await self._fetch_product_data(item, product_count=product_count)
                products_info.append(res)
                product_data_map[res['name']] = res['data']
                product_data_map[res['name']]['asin'] = res['asin']
            
            # ä¿å­˜å¿«ç…§
            project.raw_data_snapshot = product_data_map
            await self.db.commit()
            
            # 2. è·å–å¼‚æ­¥å®¢æˆ·ç«¯
            client = get_async_client()
            
            # 3. å¹¶è¡Œåˆ†ææ¯ä¸ªäº§å“
            logger.info(f"å¼€å§‹å¹¶è¡Œåˆ†æ {len(products_info)} ä¸ªäº§å“...")
            
            async def analyze_single_product(info: Dict[str, Any], max_retries: int = 3) -> Dict[str, Any]:
                """åˆ†æå•ä¸ªäº§å“ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼Œç¡®ä¿ç¨³å¥æ€§ï¼‰"""
                prompt = SINGLE_PRODUCT_PROMPT.format(
                    product_name=info['name'],
                    asin=info['asin'],
                    stats_json=json.dumps(info['data'], ensure_ascii=False)
                )
                
                last_error = None
                for attempt in range(max_retries):
                    try:
                        response = await client.chat.completions.create(
                            model=settings.QWEN_ANALYSIS_MODEL,
                            messages=[
                                {"role": "system", "content": "è¾“å‡ºçº¯JSONï¼Œç®€ä½“ä¸­æ–‡ã€‚"},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0.3,
                            max_tokens=4000,  # å¢åŠ  token é™åˆ¶ï¼Œç¡®ä¿å®Œæ•´è¾“å‡º
                            response_format={"type": "json_object"}
                        )
                        
                        content = response.choices[0].message.content
                        result = json.loads(content.replace("```json", "").replace("```", "").strip())
                        
                        # éªŒè¯ç»“æœå®Œæ•´æ€§
                        if not result.get("five_w") or not result.get("dimensions"):
                            raise ValueError("AI è¿”å›çš„æ•°æ®ç»“æ„ä¸å®Œæ•´")
                        
                        return result
                        
                    except json.JSONDecodeError as e:
                        last_error = e
                        logger.warning(f"äº§å“ {info['asin']} ç¬¬ {attempt+1}/{max_retries} æ¬¡ JSON è§£æå¤±è´¥: {e}")
                        if attempt < max_retries - 1:
                            await asyncio.sleep(2 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                    except Exception as e:
                        last_error = e
                        logger.warning(f"äº§å“ {info['asin']} ç¬¬ {attempt+1}/{max_retries} æ¬¡åˆ†æå¤±è´¥: {e}")
                        if attempt < max_retries - 1:
                            await asyncio.sleep(2 * (attempt + 1))
                
                # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åçš„é”™è¯¯
                raise last_error or Exception("æœªçŸ¥é”™è¯¯")
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰äº§å“åˆ†æ
            product_profiles = await asyncio.gather(
                *[analyze_single_product(info) for info in products_info],
                return_exceptions=True
            )
            
            # è¿‡æ»¤é”™è¯¯å¹¶æ·»åŠ  image_url
            valid_profiles = []
            for i, result in enumerate(product_profiles):
                if isinstance(result, Exception):
                    logger.error(f"äº§å“ {i+1} åˆ†æå¤±è´¥: {result}")
                    # åˆ›å»ºç©ºçš„å ä½ç»“æœ
                    valid_profiles.append({
                        "product_name": products_info[i]['name'],
                        "asin": products_info[i]['asin'],
                        "image_url": products_info[i].get('image_url'),
                        "five_w": {"who": [], "when": [], "where": [], "why": [], "what": []},
                        "dimensions": {"pros": [], "cons": []},
                        "error": str(result)
                    })
                else:
                    # æ·»åŠ  image_url åˆ°ç»“æœä¸­
                    result["image_url"] = products_info[i].get('image_url')
                    valid_profiles.append(result)
            
            logger.info(f"äº§å“åˆ†æå®Œæˆï¼ŒæˆåŠŸ {len([p for p in valid_profiles if 'error' not in p])} ä¸ª")
            
            # 4. ç”Ÿæˆäº§å“æ‘˜è¦ç”¨äºåç»­åˆ†æ
            product_summaries = self._generate_product_summaries(valid_profiles)
            
            # 5. åˆ†æ‰¹ç”Ÿæˆç»´åº¦æ´å¯Ÿå’Œç­–ç•¥æ€»ç»“
            async def generate_dimension_insights_batch(dimensions: List[str], batch_name: str) -> Dict[str, Any]:
                """åˆ†æ‰¹ç”Ÿæˆç»´åº¦æ´å¯Ÿï¼ˆæ¯æ‰¹3-5ä¸ªç»´åº¦ï¼‰"""
                dimension_names = {
                    "who": "ç”¨æˆ·æ˜¯è°", "when": "ä½•æ—¶ä½¿ç”¨", "where": "åœ¨å“ªé‡Œç”¨",
                    "why": "è´­ä¹°åŠ¨æœº", "what": "å…·ä½“ç”¨é€”", "pros": "ä¼˜åŠ¿å–ç‚¹",
                    "cons": "ç—›ç‚¹é—®é¢˜", "suggestion": "ç”¨æˆ·å»ºè®®", 
                    "scenario": "ä½¿ç”¨åœºæ™¯", "emotion": "æƒ…ç»ªåé¦ˆ"
                }
                
                dim_list = ", ".join([f"{d}({dimension_names[d]})" for d in dimensions])
                
                batch_prompt = f"""åŸºäºä»¥ä¸‹äº§å“çš„å¯¹æ¯”æ•°æ®ï¼Œä¸ºæŒ‡å®šç»´åº¦ç”Ÿæˆæ´å¯Ÿåˆ†æã€‚

äº§å“æ•°é‡ï¼š{len(valid_profiles)}
äº§å“åˆ—è¡¨ï¼š
{product_summaries}

è¯·ä¸ºä»¥ä¸‹ç»´åº¦ç”Ÿæˆæ´å¯Ÿï¼š{dim_list}

æ¯ä¸ªç»´åº¦çš„æ´å¯ŸåŒ…å«ï¼š
1. nameï¼šç»´åº¦ä¸­æ–‡åç§°
2. commonalityï¼šæ‰€æœ‰äº§å“çš„å…±æ€§ç‰¹å¾ï¼ˆ1å¥è¯ï¼‰
3. differencesï¼šæ¯ä¸ªäº§å“çš„å·®å¼‚ç‰¹ç‚¹ï¼ˆæ•°ç»„ï¼Œæ¯é¡¹åŒ…å« product åºå·å’Œ text æè¿°ï¼‰
4. positioningï¼šæ¯ä¸ªäº§å“çš„å®šä½æ´å¯Ÿï¼ˆæ•°ç»„ï¼Œæ¯é¡¹åŒ…å« product åºå·å’Œ text æè¿°ï¼‰

è¾“å‡ºJSONæ ¼å¼ï¼ˆåªè¾“å‡ºæŒ‡å®šç»´åº¦ï¼‰ï¼š
{{
  "dimension_insights": {{
    "{dimensions[0]}": {{
      "name": "{dimension_names[dimensions[0]]}",
      "commonality": "...",
      "differences": [{{"product": 1, "text": "..."}}, ...],
      "positioning": [{{"product": 1, "text": "..."}}, ...]
    }},
    ...
  }}
}}

è¦æ±‚ï¼šç®€ä½“ä¸­æ–‡ï¼Œåªè¾“å‡ºJSONã€‚"""

                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        logger.info(f"ç”Ÿæˆç»´åº¦æ´å¯Ÿæ‰¹æ¬¡ [{batch_name}]: {dimensions}")
                        response = await client.chat.completions.create(
                            model=settings.QWEN_ANALYSIS_MODEL,
                            messages=[
                                {"role": "system", "content": "è¾“å‡ºçº¯JSONï¼Œç®€ä½“ä¸­æ–‡ã€‚"},
                                {"role": "user", "content": batch_prompt}
                            ],
                            temperature=0.3,
                            max_tokens=2500,  # æ¯æ‰¹åªéœ€è¦è¾ƒå°‘çš„ token
                            response_format={"type": "json_object"}
                        )
                        
                        content = response.choices[0].message.content
                        logger.info(f"ç»´åº¦æ´å¯Ÿæ‰¹æ¬¡ [{batch_name}] å“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
                        
                        result = json.loads(content.replace("```json", "").replace("```", "").strip())
                        return result.get("dimension_insights", {})
                    except json.JSONDecodeError as e:
                        logger.error(f"ç»´åº¦æ´å¯Ÿæ‰¹æ¬¡ [{batch_name}] JSON è§£æå¤±è´¥: {e}")
                        return {}
                    except Exception as e:
                        logger.warning(f"ç»´åº¦æ´å¯Ÿæ‰¹æ¬¡ [{batch_name}] å°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
                        if attempt < max_retries - 1:
                            await asyncio.sleep(3 * (attempt + 1))
                        else:
                            logger.error(f"ç»´åº¦æ´å¯Ÿæ‰¹æ¬¡ [{batch_name}] æœ€ç»ˆå¤±è´¥: {e}")
                            return {}
            
            async def generate_all_dimension_insights() -> Dict[str, Any]:
                """åˆ†3æ‰¹ç”Ÿæˆæ‰€æœ‰10ä¸ªç»´åº¦çš„æ´å¯Ÿ"""
                # å°†10ä¸ªç»´åº¦åˆ†æˆ3æ‰¹ï¼š5Wç”»åƒ(5ä¸ª) + æ­£é¢å£ç¢‘(2ä¸ª) + è´Ÿé¢/å»ºè®®å£ç¢‘(3ä¸ª)
                batches = [
                    (["who", "when", "where", "why", "what"], "5Wç”¨æˆ·ç”»åƒ"),
                    (["pros", "cons"], "ä¼˜åŠ¿ç—›ç‚¹"),
                    (["suggestion", "scenario", "emotion"], "å»ºè®®åœºæ™¯æƒ…ç»ª"),
                ]
                
                all_insights = {}
                for dimensions, batch_name in batches:
                    batch_result = await generate_dimension_insights_batch(dimensions, batch_name)
                    all_insights.update(batch_result)
                    # æ‰¹æ¬¡ä¹‹é—´ç¨ä½œåœé¡¿ï¼Œé¿å… API é™æµ
                    await asyncio.sleep(1)
                
                logger.info(f"ç»´åº¦æ´å¯Ÿç”Ÿæˆå®Œæˆï¼Œå…± {len(all_insights)} ä¸ªç»´åº¦")
                return {"dimension_insights": all_insights}
            
            async def generate_strategy_summary() -> Dict[str, Any]:
                """ç”Ÿæˆç­–ç•¥æ€»ç»“ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
                prompt = STRATEGY_SUMMARY_PROMPT.format(
                    product_count=len(valid_profiles),
                    product_summaries=product_summaries
                )
                
                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        response = await client.chat.completions.create(
                            model=settings.QWEN_ANALYSIS_MODEL,
                            messages=[
                                {"role": "system", "content": "è¾“å‡ºçº¯JSONï¼Œç®€ä½“ä¸­æ–‡ã€‚"},
                                {"role": "user", "content": prompt}
                            ],
                            temperature=0.3,
                            max_tokens=1500,
                            response_format={"type": "json_object"}
                        )
                        
                        content = response.choices[0].message.content
                        return json.loads(content.replace("```json", "").replace("```", "").strip())
                    except Exception as e:
                        logger.warning(f"ç­–ç•¥æ€»ç»“ç”Ÿæˆå°è¯• {attempt + 1}/{max_retries} å¤±è´¥: {e}")
                        if attempt < max_retries - 1:
                            await asyncio.sleep(5 * (attempt + 1))  # æŒ‡æ•°é€€é¿
                        else:
                            logger.error(f"ç­–ç•¥æ€»ç»“ç”Ÿæˆæœ€ç»ˆå¤±è´¥: {e}")
                            return {"market_summary": "", "strategy_summary": {}}
            
            # å¹¶è¡Œæ‰§è¡Œæ´å¯Ÿå’Œæ€»ç»“ç”Ÿæˆ
            insights_result, strategy_result = await asyncio.gather(
                generate_all_dimension_insights(),
                generate_strategy_summary(),
                return_exceptions=True
            )
            
            # å¤„ç†ç»“æœ
            dimension_insights = {}
            if isinstance(insights_result, Exception):
                logger.error(f"ç»´åº¦æ´å¯Ÿç”Ÿæˆå¤±è´¥: {insights_result}")
            else:
                dimension_insights = insights_result.get("dimension_insights", {})
            
            strategy_summary = {}
            market_summary = ""
            if isinstance(strategy_result, Exception):
                logger.error(f"ç­–ç•¥æ€»ç»“ç”Ÿæˆå¤±è´¥: {strategy_result}")
            else:
                market_summary = strategy_result.get("market_summary", "")
                strategy_summary = strategy_result.get("strategy_summary", {})
            
            # 6. ç»„è£…æœ€ç»ˆç»“æœ
            result_data = {
                "product_profiles": valid_profiles,
                "dimension_insights": dimension_insights,
                "market_summary": market_summary,
                "strategy_summary": strategy_summary
            }
            
            project.result_content = result_data
            project.status = AnalysisStatus.COMPLETED.value
            project.error_message = None
            
            logger.info(f"å¯¹æ¯”åˆ†æå®Œæˆ: {project_id}")
            
        except Exception as e:
            logger.error(f"Analysis Error: {e}", exc_info=True)
            project.status = AnalysisStatus.FAILED.value
            project.error_message = str(e)
        
        await self.db.commit()
        await self.db.refresh(project)
        return project

    def _generate_product_summaries(self, profiles: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆäº§å“æ‘˜è¦ç”¨äºåç»­ promptï¼ˆ10ç»´ï¼‰"""
        summaries = []
        for i, p in enumerate(profiles, 1):
            name = p.get("product_name", f"äº§å“{i}")
            asin = p.get("asin", "")
            
            # æå–å…³é”®æ ‡ç­¾ - 5Wç”¨æˆ·ç”»åƒ
            five_w = p.get("five_w", {})
            who_tags = [t.get("label", "") for t in five_w.get("who", [])[:3]]
            when_tags = [t.get("label", "") for t in five_w.get("when", [])[:3]]
            where_tags = [t.get("label", "") for t in five_w.get("where", [])[:3]]
            why_tags = [t.get("label", "") for t in five_w.get("why", [])[:3]]
            what_tags = [t.get("label", "") for t in five_w.get("what", [])[:3]]
            
            # æå–å…³é”®æ ‡ç­¾ - 5ç±»å£ç¢‘æ´å¯Ÿ
            dims = p.get("dimensions", {})
            pros_tags = [t.get("label", "") for t in dims.get("pros", [])[:3]]
            cons_tags = [t.get("label", "") for t in dims.get("cons", [])[:3]]
            suggestion_tags = [t.get("label", "") for t in dims.get("suggestion", [])[:3]]
            scenario_tags = [t.get("label", "") for t in dims.get("scenario", [])[:3]]
            emotion_tags = [t.get("label", "") for t in dims.get("emotion", [])[:3]]
            
            summary = f"""äº§å“{i}: {name} ({asin})
  ã€5Wç”¨æˆ·ç”»åƒã€‘
  - ç”¨æˆ·(Who): {', '.join(who_tags) or 'æ— æ•°æ®'}
  - æ—¶æœº(When): {', '.join(when_tags) or 'æ— æ•°æ®'}
  - åœºæ™¯(Where): {', '.join(where_tags) or 'æ— æ•°æ®'}
  - åŠ¨æœº(Why): {', '.join(why_tags) or 'æ— æ•°æ®'}
  - ç”¨é€”(What): {', '.join(what_tags) or 'æ— æ•°æ®'}
  ã€5ç±»å£ç¢‘æ´å¯Ÿã€‘
  - ä¼˜åŠ¿(Pros): {', '.join(pros_tags) or 'æ— æ•°æ®'}
  - ç—›ç‚¹(Cons): {', '.join(cons_tags) or 'æ— æ•°æ®'}
  - å»ºè®®(Suggestion): {', '.join(suggestion_tags) or 'æ— æ•°æ®'}
  - åœºæ™¯(Scenario): {', '.join(scenario_tags) or 'æ— æ•°æ®'}
  - æƒ…ç»ª(Emotion): {', '.join(emotion_tags) or 'æ— æ•°æ®'}"""
            summaries.append(summary)
        
        return "\n\n".join(summaries)

    async def _fetch_product_data(self, item: AnalysisProjectItem, product_count: int = 1) -> Dict[str, Any]:
        """
        [Helper] å¼‚æ­¥è·å–å•ä¸ªäº§å“çš„å…¨é‡æ•°æ®
        
        Args:
            item: åˆ†æé¡¹ç›®æ¡ç›®
            product_count: æ€»äº§å“æ•°é‡ï¼ˆç”¨äºåŠ¨æ€è°ƒæ•´æ ‡ç­¾æ•°é‡ï¼‰
        """
        product = item.product
        
        # æ„å»ºå®‰å…¨çš„äº§å“åç§°
        raw_name = product.title_translated or product.title or product.asin
        safe_name = raw_name[:30].replace('"', '').replace("'", "").strip() + f" ({product.asin[-4:]})"
        
        # èšåˆæ ¸å¿ƒæ•°æ® (5W + Insight)
        context_stats = await self.summary_service._aggregate_5w_stats(product.id)
        insight_stats = await self.summary_service._aggregate_insight_stats(product.id)
        
        return {
            "name": safe_name,
            "asin": product.asin,
            "image_url": product.image_url,
            "data": {
                "user_context": self._simplify_stats(context_stats, product_count=product_count),
                "key_insights": self._simplify_stats(insight_stats, product_count=product_count)
            }
        }

    def _simplify_stats(self, data: Dict[str, Any], max_items: int = 15, product_count: int = 1) -> Dict[str, List[Dict[str, Any]]]:
        """
        ç²¾ç®€æ•°æ®ï¼šæ¯ç±»åªä¿ç•™ Top Nï¼Œåªä¿ç•™ label å’Œ count
        
        åŠ¨æ€è°ƒæ•´ç­–ç•¥ï¼ˆç¡®ä¿ Token ä¸è¶…é™ï¼‰ï¼š
        - 2ä¸ªäº§å“: æ¯ç»´åº¦æœ€å¤š 20 ä¸ªæ ‡ç­¾
        - 3ä¸ªäº§å“: æ¯ç»´åº¦æœ€å¤š 15 ä¸ªæ ‡ç­¾
        - 4-5ä¸ªäº§å“: æ¯ç»´åº¦æœ€å¤š 12 ä¸ªæ ‡ç­¾
        """
        # æ ¹æ®äº§å“æ•°é‡åŠ¨æ€è°ƒæ•´æ ‡ç­¾æ•°é‡
        if product_count <= 2:
            max_items = 20
        elif product_count == 3:
            max_items = 15
        else:
            max_items = 12
        simplified = {}
        
        for category, content in data.items():
            if not isinstance(content, dict): 
                continue
            
            items = content.get("items", [])
            # åªä¿ç•™å¿…è¦å­—æ®µï¼Œå‡å°‘ Token
            simplified[category] = [
                {"label": item.get("name"), "count": item.get("value")}
                for item in items[:max_items]
                if isinstance(item, dict)
            ]
        
        return simplified

    # ==========================================
    # é¢„è§ˆåŠŸèƒ½
    # ==========================================
    
    async def get_comparison_preview(self, product_ids: List[UUID]) -> Dict[str, Any]:
        """
        è·å–å¯¹æ¯”é¢„è§ˆæ•°æ®ï¼ˆä¸è°ƒç”¨ AIï¼Œä»…è¿”å›èšåˆæ•°æ®ï¼‰
        """
        if len(product_ids) < 2:
            raise ValueError("å¯¹æ¯”åˆ†æè‡³å°‘éœ€è¦ 2 ä¸ªäº§å“")
        
        preview_data = {}
        
        for pid in product_ids:
            product = await self.db.get(Product, pid)
            if not product:
                continue
            
            total_reviews = await self.summary_service._count_translated_reviews(pid)
            
            preview_data[str(pid)] = {
                "product": {
                    "id": str(product.id),
                    "asin": product.asin,
                    "title": product.title_translated or product.title,
                    "image_url": product.image_url,
                    "marketplace": product.marketplace
                },
                "total_reviews": total_reviews,
                "ready": total_reviews > 0
            }
        
        return {
            "success": True,
            "products": preview_data,
            "can_compare": len(preview_data) >= 2 and all(p.get("ready", False) for p in preview_data.values())
        }
