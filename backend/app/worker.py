"""
Celery Worker Configuration and Tasks

This module handles asynchronous processing of reviews:
1. Translation via Qwen API
2. Sentiment analysis
3. Database updates
"""
import logging
import time
from typing import Optional

from celery import Celery
from sqlalchemy import create_engine, select, update, and_, func
from sqlalchemy.orm import sessionmaker

from app.core.config import settings

logger = logging.getLogger(__name__)

# Create Celery application
celery_app = Celery(
    "voc_worker",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL,
)

# Celery configuration
celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,
    task_track_started=True,
    task_time_limit=1800,  # 30 minutes timeout per task (increased from 600s to handle large batches)
    task_soft_time_limit=1500,  # 25 minutes soft limit (warning before hard kill)
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    task_routes={
        # å››ä¸ªç‹¬ç«‹çš„ AI æœåŠ¡ä»»åŠ¡
        "app.worker.task_translate_bullet_points": {"queue": "translation"},  # äº”ç‚¹ç¿»è¯‘
        "app.worker.task_process_reviews": {"queue": "translation"},           # è¯„è®ºç¿»è¯‘
        "app.worker.task_extract_insights": {"queue": "translation"},          # æ´å¯Ÿæå–
        "app.worker.task_extract_themes": {"queue": "translation"},            # ä¸»é¢˜æå–
    },
)

# Synchronous database connection for Celery worker
# (Celery doesn't support async well, so we use sync SQLAlchemy)
SYNC_DATABASE_URL = settings.DATABASE_URL.replace("+asyncpg", "")
sync_engine = create_engine(SYNC_DATABASE_URL, echo=settings.DEBUG)
SyncSession = sessionmaker(bind=sync_engine)


def get_sync_db():
    """Get synchronous database session for worker."""
    return SyncSession()


# ============== Worker å¯åŠ¨æ—¶æ¸…ç†å¡ä½çš„ä»»åŠ¡ ==============

def cleanup_stuck_reviews():
    """
    æ¸…ç†å¡åœ¨ 'processing' çŠ¶æ€çš„è¯„è®ºã€‚
    å½“ Worker é‡å¯æ—¶ï¼Œä¹‹å‰æ­£åœ¨å¤„ç†çš„è¯„è®ºå¯èƒ½ä¼šå¡åœ¨ processing çŠ¶æ€ã€‚
    è¿™ä¸ªå‡½æ•°å°†å®ƒä»¬é‡ç½®ä¸º pendingï¼Œè®©å®ƒä»¬å¯ä»¥è¢«é‡æ–°å¤„ç†ã€‚
    """
    from app.models.review import Review
    
    db = get_sync_db()
    try:
        result = db.execute(
            update(Review)
            .where(Review.translation_status == "processing")
            .values(translation_status="pending")
        )
        db.commit()
        
        if result.rowcount > 0:
            logger.warning(f"[å¯åŠ¨æ¸…ç†] å·²å°† {result.rowcount} æ¡å¡ä½çš„è¯„è®ºé‡ç½®ä¸º pending çŠ¶æ€")
        else:
            logger.info("[å¯åŠ¨æ¸…ç†] æ²¡æœ‰å‘ç°å¡ä½çš„è¯„è®º")
    except Exception as e:
        logger.error(f"[å¯åŠ¨æ¸…ç†] æ¸…ç†å¡ä½è¯„è®ºå¤±è´¥: {e}")
        db.rollback()
    finally:
        db.close()


def cleanup_stuck_tasks():
    """
    æ¸…ç†å¡ä½çš„ä»»åŠ¡ï¼ˆå¿ƒè·³è¶…æ—¶ï¼‰ã€‚
    å°† PROCESSING çŠ¶æ€ä½†å¿ƒè·³è¶…æ—¶çš„ä»»åŠ¡æ ‡è®°ä¸º TIMEOUTã€‚
    """
    from app.models.task import Task, TaskStatus
    from datetime import datetime, timezone, timedelta
    
    db = get_sync_db()
    try:
        # æŸ¥æ‰¾æ‰€æœ‰ processing çŠ¶æ€çš„ä»»åŠ¡
        result = db.execute(
            select(Task).where(Task.status == TaskStatus.PROCESSING.value)
        )
        tasks = result.scalars().all()
        
        timeout_count = 0
        for task in tasks:
            if task.is_heartbeat_timeout:
                task.status = TaskStatus.TIMEOUT.value
                task.error_message = f"å¿ƒè·³è¶…æ—¶ï¼šæœ€åå¿ƒè·³æ—¶é—´ {task.last_heartbeat}"
                timeout_count += 1
                logger.warning(f"[å¯åŠ¨æ¸…ç†] ä»»åŠ¡ {task.id} ({task.task_type}) å¿ƒè·³è¶…æ—¶ï¼Œæ ‡è®°ä¸º TIMEOUT")
        
        if timeout_count > 0:
            db.commit()
            logger.warning(f"[å¯åŠ¨æ¸…ç†] å·²å°† {timeout_count} ä¸ªè¶…æ—¶ä»»åŠ¡æ ‡è®°ä¸º TIMEOUT")
        else:
            logger.info("[å¯åŠ¨æ¸…ç†] æ²¡æœ‰å‘ç°å¿ƒè·³è¶…æ—¶çš„ä»»åŠ¡")
            
    except Exception as e:
        logger.error(f"[å¯åŠ¨æ¸…ç†] æ¸…ç†è¶…æ—¶ä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()
    finally:
        db.close()


# ============== å¿ƒè·³æ›´æ–°è¾…åŠ©å‡½æ•° ==============

def update_task_heartbeat(db, task_id: str, processed_items: int = None):
    """
    æ›´æ–°ä»»åŠ¡å¿ƒè·³æ—¶é—´ã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        task_id: ä»»åŠ¡ ID
        processed_items: å¯é€‰ï¼ŒåŒæ—¶æ›´æ–°å·²å¤„ç†æ•°é‡
    """
    from app.models.task import Task
    from datetime import datetime, timezone
    
    try:
        values = {"last_heartbeat": datetime.now(timezone.utc)}
        if processed_items is not None:
            values["processed_items"] = processed_items
        
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(**values)
        )
        db.commit()
    except Exception as e:
        logger.error(f"æ›´æ–°ä»»åŠ¡å¿ƒè·³å¤±è´¥: {e}")
        db.rollback()


def get_or_create_task(db, product_id: str, task_type: str, total_items: int = 0, celery_task_id: str = None):
    """
    è·å–æˆ–åˆ›å»ºä»»åŠ¡è®°å½•ã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        product_id: äº§å“ ID
        task_type: ä»»åŠ¡ç±»å‹
        total_items: æ€»é¡¹ç›®æ•°
        celery_task_id: Celery ä»»åŠ¡ ID
        
    Returns:
        Task: ä»»åŠ¡å¯¹è±¡
    """
    from app.models.task import Task, TaskStatus
    from datetime import datetime, timezone
    
    # æŸ¥æ‰¾ç°æœ‰ä»»åŠ¡
    result = db.execute(
        select(Task).where(
            and_(
                Task.product_id == product_id,
                Task.task_type == task_type
            )
        )
    )
    task = result.scalar_one_or_none()
    
    now = datetime.now(timezone.utc)
    
    if task:
        # æ›´æ–°ç°æœ‰ä»»åŠ¡
        task.status = TaskStatus.PROCESSING.value
        task.total_items = total_items
        task.processed_items = 0
        task.last_heartbeat = now
        task.celery_task_id = celery_task_id
        task.error_message = None
    else:
        # åˆ›å»ºæ–°ä»»åŠ¡
        task = Task(
            product_id=product_id,
            task_type=task_type,
            status=TaskStatus.PROCESSING.value,
            total_items=total_items,
            processed_items=0,
            last_heartbeat=now,
            celery_task_id=celery_task_id
        )
        db.add(task)
    
    db.commit()
    db.refresh(task)
    return task


def complete_task(db, task_id: str, success: bool = True, error_message: str = None):
    """
    å®Œæˆä»»åŠ¡ã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        task_id: ä»»åŠ¡ ID
        success: æ˜¯å¦æˆåŠŸ
        error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
    """
    from app.models.task import Task, TaskStatus
    
    try:
        status = TaskStatus.COMPLETED.value if success else TaskStatus.FAILED.value
        values = {
            "status": status,
            "last_heartbeat": None  # æ¸…é™¤å¿ƒè·³ï¼Œè¡¨ç¤ºä»»åŠ¡å·²ç»“æŸ
        }
        if error_message:
            values["error_message"] = error_message
        
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(**values)
        )
        db.commit()
    except Exception as e:
        logger.error(f"å®Œæˆä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()


# ä½¿ç”¨ Celery ä¿¡å·åœ¨ Worker å¯åŠ¨æ—¶æ‰§è¡Œæ¸…ç†
from celery.signals import worker_ready

@worker_ready.connect
def on_worker_ready(**kwargs):
    """Worker å¯åŠ¨å®Œæˆåæ‰§è¡Œæ¸…ç†"""
    logger.info("Worker å·²å°±ç»ªï¼Œå¼€å§‹æ£€æŸ¥å¡ä½çš„ä»»åŠ¡...")
    cleanup_stuck_reviews()
    cleanup_stuck_tasks()  # [NEW] æ¸…ç†å¿ƒè·³è¶…æ—¶çš„ä»»åŠ¡


# ============== ä»»åŠ¡1: äº”ç‚¹ç¿»è¯‘ ==============

@celery_app.task(bind=True, max_retries=3, default_retry_delay=30)
def task_translate_bullet_points(self, product_id: str):
    """
    Translate product bullet points and title.
    This task should run FIRST, before review translation.
    
    Args:
        product_id: UUID of the product
    """
    from app.models.product import Product
    from app.services.translation import translation_service
    import json
    
    logger.info(f"Starting bullet points translation for product {product_id}")
    
    db = get_sync_db()
    
    try:
        # Get product
        result = db.execute(
            select(Product).where(Product.id == product_id)
        )
        product = result.scalar_one_or_none()
        
        if not product:
            logger.error(f"Product {product_id} not found")
            return {"success": False, "error": "Product not found"}
        
        translated_title = None
        translated_bullets = None
        
        # 1. Translate product title if not already translated
        if product.title and not product.title_translated:
            try:
                translated_title = translation_service.translate_product_title(product.title)
                product.title_translated = translated_title
                logger.info(f"Translated product title: {translated_title[:50]}...")
            except Exception as e:
                logger.error(f"Failed to translate product title: {e}")
        
        # 2. Translate bullet points if not already translated
        if product.bullet_points and not product.bullet_points_translated:
            try:
                # Parse bullet points from JSON
                bullet_points = json.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
                
                if bullet_points and len(bullet_points) > 0:
                    translated_bullets = translation_service.translate_bullet_points(bullet_points)
                    product.bullet_points_translated = json.dumps(translated_bullets, ensure_ascii=False)
                    logger.info(f"Translated {len(translated_bullets)} bullet points")
            except Exception as e:
                logger.error(f"Failed to translate bullet points: {e}")
        
        db.commit()
        
        return {
            "success": True,
            "product_id": product_id,
            "title_translated": translated_title is not None,
            "bullet_points_translated": translated_bullets is not None
        }
        
    except Exception as e:
        logger.error(f"Bullet points translation failed for product {product_id}: {e}")
        db.rollback()
        raise self.retry(exc=e)
        
    finally:
        db.close()


# ============== ä»»åŠ¡2: è¯„è®ºç¿»è¯‘ ==============

@celery_app.task(bind=True, max_retries=3, default_retry_delay=60)
def task_process_reviews(self, product_id: str, task_id: str):
    """
    Async task to process and translate reviews.
    
    Workflow:
    1. Get pending reviews from database
    2. For each review:
       a. Call Qwen API for translation
       b. Analyze sentiment
       c. Extract insights (æ·±åº¦è§£è¯»)
       d. Update database
       e. Update task progress
    3. Mark task as completed
    
    Args:
        product_id: UUID of the product
        task_id: UUID of the task to track progress
    """
    from app.models.review import Review
    from app.models.task import Task
    from app.models.insight import ReviewInsight
    from app.services.translation import translation_service
    
    logger.info(f"Starting translation task {task_id} for product {product_id}")
    
    db = get_sync_db()
    
    try:
        # Update task status to processing
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(status="processing")
        )
        db.commit()
        
        # Get pending reviews (including processing and failed - to retry stuck/failed translations)
        # ordered by review_date descending (newest first, matching frontend display)
        result = db.execute(
            select(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status.in_(["pending", "processing", "failed"])
                )
            )
            .order_by(Review.review_date.desc().nullslast(), Review.created_at.desc())
        )
        reviews = result.scalars().all()
        
        total_reviews = len(reviews)
        processed = 0
        failed = 0
        
        logger.info(f"Found {total_reviews} pending reviews to translate")
        
        for review in reviews:
            try:
                # Mark as processing
                db.execute(
                    update(Review)
                    .where(Review.id == review.id)
                    .values(translation_status="processing")
                )
                db.commit()
                
                # Validate body_original exists
                if not review.body_original or not review.body_original.strip():
                    logger.warning(f"Review {review.id} has empty body, skipping translation")
                    db.execute(
                        update(Review)
                        .where(Review.id == review.id)
                        .values(translation_status="failed")
                    )
                    db.commit()
                    failed += 1
                    continue
                
                # åªåšç¿»è¯‘ï¼Œä¸æå–æ´å¯Ÿï¼ˆæ´å¯Ÿéœ€è¦ç”¨æˆ·æ‰‹åŠ¨è§¦å‘ï¼‰
                title_translated, body_translated, sentiment, _ = translation_service.translate_review(
                    title=review.title_original,
                    body=review.body_original,
                    extract_insights=False  # å…³é—­è‡ªåŠ¨æ´å¯Ÿæå–
                )
                
                # Validate translation results
                if not body_translated or not body_translated.strip():
                    logger.error(f"Translation returned empty for review {review.id}, body: {review.body_original[:100]}")
                    raise ValueError("Translation returned empty result")
                
                # Update review with translation only
                db.execute(
                    update(Review)
                    .where(Review.id == review.id)
                    .values(
                        title_translated=title_translated if title_translated and title_translated.strip() else None,
                        body_translated=body_translated,
                        sentiment=sentiment.value,
                        translation_status="completed"
                    )
                )
                
                processed += 1
                
                # Update task progress
                db.execute(
                    update(Task)
                    .where(Task.id == task_id)
                    .values(processed_items=processed)
                )
                db.commit()
                
                logger.debug(f"Translated review {review.id}: {review.rating} stars")
                
                # Rate limiting: wait between API calls
                time.sleep(0.2)
                
            except Exception as e:
                logger.error(f"Failed to translate review {review.id}: {e}", exc_info=True)
                failed += 1
                
                # Mark review as failed (don't save empty translations)
                db.execute(
                    update(Review)
                    .where(Review.id == review.id)
                    .values(
                        translation_status="failed",
                        title_translated=None,
                        body_translated=None
                    )
                )
                db.commit()
                
                # Continue with next review
                continue
        
        # Check if there are still pending reviews
        from app.models.review import TranslationStatus
        pending_count_result = db.execute(
            select(func.count(Review.id))
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.PENDING.value
                )
            )
        )
        pending_count = pending_count_result.scalar() or 0
        
        # Update task status - only mark as completed if no pending reviews
        if pending_count == 0:
            final_status = "completed" if failed == 0 else "completed"
        else:
            # Still have pending reviews, keep as processing
            final_status = "processing"
        
        error_msg = f"{failed} reviews failed" if failed > 0 else None
        
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(
                status=final_status,
                processed_items=processed,
                error_message=error_msg
            )
        )
        db.commit()
        
        logger.info(f"Task {task_id} completed: {processed} translated, {failed} failed")
        
        return {
            "task_id": task_id,
            "product_id": product_id,
            "total": total_reviews,
            "processed": processed,
            "failed": failed
        }
        
    except Exception as e:
        logger.error(f"Task {task_id} failed: {e}")
        
        # Mark task as failed
        try:
            db.execute(
                update(Task)
                .where(Task.id == task_id)
                .values(
                    status="failed",
                    error_message=str(e)
                )
            )
            db.commit()
        except:
            pass
        
        # Retry the task
        raise self.retry(exc=e)
        
    finally:
        db.close()


@celery_app.task
def task_health_check():
    """Simple task to verify worker is running."""
    return {"status": "healthy", "worker": "voc_worker"}


@celery_app.task
def task_retry_failed_reviews(product_id: str):
    """
    Retry translation for failed reviews.
    
    Args:
        product_id: UUID of the product
    """
    from app.models.review import Review
    
    db = get_sync_db()
    
    try:
        # Reset failed reviews to pending
        result = db.execute(
            update(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "failed"
                )
            )
            .values(translation_status="pending")
        )
        db.commit()
        
        logger.info(f"Reset {result.rowcount} failed reviews to pending")
        
        # Trigger processing
        task_process_reviews.delay(product_id, None)
        
    finally:
        db.close()


@celery_app.task(bind=True, max_retries=2, default_retry_delay=30)
def task_extract_insights(self, product_id: str):
    """
    Extract insights for already translated reviews (without re-translating).
    
    This task:
    1. Gets all translated reviews that don't have insights yet
    2. **[NEW] Loads product-specific dimensions if available**
    3. Calls AI to extract insights (using dimensions for categorization)
    4. Saves insights to database
    
    Args:
        product_id: UUID of the product
    """
    from app.models.review import Review
    from app.models.insight import ReviewInsight
    from app.models.product_dimension import ProductDimension
    from app.models.task import Task, TaskType, TaskStatus
    from app.services.translation import translation_service
    from sqlalchemy import delete, exists
    
    logger.info(f"Starting insight extraction for product {product_id}")
    
    db = get_sync_db()
    task_record = None
    
    try:
        # [NEW] è·å–äº§å“çš„ç»´åº¦ Schemaï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        dimension_result = db.execute(
            select(ProductDimension)
            .where(ProductDimension.product_id == product_id)
            .order_by(ProductDimension.created_at)
        )
        dimensions = dimension_result.scalars().all()
        
        # è½¬æ¢ä¸º schema æ ¼å¼
        dimension_schema = None
        if dimensions and len(dimensions) > 0:
            dimension_schema = [
                {"name": dim.name, "description": dim.description or ""}
                for dim in dimensions
            ]
            logger.info(f"ä½¿ç”¨ {len(dimension_schema)} ä¸ªäº§å“ç»´åº¦è¿›è¡Œæ´å¯Ÿæå–")
        else:
            logger.info(f"äº§å“æš‚æ— å®šä¹‰ç»´åº¦ï¼Œä½¿ç”¨é€šç”¨æ´å¯Ÿæå–é€»è¾‘")
        
        # [FIX] å…ˆè·å–æ€»è¯„è®ºæ•°ï¼ˆå·²ç¿»è¯‘çš„è¯„è®ºï¼‰
        total_translated_result = db.execute(
            select(func.count(Review.id))
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "completed",
                    Review.body_translated.isnot(None),
                    Review.is_deleted == False
                )
            )
        )
        total_translated = total_translated_result.scalar() or 0
        
        # [FIX] è·å–å·²æœ‰æ´å¯Ÿçš„è¯„è®ºæ•°ï¼ˆprocessed_itemsï¼‰
        already_processed_result = db.execute(
            select(func.count(func.distinct(ReviewInsight.review_id)))
            .join(Review, Review.id == ReviewInsight.review_id)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.is_deleted == False
                )
            )
        )
        already_processed = already_processed_result.scalar() or 0
        
        # [NEW] åˆ›å»º/æ›´æ–° Task è®°å½•ï¼ˆtotal_items = æ€»è¯„è®ºæ•°ï¼Œprocessed_items = å·²å¤„ç†æ•°ï¼‰
        task_record = get_or_create_task(
            db=db,
            product_id=product_id,
            task_type=TaskType.INSIGHTS.value,
            total_items=total_translated,  # æ€»è¯„è®ºæ•°ï¼ˆå›ºå®šå€¼ï¼‰
            celery_task_id=self.request.id
        )
        # è®¾ç½®å·²å¤„ç†æ•°ä¸ºå½“å‰å·²æœ‰æ´å¯Ÿçš„è¯„è®ºæ•°
        task_record.processed_items = already_processed
        db.commit()
        logger.info(f"Task record: total_items={total_translated}, processed_items={already_processed}, remaining={total_translated - already_processed}")
        
        # [FIX] ä½¿ç”¨ NOT EXISTS å­æŸ¥è¯¢æ’é™¤å·²æœ‰æ´å¯Ÿçš„è¯„è®ºï¼Œé¿å…é‡å¤å¤„ç†
        insight_exists_subquery = (
            select(ReviewInsight.id)
            .where(ReviewInsight.review_id == Review.id)
            .exists()
        )
        
        # Get translated reviews that DON'T have insights yet - ordered by review_date to match page display order
        result = db.execute(
            select(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "completed",
                    Review.body_translated.isnot(None),
                    Review.is_deleted == False,
                    ~insight_exists_subquery  # [FIX] Only process reviews without insights
                )
            )
            .order_by(Review.review_date.desc().nullslast(), Review.created_at.desc())
        )
        reviews = result.scalars().all()
        
        reviews_to_process = len(reviews)
        processed = 0
        insights_extracted = 0
        
        logger.info(f"Found {reviews_to_process} reviews remaining for insight extraction (total={total_translated}, already_done={already_processed})")
        
        for review in reviews:
            try:
                # å¯¹æ¯æ¡è¯„è®ºéƒ½æ‰§è¡Œæ´å¯Ÿæå–ï¼ˆå³ä½¿å†…å®¹å¾ˆçŸ­ï¼Œç»“æœå¯èƒ½ä¸ºç©ºï¼‰
                # [UPDATED] ä¼ å…¥ç»´åº¦ schemaï¼Œè®© AI æŒ‰å®šä¹‰çš„ç»´åº¦åˆ†ç±»
                insights = translation_service.extract_insights(
                    original_text=review.body_original or "",
                    translated_text=review.body_translated or "",
                    dimension_schema=dimension_schema  # [NEW] æ³¨å…¥ç»´åº¦
                )
                
                # [FIX] ç”±äºç°åœ¨åªå¤„ç†æ²¡æœ‰æ´å¯Ÿçš„è¯„è®ºï¼Œä¸éœ€è¦åˆ é™¤æ—§æ•°æ®
                # Insert new insights (if any)
                if insights:
                    for insight_data in insights:
                        insight = ReviewInsight(
                            review_id=review.id,
                            insight_type=insight_data.get('type', 'emotion'),
                            quote=insight_data.get('quote', ''),
                            quote_translated=insight_data.get('quote_translated'),
                            analysis=insight_data.get('analysis', ''),
                            dimension=insight_data.get('dimension')
                        )
                        db.add(insight)
                    
                    insights_extracted += len(insights)
                    logger.debug(f"Extracted {len(insights)} insights for review {review.id}")
                else:
                    # å³ä½¿æ²¡æœ‰æ´å¯Ÿï¼Œä¹Ÿæ’å…¥ä¸€ä¸ªæ ‡è®°è®°å½•ï¼Œè¡¨ç¤ºå·²å¤„ç†
                    # è¿™æ ·ç»Ÿè®¡ä¼šæ˜¾ç¤º 100%ï¼Œä¸”ä¸‹æ¬¡ä¸ä¼šé‡å¤å¤„ç†
                    empty_marker = ReviewInsight(
                        review_id=review.id,
                        insight_type="_empty",  # ç‰¹æ®Šæ ‡è®°ï¼Œè¡¨ç¤ºå†…å®¹å¤ªçŸ­æ— æ´å¯Ÿ
                        quote="",
                        analysis=""
                    )
                    db.add(empty_marker)
                    logger.debug(f"No insights found for review {review.id} (content too short), marked as processed")
                
                db.commit()
                processed += 1
                
                # [FIX] å®šæœŸæ›´æ–° Task è¿›åº¦ï¼ˆæ¯10æ¡æ›´æ–°ä¸€æ¬¡ï¼‰
                # processed_items = already_processed + æ–°å¤„ç†çš„æ•°é‡
                if task_record and processed % 10 == 0:
                    task_record.processed_items = already_processed + processed
                    db.commit()
                
                # Rate limiting
                time.sleep(0.2)
                
            except Exception as e:
                logger.error(f"Failed to extract insights for review {review.id}: {e}")
                db.rollback()
                continue
        
        logger.info(f"Insight extraction completed: processed {processed} new reviews (total={total_translated}, now_done={already_processed + processed}), {insights_extracted} insights extracted")
        
        # [FIX] æ›´æ–° Task çŠ¶æ€ä¸ºå®Œæˆ
        if task_record:
            task_record.status = TaskStatus.COMPLETED.value
            task_record.processed_items = already_processed + processed  # æœ€ç»ˆå¤„ç†æ•°
            db.commit()
        
        return {
            "product_id": product_id,
            "total_reviews": total_translated,  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å˜é‡å
            "processed": processed,
            "insights_extracted": insights_extracted
        }
        
    except Exception as e:
        logger.error(f"Insight extraction failed for product {product_id}: {e}")
        # [NEW] æ›´æ–° Task çŠ¶æ€ä¸ºå¤±è´¥
        if task_record:
            task_record.status = TaskStatus.FAILED.value
            task_record.error_message = str(e)
            db.commit()
        raise self.retry(exc=e)
        
    finally:
        db.close()


# ============== ä»»åŠ¡4: ä¸»é¢˜é«˜äº®æå– ==============

@celery_app.task(bind=True, max_retries=2, default_retry_delay=30, time_limit=1800, soft_time_limit=1700)
def task_extract_themes(self, product_id: str):
    """
    Extract 5W theme keywords for already translated reviews.
    
    This task:
    1. **[NEW] Auto-generates 5W context labels if not exists (Definition phase)**
    2. Gets all translated reviews that don't have theme highlights yet
    3. **[NEW] Uses context labels for forced categorization (Execution phase)**
    4. Calls AI to extract 5W themes with evidence and explanation
    5. Saves theme highlights to database
    
    Args:
        product_id: UUID of the product
    """
    from app.models.review import Review
    from app.models.theme_highlight import ReviewThemeHighlight
    from app.models.product_context_label import ProductContextLabel
    from app.models.task import Task, TaskType, TaskStatus
    from app.services.translation import translation_service
    from sqlalchemy import delete, exists, func
    
    logger.info(f"Starting theme extraction for product {product_id}")
    
    db = get_sync_db()
    task_record = None
    
    try:
        # [NEW] Step 1: æ£€æŸ¥æ˜¯å¦æœ‰ 5W æ ‡ç­¾åº“ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨ç”Ÿæˆ
        label_count_result = db.execute(
            select(func.count(ProductContextLabel.id))
            .where(ProductContextLabel.product_id == product_id)
        )
        label_count = label_count_result.scalar() or 0
        
        context_schema = None
        labels_generated = False
        
        if label_count == 0:
            logger.info(f"äº§å“ {product_id} æš‚æ—  5W æ ‡ç­¾åº“ï¼Œå¼€å§‹è‡ªåŠ¨å­¦ä¹ ...")
            
            # [NEW] å…ˆè·å–äº§å“ä¿¡æ¯ï¼ˆæ ‡é¢˜å’Œäº”ç‚¹ï¼‰
            from app.models.product import Product
            import json as json_lib
            
            product_result = db.execute(
                select(Product).where(Product.id == product_id)
            )
            product = product_result.scalar_one_or_none()
            
            product_title = ""
            bullet_points = []
            
            if product:
                product_title = product.title or ""
                # è§£æäº”ç‚¹ï¼ˆå­˜å‚¨ä¸º JSON å­—ç¬¦ä¸²ï¼‰
                if product.bullet_points:
                    try:
                        bullet_points = json_lib.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
                    except:
                        bullet_points = []
                logger.info(f"ğŸ“¦ äº§å“ä¿¡æ¯ï¼š{product.asin}ï¼Œæ ‡é¢˜é•¿åº¦={len(product_title)}ï¼Œäº”ç‚¹={len(bullet_points)}æ¡")
            
            # è·å–å·²ç¿»è¯‘çš„è¯„è®ºæ ·æœ¬ï¼ˆè‡³å°‘10æ¡ï¼‰
            sample_result = db.execute(
                select(Review.body_original, Review.body_translated)
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status == "completed",
                        Review.body_translated.isnot(None),
                        Review.is_deleted == False
                    )
                )
                .order_by(Review.created_at.desc())
                .limit(50)
            )
            sample_reviews = sample_result.all()
            
            if len(sample_reviews) >= 30:
                # å‡†å¤‡æ ·æœ¬æ–‡æœ¬
                sample_texts = []
                for row in sample_reviews:
                    text = row.body_translated or row.body_original
                    if text and text.strip():
                        sample_texts.append(text.strip())
                
                if len(sample_texts) >= 30:
                    # [UPDATED] è°ƒç”¨ AI å­¦ä¹ æ ‡ç­¾åº“ï¼ˆä¼ å…¥äº§å“ä¿¡æ¯ï¼‰
                    learned_labels = translation_service.learn_context_labels(
                        reviews_text=sample_texts,
                        product_title=product_title,      # [NEW] äº§å“æ ‡é¢˜
                        bullet_points=bullet_points       # [NEW] äº”ç‚¹å–ç‚¹
                    )
                    
                    if learned_labels:
                        # å­˜å…¥æ•°æ®åº“
                        for context_type in ["who", "where", "when", "why", "what"]:
                            labels = learned_labels.get(context_type, [])
                            for item in labels:
                                if isinstance(item, dict) and item.get("name"):
                                    label = ProductContextLabel(
                                        product_id=product_id,
                                        type=context_type,
                                        name=item["name"].strip(),
                                        description=item.get("description", "").strip() or None,
                                        count=0,
                                        is_ai_generated=True
                                    )
                                    db.add(label)
                        
                        db.commit()
                        labels_generated = True
                        total_labels = sum(len(v) for v in learned_labels.values())
                        logger.info(f"âœ… è‡ªåŠ¨ç”Ÿæˆ 5W æ ‡ç­¾åº“æˆåŠŸï¼Œå…± {total_labels} ä¸ªæ ‡ç­¾")
                    else:
                        logger.warning(f"âš ï¸ AI å­¦ä¹ æ ‡ç­¾åº“å¤±è´¥ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
                else:
                    logger.warning(f"âš ï¸ æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘30æ¡ï¼‰ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
            else:
                logger.warning(f"âš ï¸ å·²ç¿»è¯‘è¯„è®ºä¸è¶³ï¼ˆéœ€è¦è‡³å°‘30æ¡ï¼‰ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
        
        # Step 2: è·å–æ ‡ç­¾åº“ Schemaï¼ˆå¦‚æœå­˜åœ¨æˆ–åˆšç”Ÿæˆï¼‰
        if label_count > 0 or labels_generated:
            label_result = db.execute(
                select(ProductContextLabel)
                .where(ProductContextLabel.product_id == product_id)
                .order_by(ProductContextLabel.type, ProductContextLabel.created_at)
            )
            labels = label_result.scalars().all()
            
            if labels:
                context_schema = {}
                for label in labels:
                    if label.type not in context_schema:
                        context_schema[label.type] = []
                    context_schema[label.type].append({
                        "name": label.name,
                        "description": label.description or ""
                    })
                logger.info(f"âœ… ä½¿ç”¨ 5W æ ‡ç­¾åº“è¿›è¡Œå¼ºåˆ¶å½’ç±»ï¼Œå…± {len(labels)} ä¸ªæ ‡ç­¾")
        else:
            logger.info(f"â„¹ï¸ æœªä½¿ç”¨æ ‡ç­¾åº“ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
        
        # Get translated reviews that don't have theme highlights yet
        # Use a subquery to check for existing theme highlights
        theme_exists_subquery = (
            select(ReviewThemeHighlight.id)
            .where(ReviewThemeHighlight.review_id == Review.id)
            .exists()
        )
        
        # Ordered by review_date to match page display order
        result = db.execute(
            select(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "completed",
                    Review.body_translated.isnot(None),
                    Review.is_deleted == False,
                    ~theme_exists_subquery  # Reviews without theme highlights
                )
            )
            .order_by(Review.review_date.desc().nullslast(), Review.created_at.desc())
        )
        reviews = result.scalars().all()
        
        total_reviews = len(reviews)
        processed = 0
        themes_extracted = 0
        
        logger.info(f"Found {total_reviews} translated reviews for theme extraction")
        
        # [NEW] åˆ›å»º/æ›´æ–°ä»»åŠ¡è®°å½•ï¼Œå¯ç”¨å¿ƒè·³
        if total_reviews > 0:
            task_record = get_or_create_task(
                db=db,
                product_id=product_id,
                task_type=TaskType.THEMES.value,
                total_items=total_reviews,
                celery_task_id=self.request.id
            )
            logger.info(f"ä»»åŠ¡è®°å½•å·²åˆ›å»º: {task_record.id}")
        
        # [NEW] æ„å»ºæ ‡ç­¾ååˆ°æ ‡ç­¾IDçš„æ˜ å°„è¡¨ï¼ˆç”¨äºå…³è” context_label_idï¼‰
        label_id_map = {}  # key: (theme_type, label_name), value: context_label_id
        if context_schema:
            for label in labels:
                key = (label.type, label.name)
                label_id_map[key] = label.id
            logger.debug(f"æ„å»ºæ ‡ç­¾æ˜ å°„è¡¨ï¼Œå…± {len(label_id_map)} ä¸ªæ ‡ç­¾")
        
        for review in reviews:
            try:
                # å¯¹æ¯æ¡è¯„è®ºéƒ½æ‰§è¡Œä¸»é¢˜æå–ï¼ˆå³ä½¿å†…å®¹å¾ˆçŸ­ï¼Œç»“æœå¯èƒ½ä¸ºç©ºï¼‰
                # å…ˆåˆ é™¤æ—§çš„ä¸»é¢˜æ•°æ®
                db.execute(
                    delete(ReviewThemeHighlight).where(ReviewThemeHighlight.review_id == review.id)
                )
                
                # [UPDATED] Extract themes with context schema (forced categorization)
                themes = translation_service.extract_themes(
                    original_text=review.body_original or "",
                    translated_text=review.body_translated or "",
                    context_schema=context_schema  # [NEW] ä½¿ç”¨æ ‡ç­¾åº“è¿›è¡Œå¼ºåˆ¶å½’ç±»
                )
                
                # [UPDATED] Insert theme highlights - ä¸€æ¡è®°å½• = ä¸€ä¸ªæ ‡ç­¾
                if themes:
                    for theme_type, items in themes.items():
                        if not items or len(items) == 0:
                            continue
                        
                        for item in items:
                            # è·å–æ ‡ç­¾ä¿¡æ¯ï¼ˆå…¼å®¹ä¸¤ç§æ ¼å¼ï¼štag/quote æˆ– content/content_originalï¼‰
                            label_name = item.get("content", "").strip()
                            # åŸæ–‡è¯æ®ï¼ˆå…¼å®¹ quote å’Œ content_originalï¼‰
                            quote = item.get("quote") or item.get("content_original") or None
                            # ä¸­æ–‡ç¿»è¯‘è¯æ®ï¼ˆå…¼å®¹ quote_translated å’Œ content_translatedï¼‰
                            quote_translated = item.get("quote_translated") or item.get("content_translated") or None
                            explanation = item.get("explanation") or None
                            
                            if not label_name:
                                continue
                            
                            # [NEW] æŸ¥æ‰¾å¯¹åº”çš„ context_label_id
                            context_label_id = label_id_map.get((theme_type, label_name))
                            
                            # åˆ›å»ºä¸€æ¡è®°å½•å¯¹åº”ä¸€ä¸ªæ ‡ç­¾
                            theme_highlight = ReviewThemeHighlight(
                                review_id=review.id,
                                theme_type=theme_type,
                                label_name=label_name,               # æ ‡ç­¾åç§°
                                quote=quote,                         # åŸæ–‡è¯æ®
                                quote_translated=quote_translated,   # [NEW] ä¸­æ–‡ç¿»è¯‘è¯æ®
                                explanation=explanation,             # å½’ç±»ç†ç”±
                                context_label_id=context_label_id,   # å…³è”æ ‡ç­¾åº“ID
                                items=[item]                         # ä¿ç•™ items ç”¨äºå‘åå…¼å®¹
                            )
                            db.add(theme_highlight)
                            themes_extracted += 1
                    
                    logger.debug(f"Extracted {themes_extracted} theme labels for review {review.id}")
                else:
                    # å³ä½¿æ²¡æœ‰ä¸»é¢˜ï¼Œä¹Ÿæ’å…¥ä¸€ä¸ªæ ‡è®°è®°å½•ï¼Œè¡¨ç¤ºå·²å¤„ç†
                    empty_marker = ReviewThemeHighlight(
                        review_id=review.id,
                        theme_type="_empty",
                        label_name=None,
                        items=None
                    )
                    db.add(empty_marker)
                    logger.debug(f"No themes found for review {review.id}, marked as processed")
                
                db.commit()
                processed += 1
                
                # [NEW] æ›´æ–°å¿ƒè·³ï¼ˆæ¯å¤„ç†ä¸€æ¡è¯„è®ºï¼‰
                if task_record:
                    update_task_heartbeat(db, str(task_record.id), processed_items=processed)
                
                # Rate limiting
                time.sleep(0.2)
                
            except Exception as e:
                logger.error(f"Failed to extract themes for review {review.id}: {e}")
                db.rollback()
                continue
        
        logger.info(f"Theme extraction completed: {processed}/{total_reviews} reviews processed, {themes_extracted} theme entries created")
        
        # [NEW] æ›´æ–° Task çŠ¶æ€ä¸ºå®Œæˆ
        if task_record:
            task_record.status = TaskStatus.COMPLETED.value
            task_record.total_items = total_reviews
            task_record.processed_items = processed
            db.commit()
        
        return {
            "product_id": product_id,
            "total_reviews": total_reviews,
            "processed": processed,
            "themes_extracted": themes_extracted
        }
        
    except Exception as e:
        logger.error(f"Theme extraction failed for product {product_id}: {e}")
        # [NEW] æ›´æ–° Task çŠ¶æ€ä¸ºå¤±è´¥
        if task_record:
            task_record.status = TaskStatus.FAILED.value
            task_record.error_message = str(e)
            db.commit()
        raise self.retry(exc=e)
        
    finally:
        db.close()
