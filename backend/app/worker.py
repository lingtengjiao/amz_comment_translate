"""
Celery Worker Configuration and Tasks

This module handles asynchronous processing of reviews:
1. Translation via Qwen API
2. Sentiment analysis
3. Database updates
"""
import logging
import time
from typing import Optional

from celery import Celery
from sqlalchemy import create_engine, select, update, and_, func
from sqlalchemy.orm import sessionmaker
import redis

from app.core.config import settings

logger = logging.getLogger(__name__)

# Redis å®¢æˆ·ç«¯ï¼ˆç”¨äºåˆ†å¸ƒå¼é”ï¼‰
redis_client = redis.from_url(settings.REDIS_URL, decode_responses=True)

# Create Celery application
celery_app = Celery(
    "voc_worker",
    broker=settings.REDIS_URL,
    backend=settings.REDIS_URL,
)

# Celery configuration
celery_app.conf.update(
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="UTC",
    enable_utc=True,
    task_track_started=True,
    task_time_limit=1800,  # 30 minutes timeout per task (increased from 600s to handle large batches)
    task_soft_time_limit=1500,  # 25 minutes soft limit (warning before hard kill)
    worker_prefetch_multiplier=1,
    task_acks_late=True,
    task_routes={
        # ç¿»è¯‘ç›¸å…³ä»»åŠ¡ï¼ˆé«˜é¢‘ã€è½»é‡ï¼‰
        "app.worker.task_translate_bullet_points": {"queue": "translation"},
        "app.worker.task_process_reviews": {"queue": "translation"},
        "app.worker.task_ingest_translation_only": {"queue": "translation"},  # æµå¼è½»é‡ç¿»è¯‘
        
        # åˆ†æç›¸å…³ä»»åŠ¡ï¼ˆä½é¢‘ã€é‡é‡çº§ï¼‰
        "app.worker.task_extract_insights": {"queue": "analysis"},  # æ´å¯Ÿæå–
        "app.worker.task_extract_themes": {"queue": "analysis"},  # ä¸»é¢˜æå–
        "app.worker.task_scientific_learning_and_analysis": {"queue": "analysis"},  # ç§‘å­¦å­¦ä¹ +å›å¡«
        "app.worker.task_full_auto_analysis": {"queue": "analysis"},  # ğŸ”¥ å…¨è‡ªåŠ¨åˆ†æï¼ˆç‹¬ç«‹é˜Ÿåˆ—ï¼‰
    },
)

# Synchronous database connection for Celery worker
# (Celery doesn't support async well, so we use sync SQLAlchemy)
SYNC_DATABASE_URL = settings.DATABASE_URL.replace("+asyncpg", "")
sync_engine = create_engine(SYNC_DATABASE_URL, echo=settings.DEBUG)
SyncSession = sessionmaker(bind=sync_engine)


def get_sync_db():
    """Get synchronous database session for worker."""
    return SyncSession()


# ============== Worker å¯åŠ¨æ—¶æ¸…ç†å¡ä½çš„ä»»åŠ¡ ==============

def cleanup_stuck_reviews():
    """
    æ¸…ç†å¡åœ¨ 'processing' çŠ¶æ€çš„è¯„è®ºã€‚
    å½“ Worker é‡å¯æ—¶ï¼Œä¹‹å‰æ­£åœ¨å¤„ç†çš„è¯„è®ºå¯èƒ½ä¼šå¡åœ¨ processing çŠ¶æ€ã€‚
    è¿™ä¸ªå‡½æ•°å°†å®ƒä»¬é‡ç½®ä¸º pendingï¼Œè®©å®ƒä»¬å¯ä»¥è¢«é‡æ–°å¤„ç†ã€‚
    """
    from app.models.review import Review
    
    db = get_sync_db()
    try:
        result = db.execute(
            update(Review)
            .where(Review.translation_status == "processing")
            .values(translation_status="pending")
        )
        db.commit()
        
        if result.rowcount > 0:
            logger.warning(f"[å¯åŠ¨æ¸…ç†] å·²å°† {result.rowcount} æ¡å¡ä½çš„è¯„è®ºé‡ç½®ä¸º pending çŠ¶æ€")
        else:
            logger.info("[å¯åŠ¨æ¸…ç†] æ²¡æœ‰å‘ç°å¡ä½çš„è¯„è®º")
    except Exception as e:
        logger.error(f"[å¯åŠ¨æ¸…ç†] æ¸…ç†å¡ä½è¯„è®ºå¤±è´¥: {e}")
        db.rollback()
    finally:
        db.close()


def cleanup_stuck_tasks():
    """
    æ¸…ç†å¡ä½çš„ä»»åŠ¡ï¼ˆå¿ƒè·³è¶…æ—¶ï¼‰ã€‚
    å°† PROCESSING çŠ¶æ€ä½†å¿ƒè·³è¶…æ—¶çš„ä»»åŠ¡æ ‡è®°ä¸º TIMEOUTã€‚
    """
    from app.models.task import Task, TaskStatus
    from datetime import datetime, timezone, timedelta
    
    db = get_sync_db()
    try:
        # æŸ¥æ‰¾æ‰€æœ‰ processing çŠ¶æ€çš„ä»»åŠ¡
        result = db.execute(
            select(Task).where(Task.status == TaskStatus.PROCESSING.value)
        )
        tasks = result.scalars().all()
        
        timeout_count = 0
        for task in tasks:
            if task.is_heartbeat_timeout:
                task.status = TaskStatus.TIMEOUT.value
                task.error_message = f"å¿ƒè·³è¶…æ—¶ï¼šæœ€åå¿ƒè·³æ—¶é—´ {task.last_heartbeat}"
                timeout_count += 1
                logger.warning(f"[å¯åŠ¨æ¸…ç†] ä»»åŠ¡ {task.id} ({task.task_type}) å¿ƒè·³è¶…æ—¶ï¼Œæ ‡è®°ä¸º TIMEOUT")
        
        if timeout_count > 0:
            db.commit()
            logger.warning(f"[å¯åŠ¨æ¸…ç†] å·²å°† {timeout_count} ä¸ªè¶…æ—¶ä»»åŠ¡æ ‡è®°ä¸º TIMEOUT")
        else:
            logger.info("[å¯åŠ¨æ¸…ç†] æ²¡æœ‰å‘ç°å¿ƒè·³è¶…æ—¶çš„ä»»åŠ¡")
            
    except Exception as e:
        logger.error(f"[å¯åŠ¨æ¸…ç†] æ¸…ç†è¶…æ—¶ä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()
    finally:
        db.close()


# ============== å¿ƒè·³æ›´æ–°è¾…åŠ©å‡½æ•° ==============

def update_task_heartbeat(db, task_id: str, processed_items: int = None):
    """
    æ›´æ–°ä»»åŠ¡å¿ƒè·³æ—¶é—´ã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        task_id: ä»»åŠ¡ ID
        processed_items: å¯é€‰ï¼ŒåŒæ—¶æ›´æ–°å·²å¤„ç†æ•°é‡
    """
    from app.models.task import Task
    from datetime import datetime, timezone
    
    try:
        values = {"last_heartbeat": datetime.now(timezone.utc)}
        if processed_items is not None:
            values["processed_items"] = processed_items
        
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(**values)
        )
        db.commit()
    except Exception as e:
        logger.error(f"æ›´æ–°ä»»åŠ¡å¿ƒè·³å¤±è´¥: {e}")
        db.rollback()


def get_or_create_task(db, product_id: str, task_type: str, total_items: int = 0, celery_task_id: str = None):
    """
    è·å–æˆ–åˆ›å»ºä»»åŠ¡è®°å½•ã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        product_id: äº§å“ ID
        task_type: ä»»åŠ¡ç±»å‹
        total_items: æ€»é¡¹ç›®æ•°
        celery_task_id: Celery ä»»åŠ¡ ID
        
    Returns:
        Task: ä»»åŠ¡å¯¹è±¡
    """
    from app.models.task import Task, TaskStatus
    from datetime import datetime, timezone
    
    # æŸ¥æ‰¾ç°æœ‰ä»»åŠ¡
    result = db.execute(
        select(Task).where(
            and_(
                Task.product_id == product_id,
                Task.task_type == task_type
            )
        )
    )
    task = result.scalar_one_or_none()
    
    now = datetime.now(timezone.utc)
    
    if task:
        # æ›´æ–°ç°æœ‰ä»»åŠ¡
        task.status = TaskStatus.PROCESSING.value
        task.total_items = total_items
        task.processed_items = 0
        task.last_heartbeat = now
        task.celery_task_id = celery_task_id
        task.error_message = None
    else:
        # åˆ›å»ºæ–°ä»»åŠ¡
        task = Task(
            product_id=product_id,
            task_type=task_type,
            status=TaskStatus.PROCESSING.value,
            total_items=total_items,
            processed_items=0,
            last_heartbeat=now,
            celery_task_id=celery_task_id
        )
        db.add(task)
    
    db.commit()
    db.refresh(task)
    return task


def complete_task(db, task_id: str, success: bool = True, error_message: str = None):
    """
    å®Œæˆä»»åŠ¡ã€‚
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        task_id: ä»»åŠ¡ ID
        success: æ˜¯å¦æˆåŠŸ
        error_message: é”™è¯¯ä¿¡æ¯ï¼ˆå¤±è´¥æ—¶ï¼‰
    """
    from app.models.task import Task, TaskStatus
    
    try:
        status = TaskStatus.COMPLETED.value if success else TaskStatus.FAILED.value
        values = {
            "status": status,
            "last_heartbeat": None  # æ¸…é™¤å¿ƒè·³ï¼Œè¡¨ç¤ºä»»åŠ¡å·²ç»“æŸ
        }
        if error_message:
            values["error_message"] = error_message
        
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(**values)
        )
        db.commit()
    except Exception as e:
        logger.error(f"å®Œæˆä»»åŠ¡å¤±è´¥: {e}")
        db.rollback()


# ä½¿ç”¨ Celery ä¿¡å·åœ¨ Worker å¯åŠ¨æ—¶æ‰§è¡Œæ¸…ç†
from celery.signals import worker_ready

@worker_ready.connect
def on_worker_ready(**kwargs):
    """Worker å¯åŠ¨å®Œæˆåæ‰§è¡Œæ¸…ç†"""
    logger.info("Worker å·²å°±ç»ªï¼Œå¼€å§‹æ£€æŸ¥å¡ä½çš„ä»»åŠ¡...")
    cleanup_stuck_reviews()
    cleanup_stuck_tasks()  # [NEW] æ¸…ç†å¿ƒè·³è¶…æ—¶çš„ä»»åŠ¡


# ============== ä»»åŠ¡1: äº”ç‚¹ç¿»è¯‘ ==============

@celery_app.task(bind=True, max_retries=3, default_retry_delay=30)
def task_translate_bullet_points(self, product_id: str):
    """
    Translate product bullet points and title.
    This task should run FIRST, before review translation.
    
    Args:
        product_id: UUID of the product
    """
    from app.models.product import Product
    from app.services.translation import translation_service
    import json
    
    logger.info(f"Starting bullet points translation for product {product_id}")
    
    db = get_sync_db()
    
    try:
        # Get product
        result = db.execute(
            select(Product).where(Product.id == product_id)
        )
        product = result.scalar_one_or_none()
        
        if not product:
            logger.error(f"Product {product_id} not found")
            return {"success": False, "error": "Product not found"}
        
        translated_title = None
        translated_bullets = None
        
        # 1. Translate product title if not already translated
        if product.title and not product.title_translated:
            try:
                translated_title = translation_service.translate_product_title(product.title)
                product.title_translated = translated_title
                logger.info(f"Translated product title: {translated_title[:50]}...")
            except Exception as e:
                logger.error(f"Failed to translate product title: {e}")
        
        # 2. Translate bullet points if not already translated
        if product.bullet_points and not product.bullet_points_translated:
            try:
                # Parse bullet points from JSON
                bullet_points = json.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
                
                if bullet_points and len(bullet_points) > 0:
                    translated_bullets = translation_service.translate_bullet_points(bullet_points)
                    product.bullet_points_translated = json.dumps(translated_bullets, ensure_ascii=False)
                    logger.info(f"Translated {len(translated_bullets)} bullet points")
            except Exception as e:
                logger.error(f"Failed to translate bullet points: {e}")
        
        db.commit()
        
        return {
            "success": True,
            "product_id": product_id,
            "title_translated": translated_title is not None,
            "bullet_points_translated": translated_bullets is not None
        }
        
    except Exception as e:
        logger.error(f"Bullet points translation failed for product {product_id}: {e}")
        db.rollback()
        raise self.retry(exc=e)
        
    finally:
        db.close()


# ============== ä»»åŠ¡2: è¯„è®ºç¿»è¯‘ ==============

@celery_app.task(bind=True, max_retries=3, default_retry_delay=60)
def task_process_reviews(self, product_id: str, task_id: str):
    """
    Async task to process and translate reviews.
    
    Workflow:
    1. Get pending reviews from database
    2. For each review:
       a. Call Qwen API for translation
       b. Analyze sentiment
       c. Extract insights (æ·±åº¦è§£è¯»)
       d. Update database
       e. Update task progress
    3. Mark task as completed
    
    Args:
        product_id: UUID of the product
        task_id: UUID of the task to track progress
    """
    from app.models.review import Review
    from app.models.task import Task
    from app.models.insight import ReviewInsight
    from app.services.translation import translation_service
    
    logger.info(f"Starting translation task {task_id} for product {product_id}")
    
    db = get_sync_db()
    
    try:
        # Update task status to processing
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(status="processing")
        )
        db.commit()
        
        # Get pending reviews (including processing and failed - to retry stuck/failed translations)
        # ordered by review_date descending (newest first, matching frontend display)
        result = db.execute(
            select(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status.in_(["pending", "processing", "failed"])
                )
            )
            .order_by(Review.review_date.desc().nullslast(), Review.created_at.desc())
        )
        reviews = result.scalars().all()
        
        total_reviews = len(reviews)
        processed = 0
        failed = 0
        
        logger.info(f"Found {total_reviews} pending reviews to translate")
        
        for review in reviews:
            try:
                # Mark as processing
                db.execute(
                    update(Review)
                    .where(Review.id == review.id)
                    .values(translation_status="processing")
                )
                db.commit()
                
                # Validate body_original exists
                if not review.body_original or not review.body_original.strip():
                    logger.warning(f"Review {review.id} has empty body, skipping translation")
                    db.execute(
                        update(Review)
                        .where(Review.id == review.id)
                        .values(translation_status="failed")
                    )
                    db.commit()
                    failed += 1
                    continue
                
                # åªåšç¿»è¯‘ï¼Œä¸æå–æ´å¯Ÿï¼ˆæ´å¯Ÿéœ€è¦ç”¨æˆ·æ‰‹åŠ¨è§¦å‘ï¼‰
                title_translated, body_translated, sentiment, _ = translation_service.translate_review(
                    title=review.title_original,
                    body=review.body_original,
                    extract_insights=False  # å…³é—­è‡ªåŠ¨æ´å¯Ÿæå–
                )
                
                # Validate translation results
                if not body_translated or not body_translated.strip():
                    logger.error(f"Translation returned empty for review {review.id}, body: {review.body_original[:100]}")
                    raise ValueError("Translation returned empty result")
                
                # Update review with translation only
                db.execute(
                    update(Review)
                    .where(Review.id == review.id)
                    .values(
                        title_translated=title_translated if title_translated and title_translated.strip() else None,
                        body_translated=body_translated,
                        sentiment=sentiment.value,
                        translation_status="completed"
                    )
                )
                
                processed += 1
                
                # Update task progress
                db.execute(
                    update(Task)
                    .where(Task.id == task_id)
                    .values(processed_items=processed)
                )
                db.commit()
                
                logger.debug(f"Translated review {review.id}: {review.rating} stars")
                
                # Rate limiting: wait between API calls
                time.sleep(0.2)
                
            except Exception as e:
                logger.error(f"Failed to translate review {review.id}: {e}", exc_info=True)
                failed += 1
                
                # Mark review as failed (don't save empty translations)
                db.execute(
                    update(Review)
                    .where(Review.id == review.id)
                    .values(
                        translation_status="failed",
                        title_translated=None,
                        body_translated=None
                    )
                )
                db.commit()
                
                # Continue with next review
                continue
        
        # Check if there are still pending reviews
        from app.models.review import TranslationStatus
        pending_count_result = db.execute(
            select(func.count(Review.id))
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.PENDING.value
                )
            )
        )
        pending_count = pending_count_result.scalar() or 0
        
        # Update task status - only mark as completed if no pending reviews
        if pending_count == 0:
            final_status = "completed" if failed == 0 else "completed"
        else:
            # Still have pending reviews, keep as processing
            final_status = "processing"
        
        error_msg = f"{failed} reviews failed" if failed > 0 else None
        
        db.execute(
            update(Task)
            .where(Task.id == task_id)
            .values(
                status=final_status,
                processed_items=processed,
                error_message=error_msg
            )
        )
        db.commit()
        
        logger.info(f"Task {task_id} completed: {processed} translated, {failed} failed")
        
        return {
            "task_id": task_id,
            "product_id": product_id,
            "total": total_reviews,
            "processed": processed,
            "failed": failed
        }
        
    except Exception as e:
        logger.error(f"Task {task_id} failed: {e}")
        
        # Mark task as failed
        try:
            db.execute(
                update(Task)
                .where(Task.id == task_id)
                .values(
                    status="failed",
                    error_message=str(e)
                )
            )
            db.commit()
        except:
            pass
        
        # Retry the task
        raise self.retry(exc=e)
        
    finally:
        db.close()


@celery_app.task
def task_health_check():
    """Simple task to verify worker is running."""
    return {"status": "healthy", "worker": "voc_worker"}


@celery_app.task
def task_retry_failed_reviews(product_id: str):
    """
    Retry translation for failed reviews.
    
    Args:
        product_id: UUID of the product
    """
    from app.models.review import Review
    
    db = get_sync_db()
    
    try:
        # Reset failed reviews to pending
        result = db.execute(
            update(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "failed"
                )
            )
            .values(translation_status="pending")
        )
        db.commit()
        
        logger.info(f"Reset {result.rowcount} failed reviews to pending")
        
        # Trigger processing
        task_process_reviews.delay(product_id, None)
        
    finally:
        db.close()


@celery_app.task(bind=True, max_retries=2, default_retry_delay=30)
def task_extract_insights(self, product_id: str):
    """
    Extract insights for already translated reviews (without re-translating).
    
    This task:
    1. Gets all translated reviews that don't have insights yet
    2. **[NEW] Loads product-specific dimensions if available**
    3. Calls AI to extract insights (using dimensions for categorization)
    4. Saves insights to database
    
    Args:
        product_id: UUID of the product
    """
    from app.models.review import Review
    from app.models.insight import ReviewInsight
    from app.models.product_dimension import ProductDimension
    from app.models.task import Task, TaskType, TaskStatus
    from app.services.translation import translation_service
    from sqlalchemy import delete, exists
    
    logger.info(f"Starting insight extraction for product {product_id}")
    
    db = get_sync_db()
    task_record = None
    
    try:
        # [NEW] è·å–äº§å“çš„ç»´åº¦ Schemaï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        dimension_result = db.execute(
            select(ProductDimension)
            .where(ProductDimension.product_id == product_id)
            .order_by(ProductDimension.created_at)
        )
        dimensions = dimension_result.scalars().all()
        
        # è½¬æ¢ä¸º schema æ ¼å¼
        dimension_schema = None
        if dimensions and len(dimensions) > 0:
            dimension_schema = [
                {"name": dim.name, "description": dim.description or ""}
                for dim in dimensions
            ]
            logger.info(f"ä½¿ç”¨ {len(dimension_schema)} ä¸ªäº§å“ç»´åº¦è¿›è¡Œæ´å¯Ÿæå–")
        else:
            logger.info(f"äº§å“æš‚æ— å®šä¹‰ç»´åº¦ï¼Œä½¿ç”¨é€šç”¨æ´å¯Ÿæå–é€»è¾‘")
        
        # [FIX] å…ˆè·å–æ€»è¯„è®ºæ•°ï¼ˆå·²ç¿»è¯‘çš„è¯„è®ºï¼‰
        total_translated_result = db.execute(
            select(func.count(Review.id))
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "completed",
                    Review.body_translated.isnot(None),
                    Review.is_deleted == False
                )
            )
        )
        total_translated = total_translated_result.scalar() or 0
        
        # [FIX] è·å–å·²æœ‰æ´å¯Ÿçš„è¯„è®ºæ•°ï¼ˆprocessed_itemsï¼‰
        already_processed_result = db.execute(
            select(func.count(func.distinct(ReviewInsight.review_id)))
            .join(Review, Review.id == ReviewInsight.review_id)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.is_deleted == False
                )
            )
        )
        already_processed = already_processed_result.scalar() or 0
        
        # [NEW] åˆ›å»º/æ›´æ–° Task è®°å½•ï¼ˆtotal_items = æ€»è¯„è®ºæ•°ï¼Œprocessed_items = å·²å¤„ç†æ•°ï¼‰
        task_record = get_or_create_task(
            db=db,
            product_id=product_id,
            task_type=TaskType.INSIGHTS.value,
            total_items=total_translated,  # æ€»è¯„è®ºæ•°ï¼ˆå›ºå®šå€¼ï¼‰
            celery_task_id=self.request.id
        )
        # è®¾ç½®å·²å¤„ç†æ•°ä¸ºå½“å‰å·²æœ‰æ´å¯Ÿçš„è¯„è®ºæ•°
        task_record.processed_items = already_processed
        db.commit()
        logger.info(f"Task record: total_items={total_translated}, processed_items={already_processed}, remaining={total_translated - already_processed}")
        
        # [FIX] ä½¿ç”¨ NOT EXISTS å­æŸ¥è¯¢æ’é™¤å·²æœ‰æ´å¯Ÿçš„è¯„è®ºï¼Œé¿å…é‡å¤å¤„ç†
        insight_exists_subquery = (
            select(ReviewInsight.id)
            .where(ReviewInsight.review_id == Review.id)
            .exists()
        )
        
        # Get translated reviews that DON'T have insights yet - ordered by review_date to match page display order
        result = db.execute(
            select(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "completed",
                    Review.body_translated.isnot(None),
                    Review.is_deleted == False,
                    ~insight_exists_subquery  # [FIX] Only process reviews without insights
                )
            )
            .order_by(Review.review_date.desc().nullslast(), Review.created_at.desc())
        )
        reviews = result.scalars().all()
        
        reviews_to_process = len(reviews)
        processed = 0
        insights_extracted = 0
        
        logger.info(f"Found {reviews_to_process} reviews remaining for insight extraction (total={total_translated}, already_done={already_processed})")
        
        for review in reviews:
            try:
                # å¯¹æ¯æ¡è¯„è®ºéƒ½æ‰§è¡Œæ´å¯Ÿæå–ï¼ˆå³ä½¿å†…å®¹å¾ˆçŸ­ï¼Œç»“æœå¯èƒ½ä¸ºç©ºï¼‰
                # [UPDATED] ä¼ å…¥ç»´åº¦ schemaï¼Œè®© AI æŒ‰å®šä¹‰çš„ç»´åº¦åˆ†ç±»
                insights = translation_service.extract_insights(
                    original_text=review.body_original or "",
                    translated_text=review.body_translated or "",
                    dimension_schema=dimension_schema  # [NEW] æ³¨å…¥ç»´åº¦
                )
                
                # [FIX] ç”±äºç°åœ¨åªå¤„ç†æ²¡æœ‰æ´å¯Ÿçš„è¯„è®ºï¼Œä¸éœ€è¦åˆ é™¤æ—§æ•°æ®
                # Insert new insights (if any)
                if insights:
                    for insight_data in insights:
                        insight = ReviewInsight(
                            review_id=review.id,
                            insight_type=insight_data.get('type', 'emotion'),
                            quote=insight_data.get('quote', ''),
                            quote_translated=insight_data.get('quote_translated'),
                            analysis=insight_data.get('analysis', ''),
                            dimension=insight_data.get('dimension')
                        )
                        db.add(insight)
                    
                    insights_extracted += len(insights)
                    logger.debug(f"Extracted {len(insights)} insights for review {review.id}")
                else:
                    # å³ä½¿æ²¡æœ‰æ´å¯Ÿï¼Œä¹Ÿæ’å…¥ä¸€ä¸ªæ ‡è®°è®°å½•ï¼Œè¡¨ç¤ºå·²å¤„ç†
                    # è¿™æ ·ç»Ÿè®¡ä¼šæ˜¾ç¤º 100%ï¼Œä¸”ä¸‹æ¬¡ä¸ä¼šé‡å¤å¤„ç†
                    empty_marker = ReviewInsight(
                        review_id=review.id,
                        insight_type="_empty",  # ç‰¹æ®Šæ ‡è®°ï¼Œè¡¨ç¤ºå†…å®¹å¤ªçŸ­æ— æ´å¯Ÿ
                        quote="",
                        analysis=""
                    )
                    db.add(empty_marker)
                    logger.debug(f"No insights found for review {review.id} (content too short), marked as processed")
                
                db.commit()
                processed += 1
                
                # [FIX] å®šæœŸæ›´æ–° Task è¿›åº¦ï¼ˆæ¯10æ¡æ›´æ–°ä¸€æ¬¡ï¼‰
                # processed_items = already_processed + æ–°å¤„ç†çš„æ•°é‡
                if task_record and processed % 10 == 0:
                    task_record.processed_items = already_processed + processed
                    db.commit()
                
                # Rate limiting
                time.sleep(0.2)
                
            except Exception as e:
                logger.error(f"Failed to extract insights for review {review.id}: {e}")
                db.rollback()
                continue
        
        logger.info(f"Insight extraction completed: processed {processed} new reviews (total={total_translated}, now_done={already_processed + processed}), {insights_extracted} insights extracted")
        
        # [FIX] æ›´æ–° Task çŠ¶æ€ä¸ºå®Œæˆ
        if task_record:
            task_record.status = TaskStatus.COMPLETED.value
            task_record.processed_items = already_processed + processed  # æœ€ç»ˆå¤„ç†æ•°
            db.commit()
        
        return {
            "product_id": product_id,
            "total_reviews": total_translated,  # ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„å˜é‡å
            "processed": processed,
            "insights_extracted": insights_extracted
        }
        
    except Exception as e:
        logger.error(f"Insight extraction failed for product {product_id}: {e}")
        # [NEW] æ›´æ–° Task çŠ¶æ€ä¸ºå¤±è´¥
        if task_record:
            task_record.status = TaskStatus.FAILED.value
            task_record.error_message = str(e)
            db.commit()
        raise self.retry(exc=e)
        
    finally:
        db.close()


# ============== ä»»åŠ¡4: ä¸»é¢˜é«˜äº®æå– ==============

@celery_app.task(bind=True, max_retries=2, default_retry_delay=30, time_limit=1800, soft_time_limit=1700)
def task_extract_themes(self, product_id: str):
    """
    Extract 5W theme keywords for already translated reviews.
    
    This task:
    1. **[NEW] Auto-generates 5W context labels if not exists (Definition phase)**
    2. Gets all translated reviews that don't have theme highlights yet
    3. **[NEW] Uses context labels for forced categorization (Execution phase)**
    4. Calls AI to extract 5W themes with evidence and explanation
    5. Saves theme highlights to database
    
    Args:
        product_id: UUID of the product
    """
    from app.models.review import Review
    from app.models.theme_highlight import ReviewThemeHighlight
    from app.models.product_context_label import ProductContextLabel
    from app.models.task import Task, TaskType, TaskStatus
    from app.services.translation import translation_service
    from sqlalchemy import delete, exists, func
    
    logger.info(f"Starting theme extraction for product {product_id}")
    
    db = get_sync_db()
    task_record = None
    
    try:
        # [NEW] Step 1: æ£€æŸ¥æ˜¯å¦æœ‰ 5W æ ‡ç­¾åº“ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨ç”Ÿæˆ
        label_count_result = db.execute(
            select(func.count(ProductContextLabel.id))
            .where(ProductContextLabel.product_id == product_id)
        )
        label_count = label_count_result.scalar() or 0
        
        context_schema = None
        labels_generated = False
        
        if label_count == 0:
            logger.info(f"äº§å“ {product_id} æš‚æ—  5W æ ‡ç­¾åº“ï¼Œå¼€å§‹è‡ªåŠ¨å­¦ä¹ ...")
            
            # [NEW] å…ˆè·å–äº§å“ä¿¡æ¯ï¼ˆæ ‡é¢˜å’Œäº”ç‚¹ï¼‰
            from app.models.product import Product
            import json as json_lib
            
            product_result = db.execute(
                select(Product).where(Product.id == product_id)
            )
            product = product_result.scalar_one_or_none()
            
            product_title = ""
            bullet_points = []
            
            if product:
                product_title = product.title or ""
                # è§£æäº”ç‚¹ï¼ˆå­˜å‚¨ä¸º JSON å­—ç¬¦ä¸²ï¼‰
                if product.bullet_points:
                    try:
                        bullet_points = json_lib.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
                    except:
                        bullet_points = []
                logger.info(f"ğŸ“¦ äº§å“ä¿¡æ¯ï¼š{product.asin}ï¼Œæ ‡é¢˜é•¿åº¦={len(product_title)}ï¼Œäº”ç‚¹={len(bullet_points)}æ¡")
            
            # è·å–å·²ç¿»è¯‘çš„è¯„è®ºæ ·æœ¬ï¼ˆè‡³å°‘10æ¡ï¼‰
            sample_result = db.execute(
                select(Review.body_original, Review.body_translated)
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status == "completed",
                        Review.body_translated.isnot(None),
                        Review.is_deleted == False
                    )
                )
                .order_by(Review.created_at.desc())
                .limit(50)
            )
            sample_reviews = sample_result.all()
            
            if len(sample_reviews) >= 30:
                # å‡†å¤‡æ ·æœ¬æ–‡æœ¬
                sample_texts = []
                for row in sample_reviews:
                    text = row.body_translated or row.body_original
                    if text and text.strip():
                        sample_texts.append(text.strip())
                
                if len(sample_texts) >= 30:
                    # [UPDATED] è°ƒç”¨ AI å­¦ä¹ æ ‡ç­¾åº“ï¼ˆä¼ å…¥äº§å“ä¿¡æ¯ï¼‰
                    learned_labels = translation_service.learn_context_labels(
                        reviews_text=sample_texts,
                        product_title=product_title,      # [NEW] äº§å“æ ‡é¢˜
                        bullet_points=bullet_points       # [NEW] äº”ç‚¹å–ç‚¹
                    )
                    
                    if learned_labels:
                        # å­˜å…¥æ•°æ®åº“
                        for context_type in ["who", "where", "when", "why", "what"]:
                            labels = learned_labels.get(context_type, [])
                            for item in labels:
                                if isinstance(item, dict) and item.get("name"):
                                    label = ProductContextLabel(
                                        product_id=product_id,
                                        type=context_type,
                                        name=item["name"].strip(),
                                        description=item.get("description", "").strip() or None,
                                        count=0,
                                        is_ai_generated=True
                                    )
                                    db.add(label)
                        
                        db.commit()
                        labels_generated = True
                        total_labels = sum(len(v) for v in learned_labels.values())
                        logger.info(f"âœ… è‡ªåŠ¨ç”Ÿæˆ 5W æ ‡ç­¾åº“æˆåŠŸï¼Œå…± {total_labels} ä¸ªæ ‡ç­¾")
                    else:
                        logger.warning(f"âš ï¸ AI å­¦ä¹ æ ‡ç­¾åº“å¤±è´¥ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
                else:
                    logger.warning(f"âš ï¸ æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼ˆéœ€è¦è‡³å°‘30æ¡ï¼‰ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
            else:
                logger.warning(f"âš ï¸ å·²ç¿»è¯‘è¯„è®ºä¸è¶³ï¼ˆéœ€è¦è‡³å°‘30æ¡ï¼‰ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
        
        # Step 2: è·å–æ ‡ç­¾åº“ Schemaï¼ˆå¦‚æœå­˜åœ¨æˆ–åˆšç”Ÿæˆï¼‰
        if label_count > 0 or labels_generated:
            label_result = db.execute(
                select(ProductContextLabel)
                .where(ProductContextLabel.product_id == product_id)
                .order_by(ProductContextLabel.type, ProductContextLabel.created_at)
            )
            labels = label_result.scalars().all()
            
            if labels:
                context_schema = {}
                for label in labels:
                    if label.type not in context_schema:
                        context_schema[label.type] = []
                    context_schema[label.type].append({
                        "name": label.name,
                        "description": label.description or ""
                    })
                logger.info(f"âœ… ä½¿ç”¨ 5W æ ‡ç­¾åº“è¿›è¡Œå¼ºåˆ¶å½’ç±»ï¼Œå…± {len(labels)} ä¸ªæ ‡ç­¾")
        else:
            logger.info(f"â„¹ï¸ æœªä½¿ç”¨æ ‡ç­¾åº“ï¼Œå°†ä½¿ç”¨å¼€æ”¾æå–æ¨¡å¼")
        
        # Get translated reviews that don't have theme highlights yet
        # Use a subquery to check for existing theme highlights
        theme_exists_subquery = (
            select(ReviewThemeHighlight.id)
            .where(ReviewThemeHighlight.review_id == Review.id)
            .exists()
        )
        
        # Ordered by review_date to match page display order
        result = db.execute(
            select(Review)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == "completed",
                    Review.body_translated.isnot(None),
                    Review.is_deleted == False,
                    ~theme_exists_subquery  # Reviews without theme highlights
                )
            )
            .order_by(Review.review_date.desc().nullslast(), Review.created_at.desc())
        )
        reviews = result.scalars().all()
        
        total_reviews = len(reviews)
        processed = 0
        themes_extracted = 0
        
        logger.info(f"Found {total_reviews} translated reviews for theme extraction")
        
        # [NEW] åˆ›å»º/æ›´æ–°ä»»åŠ¡è®°å½•ï¼Œå¯ç”¨å¿ƒè·³
        if total_reviews > 0:
            task_record = get_or_create_task(
                db=db,
                product_id=product_id,
                task_type=TaskType.THEMES.value,
                total_items=total_reviews,
                celery_task_id=self.request.id
            )
            logger.info(f"ä»»åŠ¡è®°å½•å·²åˆ›å»º: {task_record.id}")
        
        # [NEW] æ„å»ºæ ‡ç­¾ååˆ°æ ‡ç­¾IDçš„æ˜ å°„è¡¨ï¼ˆç”¨äºå…³è” context_label_idï¼‰
        label_id_map = {}  # key: (theme_type, label_name), value: context_label_id
        if context_schema:
            for label in labels:
                key = (label.type, label.name)
                label_id_map[key] = label.id
            logger.debug(f"æ„å»ºæ ‡ç­¾æ˜ å°„è¡¨ï¼Œå…± {len(label_id_map)} ä¸ªæ ‡ç­¾")
        
        for review in reviews:
            try:
                # å¯¹æ¯æ¡è¯„è®ºéƒ½æ‰§è¡Œä¸»é¢˜æå–ï¼ˆå³ä½¿å†…å®¹å¾ˆçŸ­ï¼Œç»“æœå¯èƒ½ä¸ºç©ºï¼‰
                # å…ˆåˆ é™¤æ—§çš„ä¸»é¢˜æ•°æ®
                db.execute(
                    delete(ReviewThemeHighlight).where(ReviewThemeHighlight.review_id == review.id)
                )
                
                # [UPDATED] Extract themes with context schema (forced categorization)
                themes = translation_service.extract_themes(
                    original_text=review.body_original or "",
                    translated_text=review.body_translated or "",
                    context_schema=context_schema  # [NEW] ä½¿ç”¨æ ‡ç­¾åº“è¿›è¡Œå¼ºåˆ¶å½’ç±»
                )
                
                # [UPDATED] Insert theme highlights - ä¸€æ¡è®°å½• = ä¸€ä¸ªæ ‡ç­¾
                if themes:
                    for theme_type, items in themes.items():
                        if not items or len(items) == 0:
                            continue
                        
                        for item in items:
                            # è·å–æ ‡ç­¾ä¿¡æ¯ï¼ˆå…¼å®¹ä¸¤ç§æ ¼å¼ï¼štag/quote æˆ– content/content_originalï¼‰
                            label_name = item.get("content", "").strip()
                            # åŸæ–‡è¯æ®ï¼ˆå…¼å®¹ quote å’Œ content_originalï¼‰
                            quote = item.get("quote") or item.get("content_original") or None
                            # ä¸­æ–‡ç¿»è¯‘è¯æ®ï¼ˆå…¼å®¹ quote_translated å’Œ content_translatedï¼‰
                            quote_translated = item.get("quote_translated") or item.get("content_translated") or None
                            explanation = item.get("explanation") or None
                            
                            if not label_name:
                                continue
                            
                            # [NEW] æŸ¥æ‰¾å¯¹åº”çš„ context_label_id
                            context_label_id = label_id_map.get((theme_type, label_name))
                            
                            # åˆ›å»ºä¸€æ¡è®°å½•å¯¹åº”ä¸€ä¸ªæ ‡ç­¾
                            theme_highlight = ReviewThemeHighlight(
                                review_id=review.id,
                                theme_type=theme_type,
                                label_name=label_name,               # æ ‡ç­¾åç§°
                                quote=quote,                         # åŸæ–‡è¯æ®
                                quote_translated=quote_translated,   # [NEW] ä¸­æ–‡ç¿»è¯‘è¯æ®
                                explanation=explanation,             # å½’ç±»ç†ç”±
                                context_label_id=context_label_id,   # å…³è”æ ‡ç­¾åº“ID
                                items=[item]                         # ä¿ç•™ items ç”¨äºå‘åå…¼å®¹
                            )
                            db.add(theme_highlight)
                            themes_extracted += 1
                    
                    logger.debug(f"Extracted {themes_extracted} theme labels for review {review.id}")
                else:
                    # å³ä½¿æ²¡æœ‰ä¸»é¢˜ï¼Œä¹Ÿæ’å…¥ä¸€ä¸ªæ ‡è®°è®°å½•ï¼Œè¡¨ç¤ºå·²å¤„ç†
                    empty_marker = ReviewThemeHighlight(
                        review_id=review.id,
                        theme_type="_empty",
                        label_name=None,
                        items=None
                    )
                    db.add(empty_marker)
                    logger.debug(f"No themes found for review {review.id}, marked as processed")
                
                db.commit()
                processed += 1
                
                # [NEW] æ›´æ–°å¿ƒè·³ï¼ˆæ¯å¤„ç†ä¸€æ¡è¯„è®ºï¼‰
                if task_record:
                    update_task_heartbeat(db, str(task_record.id), processed_items=processed)
                
                # Rate limiting
                time.sleep(0.2)
                
            except Exception as e:
                logger.error(f"Failed to extract themes for review {review.id}: {e}")
                db.rollback()
                continue
        
        logger.info(f"Theme extraction completed: {processed}/{total_reviews} reviews processed, {themes_extracted} theme entries created")
        
        # [NEW] æ›´æ–° Task çŠ¶æ€ä¸ºå®Œæˆ
        if task_record:
            task_record.status = TaskStatus.COMPLETED.value
            task_record.total_items = total_reviews
            task_record.processed_items = processed
            db.commit()
        
        return {
            "product_id": product_id,
            "total_reviews": total_reviews,
            "processed": processed,
            "themes_extracted": themes_extracted
        }
        
    except Exception as e:
        logger.error(f"Theme extraction failed for product {product_id}: {e}")
        # [NEW] æ›´æ–° Task çŠ¶æ€ä¸ºå¤±è´¥
        if task_record:
            task_record.status = TaskStatus.FAILED.value
            task_record.error_message = str(e)
            db.commit()
        raise self.retry(exc=e)
        
    finally:
        db.close()


# ============== [NEW] ä»»åŠ¡5: æµå¼è½»é‡ç¿»è¯‘ ==============

@celery_app.task(bind=True, max_retries=2, default_retry_delay=30)
def task_ingest_translation_only(self, product_id: str):
    """
    æµå¼è½»é‡ç¿»è¯‘ä»»åŠ¡ (Stream Translation Only)
    
    æ•°æ®å…¥åº“åç«‹å³è¿è¡Œï¼Œåªè´Ÿè´£ï¼š
    1. Title/BulletPoints ç¿»è¯‘
    2. Review Text ç¿»è¯‘
    
    ä¸è´Ÿè´£ï¼š
    - ç»´åº¦æå–
    - æ´å¯Ÿåˆ†æ
    - ä¸»é¢˜æå–
    
    è®¾è®¡ç†å¿µï¼šè®©ç”¨æˆ·åœ¨å‰å°"è¾¹é‡‡è¾¹çœ‹"ç¿»è¯‘ç»“æœ
    
    ğŸ”’ å¹¶å‘ç­–ç•¥ï¼šä½¿ç”¨ PostgreSQL è¡Œçº§é”ï¼ˆSELECT FOR UPDATE SKIP LOCKEDï¼‰
       - å¤šä¸ªä»»åŠ¡å¯ä»¥å¹¶å‘å¤„ç†åŒä¸€äº§å“çš„ä¸åŒè¯„è®º
       - è‡ªåŠ¨é¿å…é‡å¤å¤„ç†åŒä¸€æ¡è¯„è®º
       - æ— éœ€æ‰‹åŠ¨ç®¡ç†åˆ†å¸ƒå¼é”
    
    Args:
        product_id: äº§å“ UUID
    """
    from app.models.product import Product
    from app.models.review import Review, TranslationStatus
    from app.services.translation import translation_service
    import json
    
    logger.info(f"[æµå¼ç¿»è¯‘] å¼€å§‹å¤„ç†äº§å“ {product_id}")
    
    db = get_sync_db()
    
    try:
        # 1. è·å–äº§å“ä¿¡æ¯
        product_result = db.execute(
            select(Product).where(Product.id == product_id)
        )
        product = product_result.scalar_one_or_none()
        
        if not product:
            logger.error(f"[æµå¼ç¿»è¯‘] äº§å“ {product_id} ä¸å­˜åœ¨")
            return {"success": False, "error": "Product not found"}
        
        # 2. ç¿»è¯‘äº§å“æ ‡é¢˜ï¼ˆå¦‚æœæœªç¿»è¯‘ï¼‰
        if product.title and not product.title_translated:
            try:
                product.title_translated = translation_service.translate_product_title(product.title)
                logger.info(f"[æµå¼ç¿»è¯‘] æ ‡é¢˜ç¿»è¯‘å®Œæˆ: {product.title_translated[:30]}...")
            except Exception as e:
                logger.warning(f"[æµå¼ç¿»è¯‘] æ ‡é¢˜ç¿»è¯‘å¤±è´¥: {e}")
        
        # 3. ç¿»è¯‘äº”ç‚¹æè¿°ï¼ˆå¦‚æœæœªç¿»è¯‘ï¼‰
        if product.bullet_points and not product.bullet_points_translated:
            try:
                bullet_points = json.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
                if bullet_points and len(bullet_points) > 0:
                    translated_bullets = translation_service.translate_bullet_points(bullet_points)
                    product.bullet_points_translated = json.dumps(translated_bullets, ensure_ascii=False)
                    logger.info(f"[æµå¼ç¿»è¯‘] äº”ç‚¹ç¿»è¯‘å®Œæˆ: {len(translated_bullets)} æ¡")
            except Exception as e:
                logger.warning(f"[æµå¼ç¿»è¯‘] äº”ç‚¹ç¿»è¯‘å¤±è´¥: {e}")
        
        db.commit()
        
        # 4. ğŸ”„ å¾ªç¯ç¿»è¯‘æ‰€æœ‰å¾…å¤„ç†çš„è¯„è®ºï¼ˆåªç¿»è¯‘ï¼Œä¸æå–æ´å¯Ÿï¼‰
        # ä½¿ç”¨å¾ªç¯å¤„ç†æ‰€æœ‰å¾…ç¿»è¯‘è¯„è®ºï¼Œè€Œä¸æ˜¯åªå¤„ç† 100 æ¡
        translated_count = 0
        failed_count = 0
        batch_size = 20  # ğŸ”¥ æ¯æ‰¹å¤„ç† 20 æ¡ï¼ˆåŒ¹é…æµå¼æ’å…¥çš„é¢‘ç‡ï¼‰
        
        while True:
            # ğŸ”’ ä½¿ç”¨ PostgreSQL è¡Œçº§é”é¿å…é‡å¤å¤„ç†
            # FOR UPDATE SKIP LOCKED: è·³è¿‡å·²è¢«å…¶ä»–ä»»åŠ¡é”å®šçš„è¡Œ
            # è¿™æ ·å¤šä¸ªä»»åŠ¡å¯ä»¥å¹¶å‘å¤„ç†ä¸åŒçš„è¯„è®º
            pending_result = db.execute(
                select(Review)
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status.in_([
                            TranslationStatus.PENDING.value,
                            TranslationStatus.FAILED.value
                        ]),
                        Review.is_deleted == False
                    )
                )
                .order_by(Review.created_at.desc())
                .limit(batch_size)
                .with_for_update(skip_locked=True)  # ğŸ”¥ å…³é”®ï¼šè·³è¿‡å·²é”å®šçš„è¡Œ
            )
            pending_reviews = pending_result.scalars().all()
            
            if not pending_reviews:
                logger.info(f"[æµå¼ç¿»è¯‘] æ²¡æœ‰æ›´å¤šå¾…ç¿»è¯‘çš„è¯„è®º")
                break
            
            logger.info(f"[æµå¼ç¿»è¯‘] å¤„ç†æ‰¹æ¬¡: {len(pending_reviews)} æ¡è¯„è®º")
            
            for review in pending_reviews:
                try:
                    # æ ‡è®°ä¸ºå¤„ç†ä¸­
                    review.translation_status = TranslationStatus.PROCESSING.value
                    db.commit()
                    
                    # åªåšç¿»è¯‘ï¼Œä¸æå–æ´å¯Ÿ
                    title_translated, body_translated, sentiment, _ = translation_service.translate_review(
                        title=review.title_original,
                        body=review.body_original,
                        extract_insights=False  # å…³é—­æ´å¯Ÿæå–
                    )
                    
                    if body_translated and body_translated.strip():
                        review.title_translated = title_translated
                        review.body_translated = body_translated
                        review.sentiment = sentiment.value
                        review.translation_status = TranslationStatus.COMPLETED.value
                        translated_count += 1
                    else:
                        review.translation_status = TranslationStatus.FAILED.value
                        failed_count += 1
                    
                    db.commit()
                    
                    # æ§åˆ¶é€Ÿç‡
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.warning(f"[æµå¼ç¿»è¯‘] è¯„è®º {review.id} ç¿»è¯‘å¤±è´¥: {e}")
                    review.translation_status = TranslationStatus.FAILED.value
                    db.commit()
                    failed_count += 1
            
            # å¦‚æœè¿™æ‰¹å¤„ç†çš„æ•°é‡å°äº batch_sizeï¼Œè¯´æ˜æ²¡æœ‰æ›´å¤šäº†
            if len(pending_reviews) < batch_size:
                break
        
        logger.info(f"[æµå¼ç¿»è¯‘] å®Œæˆ: ç¿»è¯‘ {translated_count} æ¡, å¤±è´¥ {failed_count} æ¡")
        
        return {
            "success": True,
            "product_id": product_id,
            "translated_count": translated_count,
            "failed_count": failed_count
        }
        
    except Exception as e:
        logger.error(f"[æµå¼ç¿»è¯‘] äº§å“ {product_id} å¤„ç†å¤±è´¥: {e}")
        db.rollback()
        raise self.retry(exc=e)
        
    finally:
        db.close()
        # ğŸ”’ PostgreSQL è¡Œçº§é”ä¼šåœ¨äº‹åŠ¡ç»“æŸæ—¶è‡ªåŠ¨é‡Šæ”¾


# ============== [NEW] ä»»åŠ¡6: ç§‘å­¦å­¦ä¹ ä¸å…¨é‡å›å¡« ==============

@celery_app.task(bind=True, max_retries=1, default_retry_delay=60)
def task_scientific_learning_and_analysis(self, product_id: str):
    """
    ç§‘å­¦å­¦ä¹ ä¸å…¨é‡å›å¡«ä»»åŠ¡ (Scientific Learning & Backfill)
    
    ç”¨æˆ·ç‚¹å‡»"å¼€å§‹åˆ†æ"æˆ–é‡‡é›†å®Œæˆåè§¦å‘ã€‚
    åˆ©ç”¨è‹±æ–‡åŸæ–‡è¿›è¡Œ Schema å­¦ä¹ ï¼Œç„¶åå›å¡«æ‰€æœ‰æ•°æ®ã€‚
    
    æµç¨‹ï¼š
    1. ç§‘å­¦é‡‡æ ·ï¼ˆåŸºäºè‹±æ–‡åŸæ–‡ï¼Œä¸ç­‰å¾…ç¿»è¯‘ï¼‰
    2. è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹ ï¼ˆç»´åº¦ + 5Wæ ‡ç­¾ï¼‰
    3. å…¨é‡æ´å¯Ÿå›å¡«ï¼ˆå¯¹å·²ç¿»è¯‘çš„è¯„è®ºæå–æ´å¯Ÿï¼‰
    4. å…¨é‡ä¸»é¢˜å›å¡«ï¼ˆå¯¹å·²ç¿»è¯‘çš„è¯„è®ºæå–5Wä¸»é¢˜ï¼‰
    
    Args:
        product_id: äº§å“ UUID
    """
    from app.models.product import Product
    from app.models.product_dimension import ProductDimension
    from app.models.product_context_label import ProductContextLabel
    from app.services.translation import translation_service
    import json as json_lib
    import asyncio
    
    logger.info(f"[ç§‘å­¦å­¦ä¹ ] å¼€å§‹å¤„ç†äº§å“ {product_id}")
    
    db = get_sync_db()
    
    try:
        # === Step 0: è·å–äº§å“ä¿¡æ¯ ===
        product_result = db.execute(
            select(Product).where(Product.id == product_id)
        )
        product = product_result.scalar_one_or_none()
        
        if not product:
            logger.error(f"[ç§‘å­¦å­¦ä¹ ] äº§å“ {product_id} ä¸å­˜åœ¨")
            return {"success": False, "error": "Product not found"}
        
        # è§£æäº§å“ä¿¡æ¯
        product_title = product.title or ""
        bullet_points = []
        if product.bullet_points:
            try:
                bullet_points = json_lib.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
            except:
                bullet_points = []
        
        # === Step 1: ç§‘å­¦é‡‡æ ·ï¼ˆåŸºäºè‹±æ–‡åŸæ–‡ï¼‰===
        logger.info(f"[ç§‘å­¦å­¦ä¹ ] Step 1: ç§‘å­¦é‡‡æ ·ä¸­...")
        
        # éœ€è¦åŒæ­¥æ–¹å¼æ‰§è¡Œå¼‚æ­¥æ–¹æ³•
        from app.services.review_service import ReviewService
        from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
        from sqlalchemy.orm import sessionmaker
        from app.core.config import settings
        from app.models.review import Review
        
        # ä½¿ç”¨åŒæ­¥æŸ¥è¯¢è·å–ç§‘å­¦é‡‡æ ·
        sample_stmt = (
            select(Review.body_original)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.body_original.isnot(None),
                    Review.body_original != "",
                    Review.is_deleted == False
                )
            )
            .order_by(Review.helpful_votes.desc(), func.length(Review.body_original).desc())
            .limit(50)
        )
        sample_result = db.execute(sample_stmt)
        raw_samples = [r[0] for r in sample_result.all() if r[0] and r[0].strip()]
        
        if len(raw_samples) < 10:
            logger.warning(f"[ç§‘å­¦å­¦ä¹ ] æ ·æœ¬ä¸è¶³ï¼ˆ{len(raw_samples)} æ¡ï¼‰ï¼Œéœ€è¦è‡³å°‘ 10 æ¡è‹±æ–‡è¯„è®º")
            return {"success": False, "error": f"æ ·æœ¬ä¸è¶³: {len(raw_samples)} æ¡ï¼Œéœ€è¦è‡³å°‘ 10 æ¡"}
        
        logger.info(f"[ç§‘å­¦å­¦ä¹ ] é‡‡æ ·å®Œæˆ: {len(raw_samples)} æ¡é«˜è´¨é‡è‹±æ–‡è¯„è®º")
        
        # === Step 2: è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹  ===
        logger.info(f"[ç§‘å­¦å­¦ä¹ ] Step 2: è·¨è¯­è¨€é›¶æ ·æœ¬å­¦ä¹ ä¸­...")
        
        # 2.1 å­¦ä¹ ç»´åº¦ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        dim_count_result = db.execute(
            select(func.count(ProductDimension.id))
            .where(ProductDimension.product_id == product_id)
        )
        dim_count = dim_count_result.scalar() or 0
        
        dimensions_learned = 0
        if dim_count == 0:
            logger.info(f"[ç§‘å­¦å­¦ä¹ ] å­¦ä¹ äº§å“ç»´åº¦ä¸­...")
            dims = translation_service.learn_dimensions_from_raw(
                raw_reviews=raw_samples,
                product_title=product_title,
                bullet_points="\n".join(bullet_points) if bullet_points else ""
            )
            
            if dims:
                for dim in dims:
                    dimension = ProductDimension(
                        product_id=product_id,
                        name=dim["name"],
                        description=dim.get("description", ""),
                        is_ai_generated=True
                    )
                    db.add(dimension)
                db.commit()
                dimensions_learned = len(dims)
                logger.info(f"[ç§‘å­¦å­¦ä¹ ] ç»´åº¦å­¦ä¹ å®Œæˆ: {dimensions_learned} ä¸ª")
        else:
            logger.info(f"[ç§‘å­¦å­¦ä¹ ] äº§å“å·²æœ‰ {dim_count} ä¸ªç»´åº¦ï¼Œè·³è¿‡å­¦ä¹ ")
        
        # 2.2 å­¦ä¹ 5Wæ ‡ç­¾ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        label_count_result = db.execute(
            select(func.count(ProductContextLabel.id))
            .where(ProductContextLabel.product_id == product_id)
        )
        label_count = label_count_result.scalar() or 0
        
        labels_learned = 0
        if label_count == 0:
            logger.info(f"[ç§‘å­¦å­¦ä¹ ] å­¦ä¹ 5Wæ ‡ç­¾åº“ä¸­...")
            labels = translation_service.learn_context_labels_from_raw(
                raw_reviews=raw_samples,
                product_title=product_title,
                bullet_points=bullet_points
            )
            
            if labels:
                for context_type in ["who", "where", "when", "why", "what"]:
                    type_labels = labels.get(context_type, [])
                    for item in type_labels:
                        if isinstance(item, dict) and item.get("name"):
                            label = ProductContextLabel(
                                product_id=product_id,
                                type=context_type,
                                name=item["name"].strip(),
                                description=item.get("description", "").strip() or None,
                                count=0,
                                is_ai_generated=True
                            )
                            db.add(label)
                            labels_learned += 1
                db.commit()
                logger.info(f"[ç§‘å­¦å­¦ä¹ ] 5Wæ ‡ç­¾å­¦ä¹ å®Œæˆ: {labels_learned} ä¸ª")
        else:
            logger.info(f"[ç§‘å­¦å­¦ä¹ ] äº§å“å·²æœ‰ {label_count} ä¸ª5Wæ ‡ç­¾ï¼Œè·³è¿‡å­¦ä¹ ")
        
        # === Step 3: è§¦å‘å…¨é‡æ´å¯Ÿå›å¡« ===
        logger.info(f"[ç§‘å­¦å­¦ä¹ ] Step 3: è§¦å‘å…¨é‡æ´å¯Ÿå›å¡«...")
        task_extract_insights.delay(product_id)
        
        # === Step 4: è§¦å‘å…¨é‡ä¸»é¢˜å›å¡« ===
        logger.info(f"[ç§‘å­¦å­¦ä¹ ] Step 4: è§¦å‘å…¨é‡ä¸»é¢˜å›å¡«...")
        task_extract_themes.delay(product_id)
        
        logger.info(f"[ç§‘å­¦å­¦ä¹ ] å®Œæˆ: ç»´åº¦ +{dimensions_learned}, æ ‡ç­¾ +{labels_learned}")
        
        return {
            "success": True,
            "product_id": product_id,
            "samples_used": len(raw_samples),
            "dimensions_learned": dimensions_learned,
            "labels_learned": labels_learned,
            "backfill_triggered": True
        }
        
    except Exception as e:
        logger.error(f"[ç§‘å­¦å­¦ä¹ ] äº§å“ {product_id} å¤„ç†å¤±è´¥: {e}")
        db.rollback()
        raise self.retry(exc=e)
        
    finally:
        db.close()


# ============== [NEW] ä»»åŠ¡7: å…¨è‡ªåŠ¨åˆ†æï¼ˆé‡‡é›†å®Œæˆåè§¦å‘ï¼‰==============

@celery_app.task(bind=True, max_retries=2, default_retry_delay=120)
def task_full_auto_analysis(self, product_id: str, task_id: str):
    """
    ğŸš€ å…¨è‡ªåŠ¨åˆ†æä»»åŠ¡ (Full Auto Analysis Pipeline) - æµå¼å¹¶è¡Œä¼˜åŒ–ç‰ˆ
    
    é‡‡é›†å®Œæˆåè‡ªåŠ¨è§¦å‘ï¼Œæ‰§è¡Œå®Œæ•´çš„åˆ†ææµæ°´çº¿ã€‚
    
    â­ æ ¸å¿ƒä¼˜åŒ–ï¼šç¿»è¯‘åœ¨ ingest æ—¶å°±å·²å¼€å§‹ï¼ˆæµå¼ä¸Šä¼ è¾¹å­˜è¾¹è¯‘ï¼‰
    
    æµå¼å¹¶è¡Œæµç¨‹ï¼š
    
    [æ•°æ®é‡‡é›†é˜¶æ®µ - åœ¨æ­¤ä»»åŠ¡è§¦å‘ä¹‹å‰]
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    æ’å…¥æ•°æ® â†’ ç«‹å³è§¦å‘ç¿»è¯‘ï¼ˆtask_ingest_translation_onlyï¼‰
    æ’å…¥æ•°æ® â†’ ç«‹å³è§¦å‘ç¿»è¯‘
    ...ï¼ˆæŒç»­è¿›è¡Œä¸­ï¼‰
    
    [é‡‡é›†å®Œæˆåè§¦å‘æ­¤ä»»åŠ¡]
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Step 1: å­¦ä¹ ç»´åº¦+5Wæ ‡ç­¾ï¼ˆåŸºäºè‹±æ–‡åŸæ–‡ï¼Œä¸ç­‰ç¿»è¯‘ï¼‰
                              â†“
    Step 2: è§¦å‘æ´å¯Ÿ+ä¸»é¢˜æå–ï¼ˆç¿»è¯‘æ­¤æ—¶å·²åœ¨è¿›è¡Œä¸­ï¼ï¼‰
                              â†“
    Step 3: ç­‰å¾…ä¸‰ä»»åŠ¡å¹¶è¡Œå®Œæˆ
            â”œâ”€ ç¿»è¯‘ï¼ˆå·²åœ¨è¿›è¡Œï¼Œä¼šå…ˆå®Œæˆï¼‰
            â”œâ”€ æ´å¯Ÿæå–ï¼ˆè¾¹ç¿»è¯‘è¾¹æå–ï¼‰
            â””â”€ ä¸»é¢˜æå–ï¼ˆè¾¹ç¿»è¯‘è¾¹æå–ï¼‰
                              â†“
    Step 4: ç”Ÿæˆç»¼åˆæˆ˜ç•¥ç‰ˆæŠ¥å‘Š
    
    æ—¶é—´ä¼˜åŒ–ï¼š
    - ç¿»è¯‘åœ¨é‡‡é›†æ—¶å°±å¼€å§‹ â†’ ä¸ç­‰å¾…
    - å­¦ä¹ åŸºäºè‹±æ–‡åŸæ–‡ â†’ ä¸ä¾èµ–ç¿»è¯‘
    - ä¸‰ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ â†’ å¤§å¹…å‡å°‘ç­‰å¾…æ—¶é—´
    - é¢„è®¡èŠ‚çœ 50%+ çš„æ€»æ—¶é—´
    
    Args:
        product_id: äº§å“ UUID
        task_id: AUTO_ANALYSIS ä»»åŠ¡ UUIDï¼ˆç”¨äºæ›´æ–°è¿›åº¦ï¼‰
    """
    from app.models.product import Product
    from app.models.review import Review, TranslationStatus
    from app.models.task import Task, TaskStatus, TaskType
    from app.models.insight import ReviewInsight
    from app.models.theme_highlight import ReviewThemeHighlight
    from app.models.report import ProductReport, ReportType, ReportStatus
    from app.services.translation import translation_service
    from datetime import datetime, timezone
    import json as json_lib
    
    logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] ğŸš€ å¼€å§‹å¤„ç†äº§å“ {product_id}ï¼Œä»»åŠ¡ {task_id}")
    
    db = get_sync_db()
    
    def update_task_progress(step: int, status: str = TaskStatus.PROCESSING.value, error: str = None):
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        try:
            task_update = {
                "processed_items": step,
                "status": status,
                "last_heartbeat": datetime.now(timezone.utc)
            }
            if error:
                task_update["error_message"] = error
            db.execute(
                update(Task)
                .where(Task.id == task_id)
                .values(**task_update)
            )
            db.commit()
        except Exception as e:
            logger.error(f"[å…¨è‡ªåŠ¨åˆ†æ] æ›´æ–°ä»»åŠ¡è¿›åº¦å¤±è´¥: {e}")
    
    try:
        # è·å–äº§å“ä¿¡æ¯
        product_result = db.execute(
            select(Product).where(Product.id == product_id)
        )
        product = product_result.scalar_one_or_none()
        
        if not product:
            logger.error(f"[å…¨è‡ªåŠ¨åˆ†æ] äº§å“ {product_id} ä¸å­˜åœ¨")
            update_task_progress(0, TaskStatus.FAILED.value, "äº§å“ä¸å­˜åœ¨")
            return {"success": False, "error": "Product not found"}
        
        # ==========================================
        # Step 1: ç§‘å­¦å­¦ä¹ ï¼ˆåŸºäºè‹±æ–‡åŸæ–‡ï¼Œä¸ä¾èµ–ç¿»è¯‘ï¼ï¼‰
        # ==========================================
        update_task_progress(1, TaskStatus.PROCESSING.value)
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] Step 1/3: ç§‘å­¦å­¦ä¹ ï¼ˆåŸºäºè‹±æ–‡åŸæ–‡ï¼‰...")
        
        # ç›´æ¥è°ƒç”¨ç§‘å­¦å­¦ä¹ ä»»åŠ¡çš„é€»è¾‘ï¼ˆåŒæ­¥æ‰§è¡Œï¼‰
        from app.models.product_dimension import ProductDimension
        from app.models.product_context_label import ProductContextLabel
        
        # è§£æäº§å“ä¿¡æ¯
        product_title = product.title or ""
        bullet_points = []
        if product.bullet_points:
            try:
                bullet_points = json_lib.loads(product.bullet_points) if isinstance(product.bullet_points, str) else product.bullet_points
            except:
                bullet_points = []
        
        # ç§‘å­¦é‡‡æ ·ï¼ˆåŸºäºè‹±æ–‡åŸæ–‡ï¼‰
        sample_stmt = (
            select(Review.body_original)
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.body_original.isnot(None),
                    Review.body_original != "",
                    Review.is_deleted == False
                )
            )
            .order_by(Review.helpful_votes.desc(), func.length(Review.body_original).desc())
            .limit(50)
        )
        sample_result = db.execute(sample_stmt)
        raw_samples = [r[0] for r in sample_result.all() if r[0] and r[0].strip()]
        
        if len(raw_samples) >= 10:
            # å­¦ä¹ ç»´åº¦
            dim_count_result = db.execute(
                select(func.count(ProductDimension.id))
                .where(ProductDimension.product_id == product_id)
            )
            dim_count = dim_count_result.scalar() or 0
            
            if dim_count == 0:
                logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] å­¦ä¹ äº§å“ç»´åº¦ä¸­...")
                try:
                    dims = translation_service.learn_dimensions_from_raw(
                        raw_reviews=raw_samples,
                        product_title=product_title,
                        bullet_points="\n".join(bullet_points) if bullet_points else ""
                    )
                    if dims:
                        for dim in dims:
                            dimension = ProductDimension(
                                product_id=product_id,
                                name=dim["name"],
                                description=dim.get("description", ""),
                                is_ai_generated=True
                            )
                            db.add(dimension)
                        db.commit()
                        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] ç»´åº¦å­¦ä¹ å®Œæˆ: {len(dims)} ä¸ª")
                except Exception as e:
                    logger.error(f"[å…¨è‡ªåŠ¨åˆ†æ] ç»´åº¦å­¦ä¹ å¤±è´¥: {e}")
            
            # å­¦ä¹ 5Wæ ‡ç­¾
            label_count_result = db.execute(
                select(func.count(ProductContextLabel.id))
                .where(ProductContextLabel.product_id == product_id)
            )
            label_count = label_count_result.scalar() or 0
            
            if label_count == 0:
                logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] å­¦ä¹ 5Wæ ‡ç­¾åº“ä¸­...")
                try:
                    labels = translation_service.learn_context_labels_from_raw(
                        raw_reviews=raw_samples,
                        product_title=product_title,
                        bullet_points=bullet_points
                    )
                    if labels:
                        labels_saved = 0
                        for context_type in ["who", "where", "when", "why", "what"]:
                            type_labels = labels.get(context_type, [])
                            for item in type_labels:
                                if isinstance(item, dict) and item.get("name"):
                                    label = ProductContextLabel(
                                        product_id=product_id,
                                        type=context_type,
                                        name=item["name"].strip(),
                                        description=item.get("description", "").strip() or None,
                                        count=0,
                                        is_ai_generated=True
                                    )
                                    db.add(label)
                                    labels_saved += 1
                        db.commit()
                        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] 5Wæ ‡ç­¾å­¦ä¹ å®Œæˆ: {labels_saved} ä¸ª")
                except Exception as e:
                    logger.error(f"[å…¨è‡ªåŠ¨åˆ†æ] 5Wæ ‡ç­¾å­¦ä¹ å¤±è´¥: {e}")
        else:
            logger.warning(f"[å…¨è‡ªåŠ¨åˆ†æ] æ ·æœ¬ä¸è¶³ï¼ˆ{len(raw_samples)} æ¡ï¼‰ï¼Œè·³è¿‡å­¦ä¹ ")
        
        # ==========================================
        # Step 2: è§¦å‘æ´å¯Ÿ+ä¸»é¢˜æå–
        # æ³¨æ„ï¼šç¿»è¯‘ä»»åŠ¡åœ¨ ingest æ—¶å°±å·²ç»å¯åŠ¨äº†ï¼ä¸éœ€è¦åœ¨è¿™é‡Œè§¦å‘
        # ==========================================
        update_task_progress(2, TaskStatus.PROCESSING.value)
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] Step 2/4: è§¦å‘æ´å¯Ÿ+ä¸»é¢˜æå–...")
        
        # æ£€æŸ¥å½“å‰ç¿»è¯‘è¿›åº¦ï¼ˆç¿»è¯‘åœ¨ ingest æ—¶å°±å·²ç»å¼€å§‹äº†ï¼‰
        pending_result = db.execute(
            select(func.count(Review.id))
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status.in_([
                        TranslationStatus.PENDING.value,
                        TranslationStatus.PROCESSING.value
                    ]),
                    Review.is_deleted == False
                )
            )
        )
        pending_translation = pending_result.scalar() or 0
        
        translated_result = db.execute(
            select(func.count(Review.id))
            .where(
                and_(
                    Review.product_id == product_id,
                    Review.translation_status == TranslationStatus.COMPLETED.value,
                    Review.is_deleted == False
                )
            )
        )
        translated_count = translated_result.scalar() or 0
        
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] ğŸ“Š å½“å‰ç¿»è¯‘çŠ¶æ€: å·²ç¿»è¯‘ {translated_count} æ¡, å¾…ç¿»è¯‘ {pending_translation} æ¡")
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] ğŸ’¡ ç¿»è¯‘ä»»åŠ¡åœ¨ ingest æ—¶å°±å·²å¯åŠ¨ï¼Œç°åœ¨è§¦å‘æ´å¯Ÿ+ä¸»é¢˜æå–")
        
        # è§¦å‘æ´å¯Ÿå’Œä¸»é¢˜æå–ï¼ˆå®ƒä»¬ä¼šå¤„ç†å·²ç¿»è¯‘çš„è¯„è®ºï¼Œè¾¹ç¿»è¯‘è¾¹æå–ï¼‰
        task_extract_insights.delay(product_id)
        task_extract_themes.delay(product_id)
        
        # ==========================================
        # Step 3: ç­‰å¾…ä¸‰ä»»åŠ¡å¹¶è¡Œå®Œæˆï¼ˆç¿»è¯‘ + æ´å¯Ÿ + ä¸»é¢˜ï¼‰
        # ==========================================
        update_task_progress(3, TaskStatus.PROCESSING.value)
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] Step 3/4: ç­‰å¾…ä¸‰ä»»åŠ¡å¹¶è¡Œå®Œæˆï¼ˆç¿»è¯‘+æ´å¯Ÿ+ä¸»é¢˜ï¼‰...")
        
        # å¹¶è¡Œç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆæœ€å¤šç­‰ 15 åˆ†é’Ÿï¼‰
        max_wait_seconds = 900
        wait_interval = 15
        waited = 0
        last_log_time = 0
        
        while waited < max_wait_seconds:
            time.sleep(wait_interval)
            waited += wait_interval
            
            # æ£€æŸ¥ç¿»è¯‘è¿›åº¦
            pending_result = db.execute(
                select(func.count(Review.id))
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status.in_([
                            TranslationStatus.PENDING.value,
                            TranslationStatus.PROCESSING.value
                        ]),
                        Review.is_deleted == False
                    )
                )
            )
            pending_translation = pending_result.scalar() or 0
            
            # æ£€æŸ¥å·²ç¿»è¯‘çš„è¯„è®ºæ•°
            translated_result = db.execute(
                select(func.count(Review.id))
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status == TranslationStatus.COMPLETED.value,
                        Review.is_deleted == False
                    )
                )
            )
            translated_count = translated_result.scalar() or 0
            
            # æ£€æŸ¥æ´å¯Ÿæå–è¿›åº¦ï¼ˆå·²ç¿»è¯‘ä½†æœªæå–æ´å¯Ÿçš„è¯„è®ºï¼‰
            no_insight_result = db.execute(
                select(func.count(Review.id))
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status == TranslationStatus.COMPLETED.value,
                        Review.is_deleted == False,
                        ~Review.id.in_(
                            select(ReviewInsight.review_id).where(ReviewInsight.review_id == Review.id)
                        )
                    )
                )
            )
            pending_insights = no_insight_result.scalar() or 0
            
            # æ£€æŸ¥ä¸»é¢˜æå–è¿›åº¦ï¼ˆå·²ç¿»è¯‘ä½†æœªæå–ä¸»é¢˜çš„è¯„è®ºï¼‰
            no_theme_result = db.execute(
                select(func.count(Review.id))
                .where(
                    and_(
                        Review.product_id == product_id,
                        Review.translation_status == TranslationStatus.COMPLETED.value,
                        Review.is_deleted == False,
                        ~Review.id.in_(
                            select(ReviewThemeHighlight.review_id).where(ReviewThemeHighlight.review_id == Review.id)
                        )
                    )
                )
            )
            pending_themes = no_theme_result.scalar() or 0
            
            # æ¯30ç§’æ‰“å°ä¸€æ¬¡è¿›åº¦
            if waited - last_log_time >= 30:
                logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] ğŸ“Š å¹¶è¡Œè¿›åº¦ - å¾…ç¿»è¯‘:{pending_translation} | å¾…æ´å¯Ÿ:{pending_insights} | å¾…ä¸»é¢˜:{pending_themes}")
                last_log_time = waited
            
            # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å®Œæˆ
            if pending_translation == 0 and pending_insights == 0 and pending_themes == 0:
                logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] âœ… å¹¶è¡Œå¤„ç†å…¨éƒ¨å®Œæˆï¼å·²ç¿»è¯‘:{translated_count}æ¡")
                break
            
            # å¦‚æœæ´å¯Ÿæˆ–ä¸»é¢˜æå–ä»»åŠ¡å¯èƒ½å·²ç»“æŸä½†è¿˜æœ‰å¾…å¤„ç†çš„ï¼Œé‡æ–°è§¦å‘
            if pending_translation == 0 and waited % 60 == 0:
                if pending_insights > 0:
                    logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] é‡æ–°è§¦å‘æ´å¯Ÿæå–ï¼ˆè¿˜æœ‰{pending_insights}æ¡å¾…å¤„ç†ï¼‰")
                    task_extract_insights.delay(product_id)
                if pending_themes > 0:
                    logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] é‡æ–°è§¦å‘ä¸»é¢˜æå–ï¼ˆè¿˜æœ‰{pending_themes}æ¡å¾…å¤„ç†ï¼‰")
                    task_extract_themes.delay(product_id)
            
            # æ›´æ–°å¿ƒè·³
            update_task_progress(3, TaskStatus.PROCESSING.value)
        
        if waited >= max_wait_seconds:
            logger.warning(f"[å…¨è‡ªåŠ¨åˆ†æ] å¹¶è¡Œå¤„ç†ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­ç”ŸæˆæŠ¥å‘Š")
        
        # ==========================================
        # Step 4: ç”Ÿæˆç»¼åˆæˆ˜ç•¥ç‰ˆæŠ¥å‘Š
        # ==========================================
        update_task_progress(4, TaskStatus.PROCESSING.value)
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] Step 4/4: ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        
        try:
            # ä½¿ç”¨åŒæ­¥æ–¹å¼è°ƒç”¨æŠ¥å‘Šç”Ÿæˆ
            # ç”±äº SummaryService æ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ä½¿ç”¨ asyncio
            import asyncio
            from app.services.summary_service import SummaryService
            
            async def generate_report_async():
                # ä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥ï¼šengine å’Œ async_session_maker
                from app.db.session import async_session_maker
                
                async with async_session_maker() as async_db:
                    summary_service = SummaryService(async_db)
                    result = await summary_service.generate_report(
                        product_id=product_id,
                        report_type="comprehensive",  # ç»¼åˆæˆ˜ç•¥ç‰ˆ
                        min_reviews=10,
                        save_to_db=True
                    )
                    await async_db.commit()  # ç¡®ä¿æäº¤
                    return result
            
            # è¿è¡Œå¼‚æ­¥å‡½æ•°
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                report_result = loop.run_until_complete(generate_report_async())
            finally:
                loop.close()
            
            if report_result.get("success"):
                report_id = report_result.get("report_id")
                logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] ç»¼åˆæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼ŒæŠ¥å‘ŠID: {report_id}")
                
                # æ›´æ–°ä»»åŠ¡è®°å½•ï¼Œä¿å­˜æŠ¥å‘Š ID
                try:
                    db.execute(
                        update(Task)
                        .where(Task.id == task_id)
                        .values(error_message=f"report_id:{report_id}")  # ä¸´æ—¶å­˜å‚¨æŠ¥å‘ŠID
                    )
                    db.commit()
                except Exception as save_err:
                    logger.warning(f"[å…¨è‡ªåŠ¨åˆ†æ] ä¿å­˜æŠ¥å‘ŠIDå¤±è´¥: {save_err}")
            else:
                logger.warning(f"[å…¨è‡ªåŠ¨åˆ†æ] ç»¼åˆæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {report_result.get('error')}")
                
        except Exception as e:
            logger.error(f"[å…¨è‡ªåŠ¨åˆ†æ] æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            # ä¸å› æŠ¥å‘Šç”Ÿæˆå¤±è´¥è€Œä¸­æ–­æ•´ä¸ªä»»åŠ¡
        
        # ==========================================
        # å®Œæˆ
        # ==========================================
        update_task_progress(4, TaskStatus.COMPLETED.value)
        logger.info(f"[å…¨è‡ªåŠ¨åˆ†æ] âœ… äº§å“ {product_id} å…¨è‡ªåŠ¨åˆ†æå®Œæˆï¼ï¼ˆæµå¼å¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰")
        
        return {
            "success": True,
            "product_id": product_id,
            "task_id": task_id,
            "message": "å…¨è‡ªåŠ¨åˆ†æå®Œæˆï¼ˆå¹¶è¡Œä¼˜åŒ–ï¼‰"
        }
        
    except Exception as e:
        logger.error(f"[å…¨è‡ªåŠ¨åˆ†æ] äº§å“ {product_id} å¤„ç†å¤±è´¥: {e}")
        update_task_progress(0, TaskStatus.FAILED.value, str(e))
        db.rollback()
        raise self.retry(exc=e)
        
    finally:
        db.close()
